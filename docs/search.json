[
  {
    "objectID": "posts/2021-06-25-ML_resources.html",
    "href": "posts/2021-06-25-ML_resources.html",
    "title": "Resources list",
    "section": "",
    "text": "Below is a non-exhaustive list of resources including blogs, courses, books, podcasts, and video lectures which I have found extremely useful in learning python, statstics, and machine-learning concepts.\n\nHighly recommended machine-learning starting point:\nFor practical purposes, I’ve noticed, it is not always necessary dive super deep in a concept, rather its helpful to get a concise version of the concept, understand the core assumptions, and start applying the concept right away figuring out your knowledge gaps along the way. I strongly believe in the 80-20 rule (80% output from 20% input). In that spirit, following are the top five sources to get upto speed on learning the basics of ML.\n\nHands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Github\n\nI started to read on ML and data analysis using this wonderful book by Aurélien Géron. This is one of the best, if not the best, introductory books for machine learning. It is concise and simple to read and has jupyter notebooks to apply the concepts taught in it. Initial chapters (Part 1) of the book offer a strong foundation for traditional ML algorithms.\n\nData science from scratch\n\nBesides just focusing on ML, having experience with data wrangling using PyData stack (NumPy, Pandas, and friends) is always a plus. In fact, most of the time the limitation in setting up any ML model is massaging data into machine readable format.\n\nPractical Deep Learning for coders from Fast.AI (using PyTorch)\n\nDeep Learning is the most popular sub-branch of ML and something you should have a general understanding of. Jeremy Howard and team have setup this wonderful didactic coursework using PyTorch (personal preference) comprising of useful collection of walkthroughs and practical examples.\n\nIntroduction to Statistical Learning + Elements of Statistical Learning\n\nFantastic high-level math focussed introduction to algorithms.\n\n100 page ML\n\nApproachable compendium of key ML concepts boiled down to key insights, offers a nice way to articulate concepts in a concise way.\n\n\nNice (free) online courses:\nMachine Learning\n\nMIT’s Intro to Deep Learning\nGoogle’s ML crash course\nStanford’s CS - CNN course\nNYU’s PyTorch Deep learning\nAI Summer\n\nData Science and Computation\n\nMIT’s course on Computational Thinking\nHarvard’s CS 109\n\nMiscellaneous\n\nCMU’s course on Computer Graphics\n\n\n\nPython in general\nLearning Python\n\nAutomate Boring Stuff with Python\nScientific programing with Python\nVisual Guide to Numpy\nPython DataScience Handbook\nChris Albon’s notes\nNumpy Visual Introduction\n\nTutorials / Projects\n\nPynative\nPython Workout\nReuven Lerner’s Python Interview Prep\nProject Euler\nCalm code tips on python code\n\nWriting better code * Corey Schafer’s Tips for writing better code * Refactory blog * RealPython blog\nDatasets\n\nFiveThreeEight\nPudding data\nOur world in data\nUS Federal Reserve dataset with visualization\nIndia centric dataset\nMisc collection\n\n\n\nBooks and websites\nStatstics & Exploratory Analysis\n\nThink Stats by Allen Downley\nTelling stories with data\n\nData Science\n\nJakevdp Python Datascience Notebook\nIntroduction to Cultural Analytics & Python Nice collection of tips for web scraping, network analysis, geotagging, language processing using python.\n\nData Visualization\n\nFundamentals of Data Visualization\nCompendium of different charting types and python code\n\nMachine-Learning\n\nML Online notebook\nML interview book by Chip Huyen\nAndrew White’s Deep Learning for Molecules and Materials Notebook\nOnline deep learning book by Ian Goodfellow\nInterpretable Machine Learning\n\n\n\nMachine-learning focused key commentaries, perspectives, and reviews\nArea reviews\n\nA Survey of Deep Learning for Scientific Discovery\nThe Discipline of Machine Learning\n\nGeneral tips\n\nHow to avoid machine learning pitfalls: a guide for academic researchers\nScikit-learn documentation on common pitfalls\nMachine Learning that Matters\nThree pitfalls to avoid in machine learning\nA Few Useful Things to Know about Machine Learning\n\nCommentaries\n\nStatistical Modeling: The Two Cultures\nThe Hardware Lottery\nMachine Learning that Matters\nWhy is AI harder than we think\n\nIn Chemical Sciences:\n\nA. Y. T. Wang et al., “Machine Learning for Materials Scientists: An Introductory Guide toward Best Practices,” Chem. Mater., vol. 32, no. 12, pp. 4954–4965, 2020\n\nMolecular science:\n\nF. Strieth-Kalthoff, F. Sandfort, M. H. S. Segler, and F. Glorius, Machine learning the ropes: principles, applications and directions in synthetic chemistry, Chem. Soc. Rev\n\nGraph networks\n\nGraph networks: Relational inductive biases, deep learning, and graph networks\nMedium blog on graph neural networks\nAn attempt at demystifying graph deep learning\nGraphML substack\n\n\n\nCheat Sheets\nI’ve compiled some nice cheat-sheets discussing basics of ML, Data Science, Statistics concepts alongside some tips on NumPy, Pandas, and Scikit-learn. These compilations are particularly useful when brushing up details before a potential job interview. Link to dataset repository\n\n\nVideo series\nExplanations\n\nNeural networks series by 3Blue1Brown\nMachine learning zero to hero\nAli Godsi’s video lecture series (highly recommend his lecture on Variational Auto Encoders)\nKhan Academy’s Multivariate Calculus\nKhan Academy Statsitics + Probability\n\nPyCon talks\n\nStatistics for Hackers, Jake Vanderplas\nStatistical Thinking for Data Science, Chris Fonnesbeck\n\nAI talks / commentaries\n\nDangers of AI is weirder than you think\nMachine learning and algorithmic fairness in public and population health\nHundreds of AI tools have been built to catch covid. None of them helped.\n\n\n\nBlogs\nData Science focused\n\nNate Silver’s 538\nJim Vallandingham\nPudding’s data viz\nFlowing Data\nMike Bostock\nSpurious Correlations\nUnderstanding uncertainty\nMath3ma Blog\nMax Wolfe\nChris Albon\nCaitlin Hudson\n\nStatistics Blogs * Statistics by Jim * Probably overthinking it by Allen Downley\nML inclined * Chris Olah * Andrej Karpathy, wonderfully didactic posts * Jay Alammer’s NLP focussed\nML code examples and tutorials * Keras Code Examples * Tensorflow Examples * PyTorch Examples\nGeneral compilations * Distill Blog * KDNuggets\n\n\nData-inspired Podcasts\nFanstastic resource, you can be a fly on the wall and listen to experts talk about a topic that interests you\n\nAI in Business\nMcKinsey AI\nAZ16 podcast\nData Skeptic\nLex Friedman / AI podcast\nMicrosoft Research Podcast\n\n\n\nYouTubers\nList of YouTuber channels that never fail to inspire me\n1. Science and Technology\n\nVsauce\nSixty Symbols\nTom Scott\n3Blue1Brown\nVertisasium\nApplied Science\nMKBHD\n\nStatistics\n\nStatQuest\nCorey Schafer\n\n2. Food\n\nJ Kenji Lopez-Alt\nBinging with Babish\nAdam Ragusea\nFood Wishes\n\n3.Videography and Design\n\nCasey Neistat\nDan Mace\nPeter McKinnon\nAndrew Price - Blender\nCGMatter\nCG Figures - Scientific visualization in Blender\n\n4. Journalism\n\nDhruv Rahtee\nJohnny Harris\nFaye D’Souza\n\n\n\nDiversity & Inclusion\n\nDelotte’s Woman in AI\nAccount from Dow employees going from R&D to D&I\nDiversity in STEM: What it is and Why it Matters\nHow Diversity Makes Us Smarter\nIncreasing Gender Diversity in the STEM Research Workforce\nWithout Inclusion, Diversity Initiatives May Not Be Enough\nWork organization and mental health problems in PhD students\n\n\n\nMisc\n\nPaul Graham\nSam Altman\nBeauty of Science\nFarnam Street\nLess Wrong\nMaria Popova’s Brain Pickings\nWait But Why\nBrad Feld’s Personal Blog\nMelthing Asphalt\nRobert Heaton\nAstral Codex Ten\nAntonio García Martínez\n\n\n\nComics\n\nXkcd\nOatmeal\nCatana Comics"
  },
  {
    "objectID": "posts/2021-12-05-ML_interpretability.html",
    "href": "posts/2021-12-05-ML_interpretability.html",
    "title": "On machine learning model interpretability",
    "section": "",
    "text": "Process mindset vs outcome mindset argument – understanding right decision and right outcomes.\nHelpful notebook on simple and useful tips on model interpretations in chemical science from ever-amazing Patrick Walters."
  },
  {
    "objectID": "posts/2021-12-05-ML_interpretability.html#future-reading-additional-links",
    "href": "posts/2021-12-05-ML_interpretability.html#future-reading-additional-links",
    "title": "On machine learning model interpretability",
    "section": "Future Reading / Additional Links",
    "text": "Future Reading / Additional Links\n\nOnline Jupyter book on Interpretable Machine Learning(https://christophm.github.io/interpretable-ml-book/index.html) – highly recommended\n\nFantastic book commenting on the mathematics and idea for different method for ML model interpretatability.\n\nExplainable AI Cheetsheet. Video discussion on the general idea by Jay Alammar.\nGradient Blog Commentary on ML interpretability\nZoom in on circuits of a Neural Network\nNeptune Blog article on interpretable models\nModule for incorporating model interpretatbility for PyTorch models"
  },
  {
    "objectID": "posts/2021-12-05-ML_interpretability.html#few-key-work-horses",
    "href": "posts/2021-12-05-ML_interpretability.html#few-key-work-horses",
    "title": "On machine learning model interpretability",
    "section": "Few key work horses:",
    "text": "Few key work horses:\n\n1. SHAP\nSHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model.Github\nConsidering cooperative prediction - the value added by the feature contribution to the final output and compare it to its individual output if that feature was active.\nGiven the current set of feature values, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.\n\n\n2. Counterfactuals\n\nIf X had not occured, would have Y occured?\n\nA counterfactual is a idea of relating an action to a consequence.\n“Would I have got a cold, if I had not eaten the ice-cream?”\nUsually a model agnostic approach is implemented, wherein the input(s) of the model is varied and its effect on the prediction is analyzed. Mind here that we dont really care how the model predicts tthe output but just if the output changes by changing the input.\nThe idea echoes with the concept of degree of rate control first proposed by Charles Campbell to propose kinetic pathways and intermediates which have most impact on the final chemical reaction rate.\nCounterfactual have an important drawback - they suffer from the possibility of multiple truths. Explain on why that molecule: Andrew White Lab. Github\nPen’s blog on implementation of Exmol\nExplainerDashboard python package\nAutomate model design and NN architecture search?\n\n\n3. Canonical Correlation Analysis\nVideo from Jay Alammar."
  },
  {
    "objectID": "posts/2019-08-13-pytorch_mnist_classification.html",
    "href": "posts/2019-08-13-pytorch_mnist_classification.html",
    "title": "Neural network implementation in PyTorch",
    "section": "",
    "text": "This notebook is inspired by the Andrew Ng’s amazing Coursera course on Deep learning. The dataset we will be using the train the model on is the MNIST dataset which one of the default datasets in PyTorch.\n\nimport numpy as np \nimport torch \nimport torch.nn as nn \nimport torchvision \nimport torchvision.transforms as transforms \nimport matplotlib.pyplot as plt \nimport matplotlib as mpl\n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\ndevice = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ncpu\n\n\n\n#Import MNIST dataset\ntrain_dataset = torchvision.datasets.MNIST(root='data/',\n                                           train=True,\n                                           transform=torchvision.transforms.ToTensor(),\n                                           download=True)\n\nval_dataset = torchvision.datasets.MNIST(root='data/',\n                                           train=False,\n                                           transform=torchvision.transforms.ToTensor(),\n                                           download=True)\ninput_tensor, label = train_dataset[0]\nprint('MNIST dataset with {} train data and {} test data'.format(len(train_dataset), len(val_dataset)))\nprint('Type of data in dataset: {} AND {}'.format(type(input_tensor), type(label)))\nprint('Input tensor image dimensions: {}'.format(input_tensor.shape))\n\nMNIST dataset with 60000 train data and 10000 test data\nType of data in dataset: <class 'torch.Tensor'> AND <class 'int'>\nInput tensor image dimensions: torch.Size([1, 28, 28])\n\n\n\n#Model hyper-parameters for the fully connected Neural network \ninput_size = 784 # Image input for the digits - 28 x 28 x 1 (W-H-C) -- flattened in the end before being fed in the NN \nnum_hidden_layers = 1\nhidden_layer_size = 50\nnum_classes = 10 \nnum_epochs = 50\nbatch_size = 64 \nlearning_rate = 10e-4\n\n\n#Convert dataset to a dataloader class for ease of doing batching and SGD operations \nfrom torch.utils.data import Dataset, DataLoader\ntrain_loader = DataLoader(dataset = train_dataset,\n                          batch_size = batch_size,\n                          shuffle=True,\n                          num_workers = 2)\n\ntest_loader = DataLoader(dataset = val_dataset,\n                        batch_size = batch_size, \n                        num_workers = 2)\n\n#Take a look at one batch \nexamples = iter(train_loader)\nsamples, labels = examples.next()\nprint(samples.shape, labels.shape)\n\n#Plotting first 4 digits in the dataset: \nfor i in range(4):\n    plt.subplot(2, 2, i+1)\n    plt.imshow(samples[i][0], cmap=mpl.cm.binary, interpolation=\"nearest\")\n    plt.title('Digit:{}'.format(labels[i]))\n    plt.axis(\"off\");\n\ntorch.Size([64, 1, 28, 28]) torch.Size([64])\n\n\n\n\n\nAbove, we have defined a batch-size of 100 for the training dataset with the samples as seen here to be of size = 100 x 1 x 28 x 28\n\n#Define a model \nclass NeuralNet(nn.Module):\n    def __init__(self, input_size, num_hidden_layers, hidden_layer_size, num_classes):\n        super(NeuralNet, self).__init__()\n        self.L1 = nn.Linear(in_features = input_size, out_features = hidden_layer_size)\n        self.relu = nn.ReLU()\n        self.num_hidden_layers = num_hidden_layers\n        \n        if (self.num_hidden_layers-1) > 1:\n            self.L_hidden = nn.ModuleList( [nn.Linear(in_features = hidden_layer_size, out_features = hidden_layer_size) for _ in range(num_hidden_layers-1)] )\n            self.relu_hidden = nn.ModuleList( [nn.ReLU() for _ in range(num_hidden_layers-1)] )\n        else:\n            self.L2 = nn.Linear(in_features = hidden_layer_size, out_features = hidden_layer_size)\n            \n        self.L_out = nn.Linear(in_features = hidden_layer_size, out_features = num_classes)\n    \n    def forward(self, x):\n        out = self.relu(self.L1(x))\n        \n        if (self.num_hidden_layers-1) > 1:\n            for L_hidden, relu_hidden in zip(self.L_hidden, self.relu_hidden):\n                out = relu_hidden(L_hidden(out))\n        else:\n            out = self.relu(self.L2(out))\n        out = self.L_out(out) #No softmax or cross-entropy activation just the output from linear transformation\n        return out\n\n\nmodel = NeuralNet(input_size=input_size, \n                  num_hidden_layers=num_hidden_layers, \n                  hidden_layer_size=hidden_layer_size, \n                  num_classes=num_classes)\n\n\nmodel\n\nNeuralNet(\n  (L1): Linear(in_features=784, out_features=50, bias=True)\n  (relu): ReLU()\n  (L2): Linear(in_features=50, out_features=50, bias=True)\n  (L_out): Linear(in_features=50, out_features=10, bias=True)\n)\n\n\nCrossEntropyLoss in Pytorch implementes Softmax activation and NLLLoss in one class.\n\n#Loss and optimizer \ncriterion = nn.CrossEntropyLoss() #This is implement softmax activation for us so it is not implemented in the model \noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n#Training loop \ntotal_batches = len(train_loader)\nlosses = []\nepochs = []\nfor epoch in range(num_epochs):\n    for i, (image_tensors, labels) in enumerate(train_loader):\n        running_loss = 0\n        batch_count = 0\n        \n        #image tensor = 100, 1, 28, 28 --> 100, 784 input needed \n        image_input_to_NN = image_tensors.view(-1,28*28).to(device)\n        labels = labels.to(device)\n        \n        #Forward pass \n        outputs = model(image_input_to_NN)\n        loss = criterion(outputs, labels)\n        \n        running_loss += loss.item()\n        batch_count += 1\n        \n        #Backward \n        optimizer.zero_grad() #Detach and flush the gradients \n        loss.backward() #Backward gradients evaluation \n        optimizer.step() #To update the weights/parameters in the NN \n        \n        if (epoch) % 10 == 0 and (i+1) % 500 == 0: \n            print(f'epoch {epoch+1} / {num_epochs}, batch {i+1}/{total_batches}, loss = {loss.item():.4f}')\n    \n    loss_per_epoch = running_loss / batch_count\n    epochs.append(epoch)\n    losses.append(loss_per_epoch)\n\nepoch 1 / 50, batch 500/938, loss = 0.2568\nepoch 11 / 50, batch 500/938, loss = 0.0431\nepoch 21 / 50, batch 500/938, loss = 0.0141\nepoch 31 / 50, batch 500/938, loss = 0.0032\nepoch 41 / 50, batch 500/938, loss = 0.0518\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nax.plot(epochs, losses)\nplt.title('Loss Curve (Training)')\nax.set_xlabel('Epochs')\nax.set_ylabel('Loss Value')\n\nText(0, 0.5, 'Loss Value')\n\n\n\n\n\n\n#Test \nwith torch.no_grad():\n    n_correct = 0 \n    n_samples = 0 \n    for images, labels in test_loader:\n        images = images.view(-1, 28*28).to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        \n        _, predictions = torch.max(outputs, 1)\n        n_samples += labels.shape[0]\n        n_correct += (predictions == labels).sum().item() #For each correction prediction we add the correct samples \n    acc = 100 * n_correct / n_samples\n    print(f'Accuracy = {acc:.2f}%')\n\nAccuracy = 97.54%"
  },
  {
    "objectID": "posts/2022-01-10-cheminfo_basics_smarts.html",
    "href": "posts/2022-01-10-cheminfo_basics_smarts.html",
    "title": "Cheminformatics basics - A SMARTS way to filter molecules",
    "section": "",
    "text": "The code in this notebook is inspired from: * iwatobipen * PatWalters"
  },
  {
    "objectID": "posts/2022-01-10-cheminfo_basics_smarts.html#pattern-matching",
    "href": "posts/2022-01-10-cheminfo_basics_smarts.html#pattern-matching",
    "title": "Cheminformatics basics - A SMARTS way to filter molecules",
    "section": "Pattern matching",
    "text": "Pattern matching\n\nIn molecules\nThe SMART way\nSMARTS (SMiles ARbitrary Target Specification) is a lanuguage used to search, select, and match a substructure pattern in a molecule SMILE. The idea of SMARTS is reminiscent of regular expressions (regex) for texts. Following some pre-defined rules for searching, SMARTS offer a powerful way to systematically search though a large corpus of molecules for a particular chemical phenotype.\nMore details on the SMARTS and its ‘grammar’ can be found on the Daylight’s official page\nFew words of caution: * SMILES represent whole molecule (graph), SMARTS identify a substructure (subgraph). * All SMILES are valid SMARTS * It is better to be precise with your query than be general (you dont know what it might hit if not meticulous) > For instance, the SMILES O means an aliphatic oxygen with zero charge and two hydrogens, i.e. water. In SMARTS, the same expression means any aliphatic oxygen regardless of charge, hydrogen count, etc, e.g. it will match the oxygen in water, but also those in ethanol, acetone, molecular oxygen, hydroxy and hydronium ions, etc. Specifying [OH2] limits the pattern to match only water (this is also the fully specified SMILES for water).\n\n\n\nSMARTS Atomic Primitives\n\n\n\n\nSymbol\n\n\nSymbol name\n\n\nAtomic property requirements\n\n\nDefault\n\n\n\n\n\n\n\nwildcard\n\n\nany atom\n\n\n(no default)\n\n\n\n\n\na\n\n\naromatic\n\n\naromatic\n\n\n(no default)\n\n\n\n\nA\n\n\naliphatic\n\n\naliphatic\n\n\n(no default)\n\n\n\n\nD<n>\n\n\ndegree\n\n\n<n> explicit connections\n\n\nexactly one\n\n\n\n\nH<n>\n\n\ntotal-H-count\n\n\n<n> attached hydrogens\n\n\nexactly one1\n\n\n\n\nh<n>\n\n\nimplicit-H-count\n\n\n<n> implicit hydrogens\n\n\nat least one\n\n\n\n\nR<n>\n\n\nring membership\n\n\nin <n> SSSR rings\n\n\nany ring atom\n\n\n\n\nr<n>\n\n\nring size\n\n\nin smallest SSSR ring of size <n>\n\n\nany ring atom2\n\n\n\n\nv<n>\n\n\nvalence\n\n\ntotal bond order <n>\n\n\nexactly one2\n\n\n\n\nX<n>\n\n\nconnectivity\n\n\n<n> total connections\n\n\nexactly one2\n\n\n\n\nx<n>\n\n\nring connectivity\n\n\n<n> total ring connections\n\n\nat least one2\n\n\n\n\n\n<n>\n\n\nnegative charge\n\n\n-<n> charge\n\n\n-1 charge (– is -2, etc)\n\n\n\n\n\n+<n>\n\n\npositive charge\n\n\n+<n> formal charge\n\n\n+1 charge (++ is +2, etc)\n\n\n\n\n#n\n\n\natomic number\n\n\natomic number <n>\n\n\n(no default)2\n\n\n\n\n@\n\n\nchirality\n\n\nanticlockwise\n\n\nanticlockwise, default class2\n\n\n\n\n@@\n\n\nchirality\n\n\nclockwise\n\n\nclockwise, default class2\n\n\n\n\n@<c><n>\n\n\nchirality\n\n\nchiral class <c> chirality <n>\n\n\n(nodefault)\n\n\n\n\n@<c><n>?\n\n\nchiral or unspec\n\n\nchirality <c><n> or unspecified\n\n\n(no default)\n\n\n\n\n<n>\n\n\natomic mass\n\n\nexplicit atomic mass\n\n\nunspecified mass\n\n\n\n\n\n\nExamples1:\n\n\n\n\n\nC\n\n\naliphatic carbon atom\n\n\n\n\nc\n\n\naromatic carbon atom\n\n\n\n\na\n\n\naromatic atom\n\n\n\n\n[#6]\n\n\ncarbon atom\n\n\n\n\n[Ca]\n\n\ncalcium atom\n\n\n\n\n[++]\n\n\natom with a +2 charge\n\n\n\n\n\n\n[R]\n\n\natom in any ring\n\n\n\n\n[D3]\n\n\natom with 3 explicit bonds (implicit H’s don’t count)\n\n\n\n\n[X3]\n\n\natom with 3 total bonds (includes implicit H’s)\n\n\n\n\n[v3]\n\n\natom with bond orders totaling 3 (includes implicit H’s)\n\n\n\n\nCC@HO\n\n\nmatch chirality (H-F-O anticlockwise viewed from C)\n\n\n\n\nCC@?HO\n\n\nmatches if chirality is as specified or is not specified\n\n\n\n\n\n\n\n\n\n\n\n\ncc\n\n\nany pair of attached aromatic carbons\n\n\n\n\nc:c\n\n\naromatic carbons joined by an aromatic bond\n\n\n\n\nc-c\n\n\naromatic carbons joined by a single bond (e.g. biphenyl).\n\n\n\n\nO\n\n\nany aliphatic oxygen\n\n\n\n\n[O;H1]\n\n\nsimple hydroxy oxygen\n\n\n\n\n[O;D1]\n\n\n1-connected (hydroxy or hydroxide) oxygen\n\n\n\n\n[O;D2]\n\n\n2-connected (etheric) oxygen\n\n\n\n\n[C,c]\n\n\nany carbon\n\n\n\n\nF,Cl,Br,I]\n\n\nthe 1st four halogens.\n\n\n\n\n[N;R]\n\n\nmust be aliphatic nitrogen AND in a ring\n\n\n\n\n[!C;R]\n\n\n( NOTaliphatic carbon ) AND in a ring\n\n\n\n\n[n;H1]\n\n\nH-pyrrole nitrogen\n\n\n\n\n[n&H1]\n\n\nsame as above\n\n\n\n\n[c,n&H1]\n\n\nany arom carbon OR H-pyrrole nitrogen\n\n\n\n\n[c,n;H1]\n\n\n(arom carbon OR arom nitrogen) and exactly one H\n\n\n\n\n*!@*\n\n\ntwo atoms connected by a non-ringbond\n\n\n\n\n@;!:\n\n\ntwo atoms connected by a non-aromatic ringbond\n\n\n\n\n[C,c]=,#[C,c]\n\n\ntwo carbons connected by a double or triple bond\n\n\n\n\n\n\nQuery files\nGreg Landrum of Rdkit on query files\nPre-defined filters\n\n\nIn chemical reactions\nThe Reaction SMARTS way\nSMIRKS\n\n\n<tr>\n  <td align=\"center\">C&gt;&gt;C</td>\n  <td align=\"center\">CC&gt;&gt;CC</td>\n  <td align=\"center\">4</td>\n  <td>No maps, normal match.</td>\n</tr>     \n<tr>\n  <td align=\"center\">C&gt;&gt;C</td>\n  <td align=\"center\">[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]</td>\n  <td align=\"center\">4</td>\n  <td>No maps in query, maps in target are ignored.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1]&gt;&gt;C</td>\n  <td align=\"center\">[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]</td>\n  <td align=\"center\">4</td>\n  <td>Unpaired map in query ignored.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1]&gt;&gt;[C:1]</td>\n  <td align=\"center\">CC&gt;&gt;CC</td>\n  <td align=\"center\">0</td>\n  <td>No maps in target, hence no matches.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:?1]&gt;&gt;[C:?1]</td>\n  <td align=\"center\">CC&gt;&gt;CC</td>\n  <td align=\"center\">4</td>\n  <td>Query says mapped as shown or not present.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1]&gt;&gt;[C:1]</td>\n  <td align=\"center\">[CH3:7][CH3:8]&gt;&gt;[CH3:7][CH3:8]</td>\n  <td align=\"center\">2</td>\n  <td>Matches for target 7,7 and 8,8 atom pairs.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1]&gt;&gt;[C:2]</td>\n  <td align=\"center\">[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]</td>\n  <td align=\"center\">4</td>\n  <td>When a query class is not found on both<br>sides of the query, it is\n  ignored;<br>this query does NOT say that the atoms<br>are in different\n  classes. </td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1][C:1]&gt;&gt;[C:1]</td>\n  <td align=\"center\">[CH3:7][CH3:7]&gt;&gt; [CH3:7][CH3:7]</td>\n  <td align=\"center\">4</td>\n  <td>Atom maps match with \"or\" logic.  All atoms<br>get bound to\n  class 7.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1][C:1]&gt;&gt;[C:1]</td>\n  <td align=\"center\">[CH3:7][CH3:8]&gt;&gt; [CH3:7][CH3:8]</td>\n  <td align=\"center\">4</td>\n  <td>The reactant atoms are bound to classes 7<br>and 8. Note that having\n  the first query atom<br>bound to class 7 does not preclude<br>binding the\n  second atom. Next, the product<br>atom can bind to classes 7 or 8.</td>\n</tr>\n<tr>\n  <td align=\"center\">[C:1][C:1]&gt;&gt;[C:1]</td>\n  <td align=\"center\">[CH3:7][CH3:7]&gt;&gt; [CH3:7][CH3:8]</td>\n  <td align=\"center\">2</td>\n  <td>The reactants are bound to class 7.  The<br>product atom can bind to\n  class 7 only.</td>\n</tr>\n\n\n\nExample Reaction SMARTS:\n\n\n\n\nQuery:\n\n\nTarget:\n\n\nMatches:\n\n\nComment:\n\n\n\n\n\n\n\n\n\nOther resources:\n\nDaylight SMART Examples\nSMARTS.plus - to visualize the smart strings\n\nRelevant literature\n\nRules for Identifying Potentially Reactive or Promiscuous Compounds | Journal of Medicinal Chemistry (acs.org)\nBaell, J. B.; Holloway, G. A. New Substructure Filters for Removal of Pan Assay Interference Compounds (PAINS) from Screening Libraries and for Their Exclusion in Bioassays. J. Med. Chem. 2010.\nVidler, L. R.; Watson, I. A.; Margolis, B. J.; Cummins, D. J.; Brunavs, M. Investigating the Behavior of Published PAINS Alerts Using a Pharmaceutical Company Dataset. ACS Med. Chem. Lett. 2018.\nSchuffenhauer, A. et al. Evolution of Novartis’ small molecule screening deck design, J. Med. Chem. (2020)\nGomez-Sanchez, Ruben et al. “Maintaining a High-Quality Screening Collection: The GSK Experience.” SLAS discovery : advancing life sciences R & D vol. 26,8 (2021): 1065-1070. doi:10.1177/24725552211017526"
  },
  {
    "objectID": "posts/2022-01-10-cheminfo_basics_smarts.html#install-necessary-modules",
    "href": "posts/2022-01-10-cheminfo_basics_smarts.html#install-necessary-modules",
    "title": "Cheminformatics basics - A SMARTS way to filter molecules",
    "section": "Install necessary modules",
    "text": "Install necessary modules\n\n# collapse_output\n# Install requirements for the tutorial\n!pip install pandas rdkit-pypi mols2grid matplotlib scikit-learn ipywidgets\n\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandas in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (1.1.5)\nRequirement already satisfied: rdkit-pypi in /home/l017301/.local/lib/python3.8/site-packages (2021.9.4)\nRequirement already satisfied: mols2grid in /home/l017301/.local/lib/python3.8/site-packages (0.2.1)\nRequirement already satisfied: matplotlib in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (3.3.0)\nRequirement already satisfied: scikit-learn in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (0.23.2)\nRequirement already satisfied: ipywidgets in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (7.5.1)\nRequirement already satisfied: numpy>=1.15.4 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (1.18.5)\nRequirement already satisfied: python-dateutil>=2.7.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pandas) (2020.1)\nRequirement already satisfied: Pillow in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from rdkit-pypi) (7.2.0)\nRequirement already satisfied: jinja2>=2.11.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from mols2grid) (2.11.2)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from matplotlib) (0.10.0)\nRequirement already satisfied: joblib>=0.11 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (0.16.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\nRequirement already satisfied: scipy>=0.19.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\nRequirement already satisfied: traitlets>=4.3.1 in /home/l017301/.local/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\nRequirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (7.17.0)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\nRequirement already satisfied: nbformat>=4.2.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (5.0.7)\nRequirement already satisfied: ipykernel>=4.5.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\nRequirement already satisfied: six>=1.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\nRequirement already satisfied: MarkupSafe>=0.23 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jinja2>=2.11.0->mols2grid) (1.1.1)\nRequirement already satisfied: decorator in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.2)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/l017301/.local/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.24)\nRequirement already satisfied: jedi>=0.10 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.17.1)\nRequirement already satisfied: pexpect; sys_platform != \"win32\" in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\nRequirement already satisfied: pickleshare in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\nRequirement already satisfied: backcall in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\nRequirement already satisfied: pygments in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.6.1)\nRequirement already satisfied: setuptools>=18.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (47.1.0)\nRequirement already satisfied: notebook>=4.4.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.1.1)\nRequirement already satisfied: jupyter-core in /home/l017301/.local/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\nRequirement already satisfied: ipython-genutils in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\nRequirement already satisfied: tornado>=4.2 in /home/l017301/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\nRequirement already satisfied: jupyter-client in /home/l017301/.local/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\nRequirement already satisfied: wcwidth in /home/l017301/.local/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\nRequirement already satisfied: parso<0.8.0,>=0.7.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\nRequirement already satisfied: ptyprocess>=0.5 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\nRequirement already satisfied: terminado>=0.8.3 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.3)\nRequirement already satisfied: prometheus-client in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\nRequirement already satisfied: argon2-cffi in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\nRequirement already satisfied: Send2Trash in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\nRequirement already satisfied: pyzmq>=17 in /home/l017301/.local/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.3.0)\nRequirement already satisfied: nbconvert in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\nRequirement already satisfied: pyrsistent>=0.14.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.16.0)\nRequirement already satisfied: attrs>=17.4.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (19.3.0)\nRequirement already satisfied: nest-asyncio>=1.5 in /home/l017301/.local/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.5.4)\nRequirement already satisfied: entrypoints in /home/l017301/.local/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.3)\nRequirement already satisfied: cffi>=1.0.0 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.1)\nRequirement already satisfied: defusedxml in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\nRequirement already satisfied: mistune<2,>=0.8.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\nRequirement already satisfied: testpath in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\nRequirement already satisfied: pandocfilters>=1.4.1 in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\nRequirement already satisfied: bleach in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.5)\nRequirement already satisfied: pycparser in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\nRequirement already satisfied: packaging in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.4)\nRequirement already satisfied: webencodings in /lrlhps/apps/python/python-3.8.5/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\nWARNING: You are using pip version 20.2.2; however, version 22.2.2 is available.\nYou should consider upgrading via the '/lrlhps/apps/python/python-3.8.5/bin/python -m pip install --upgrade pip' command.\n\n\n\nimport os \nimport pandas as pd\nimport numpy as np \n\nThe majority of the basic molecular functionality is found in module rdkit.Chem\n\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.3\n\n\n\nfrom collections import defaultdict\nfrom rdkit.Chem.Draw import rdMolDraw2D\nfrom IPython.display import SVG\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 15,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 12,\n'ytick.labelsize' : 12,\n}\n \nplt.rcParams.update(plot_params)\n\n\ndiclofenac = Chem.MolFromSmiles('O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl')\ndiclofenac\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Code from : https://www.rdkit.org/docs/GettingStartedInPython.html?highlight=maccs#drawing-molecules\nsub_pattern = Chem.MolFromSmarts('O=CCccN')\nhit_ats = list(diclofenac.GetSubstructMatch(sub_pattern))\nhit_bonds = []\n\nfor bond in sub_pattern.GetBonds():\n    aid1 = hit_ats[bond.GetBeginAtomIdx()]\n    aid2 = hit_ats[bond.GetEndAtomIdx()]\n    \n    hit_bonds.append( diclofenac.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n\nd2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\nrdMolDraw2D.PrepareAndDrawMolecule(d2d, diclofenac, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\nd2d.FinishDrawing()\nSVG(d2d.GetDrawingText())\n\n\n\n\nDefining a function to make it easy and reproducible:\n\ndef viz_substruct(main_smile, substructure_smarts):\n    \n    mol_file = Chem.MolFromSmiles(main_smile)\n    sub_pattern = Chem.MolFromSmarts(substructure_smarts)\n    \n    hit_ats = list(mol_file.GetSubstructMatch(sub_pattern)) # Returns the indices of the molecule’s atoms that match a substructure query\n    hit_bonds = []\n\n    for bond in sub_pattern.GetBonds():\n        aid1 = hit_ats[bond.GetBeginAtomIdx()]\n        aid2 = hit_ats[bond.GetEndAtomIdx()]\n\n        hit_bonds.append( mol_file.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n    d2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\n    rdMolDraw2D.PrepareAndDrawMolecule(d2d, mol_file, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\n    d2d.FinishDrawing()\n    return SVG(d2d.GetDrawingText())\n\n\nviz_substruct('C1=NC(=NC(=C1)C)C2=CC=CC=N2','[ar]!@[ar]')\n\n\n\n\n\nOnline resource to visualize the SMARTS.\nThis code is inspired from Pen Taka’s blogpost\nSMARTS.plus is a nice web GUI to visualize different SMART queries real-time.\n\nfrom rdkit import Chem\nfrom IPython.display import Image\nimport requests\nimport urllib\nfrom time import time \n\n\nbaseurl = \"https://smarts.plus/smartsview/download_rest?\"\n\n\n# Function to get a request for SMART query\ndef get_img(query):\n    url = baseurl+query\n    start = time()\n    res = requests.get(url)\n    _img = Image(res.content, embed=True, retina=True)\n    print('Time taken: {0:0.2f} secs'.format(time() - start))\n    return _img\n\n\nim0 = get_img(\"smarts=[ar]!@[ar]\")\nim0\n\nTime taken: 4.04 secs\n\n\n\n\n\n\nim1 = get_img(\"smarts=[CX3](=[OX1])[OX2][CX3](=[OX1])\")\nim1\n\nTime taken: 1.95 secs\n\n\n\n\n\n\n\nSMARTS.plus now handles reaction SMARTS, SMIRKS too!\nPaper talking about the update\n\nim0 = get_img(\"smarts=[CH1:1][OH:2].[OH][C:3]=[O:4]>>[C:1][O:2][C:3]=[O:4]\")\nim0\n\nTime taken: 2.00 secs"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html",
    "href": "posts/2020-08-23-imdb_bollywood.html",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "",
    "text": "import os \nfrom requests import get \nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport time as time \nfrom tqdm.notebook import tqdm"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#load-dataset",
    "href": "posts/2020-08-23-imdb_bollywood.html#load-dataset",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Load Dataset",
    "text": "Load Dataset\nThe data set for the movie was scrapped from IMDB using BeautifulSoup. A template for the code used for scrapping the data is shown in the cell below.\n\n\nCode\nnames, year, imdb_rating, metascore, num_votes = [], [], [], [], [] \n\nstart_time = time.time()\nrequests = 0\n\nyears_url = [str(i) for i in range(1950,2006)]\npage_iter = [0, 51, 101, 151, 201]\n\nfor year_url in tqdm(years_url):\n    for page_num in tqdm(page_iter):\n        #URL to parse \n        url = 'https://www.imdb.com/search/title/?title_type=feature,&release_date={0},{0}&countries=in&languages=hi&sort=num_votes,desc&start={1}&ref_=adv_prv'.format(int(year_url), int(page_num))\n        response = get(url)\n        \n        #Sleep to carve out load \n        time.sleep(np.random.randint(1,5))\n        \n        #Estimate time elapsed per request\n        requests += 1\n        elapsed_time = time.time() - start_time\n        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n        clear_output(wait = True)\n        \n        html_soup = BeautifulSoup(response.text, 'html.parser')\n        movie_containers = html_soup.find_all('div', class_='lister-item mode-advanced')\n        \n        for i, container in enumerate(movie_containers):\n            container_entry = movie_containers[i] \n            movie_name = container_entry.h3.a.text\n            names.append(movie_name)\n            \n            movie_year = container_entry.h3.find('span',class_='lister-item-year text-muted unbold').text.strip('()')\n            year.append(movie_year)\n            #print(movie_name, movie_year)\n            \n            try:\n                movie_rating = float(container_entry.strong.text)\n                imdb_rating.append(movie_rating)\n            except AttributeError:\n                imdb_rating.append(np.nan)\n            \n            try:\n                movie_votes = float(''.join(container_entry.find('span', attrs = {'name':'nv'}).text.split(',')))\n                num_votes.append(movie_votes)\n            except (AttributeError, ValueError):\n                num_votes.append(np.nan)\n                \n            try:\n                movie_metascore = float(container_entry.find('span', class_='metascore').text.strip())\n                metascore.append(movie_metascore)\n            except AttributeError:\n                metascore.append(np.nan)\n    \n    print('Making dataframe for year {}'.format(year_url))\n    df_movies = pd.DataFrame({'name':names,'year':year,'rating':imdb_rating,'metascore':metascore,'num_votes':num_votes})\n    df_movies.to_csv('./temp_imdb_files/bollywood_data_{}.csv'.format(year_url),sep=',',header=True, index=False)\n    del df_movies\n\n\n\ndf_movies = pd.read_csv('./IMDB-files/bollywood_movies_data_1950_2020_new.csv',sep=',', skipinitialspace=True)\n\n\ndf_movies.columns\n\nIndex(['name', 'year', 'rating', 'metascore', 'num_votes'], dtype='object')\n\n\n\ndf_movies.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11876 entries, 0 to 11875\nData columns (total 5 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   name       11876 non-null  object \n 1   year       11875 non-null  object \n 2   rating     7427 non-null   float64\n 3   metascore  91 non-null     float64\n 4   num_votes  7427 non-null   float64\ndtypes: float64(3), object(2)\nmemory usage: 464.0+ KB"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#cleaning-the-data",
    "href": "posts/2020-08-23-imdb_bollywood.html#cleaning-the-data",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Cleaning the data",
    "text": "Cleaning the data\nSince we are particularly interested in release year of the movies, we can sanitize that column first. To begin, we see what are different possible strings/elements in the year.\n\ndf_movies['year'].unique()\n\narray(['1950', '1951', 'I) (1951', '1952', '1957', 'II) (1952', '1953',\n       'II) (1953', 'III) (1953', 'I) (1953', '1954', 'I) (1954',\n       'III) (1954', '1955', '1956', 'II) (1957', '1958', 'I) (1958',\n       '1959', 'II) (1959', '1960', 'I) (1960', '1961', '1962', '1963',\n       'I) (1964', '1964', '1965', '1966', '1967', '1968', 'I) (1968',\n       '1969', 'I) (1969', '1979', '1970', 'II) (1970', '1971',\n       'I) (1971', 'II) (1971', '1972', 'II) (1972', '1973', '1974',\n       'II) (1974', '1975', 'I) (1975', 'II) (1975', '1976', '1977',\n       'I) (1977', '1978', 'II) (1978', 'I) (1979', 'II) (1979', '1980',\n       'I) (1980', '1981', '1982', 'I) (1982', '1983', 'I) (1983',\n       'II) (1983', '1984', 'II) (1984', '1985', 'I) (1985', '1986',\n       'I) (1986', 'II) (1986', '1987', 'I) (1987', '1988', 'I) (1988',\n       'II) (1988', '1989', 'I) (1989', '1990', 'II) (1990', 'I) (1990',\n       '1991', 'I) (1991', '1992', '1993', 'I) (1992', 'II) (1992',\n       'I) (1993', 'II) (1993', '1994', 'II) (1994', 'I) (1994', '1995',\n       '1996', 'I) (1996', '1997', 'I) (1997', '1998', 'II) (1998',\n       '2005', '1999', 'II) (1999', '2000', 'II) (2000', 'I) (2000',\n       '2001', 'I) (2001', 'I) (2002', '2002', '2003', 'I) (2003', '2004',\n       '2007', 'I) (2005', 'II) (2005', '2006', 'I) (2006', 'II) (2006',\n       'I) (2007', 'III) (2007', '2008', 'I) (2008', 'II) (2008', '2009',\n       'I) (2009', '2012', 'II) (2009', '2010', 'I) (2010', 'II) (2010',\n       'IV) (2010', '2011', 'I) (2011', 'II) (2011', 'IV) (2011',\n       'II) (2012', 'I) (2012', '2013', 'I) (2013', 'II) (2013',\n       'V) (2013', '2014', 'I) (2014', 'III) (2014', 'VIII) (2014',\n       'II) (2014', 'IV) (2014', '2015', 'I) (2015', 'V) (2015',\n       'III) (2015', 'VI) (2015', 'II) (2015', 'IV) (2015', '2016',\n       'I) (2016', 'III) (2016', 'XVII) (2016', 'IV) (2016', 'V) (2016',\n       'X) (2016', 'II) (2016', 'VII) (2016', 'VI) (2016', '2017',\n       'I) (2017', 'II) (2017', 'III) (2017', 'IV) (2017', '2018',\n       'III) (2018', 'I) (2018', 'II) (2018', '2019', 'III) (2019',\n       'I) (2019', 'II) (2019', 'IV) (2019', '2020', 'I) (2020',\n       'II) (2020', 'VI) (2020', nan], dtype=object)\n\n\nData pulled from the website has phantom characters alongside the dates. Hence this would need some cleaning from our end to ensure all the dates are in consistent format.\n\ndf_movies.shape\n\n(11876, 5)\n\n\nI am using strip to loop each date entry in the dataset and strip off any residual characters which coincide with the those mentioned in the filter. Another option is to use replace in pandas using regex filters\n\ndf_movies['year'] = df_movies['year'].astype('str')\n\n\ndf_movies['year']=[i.strip('IIII) XVII) ( (  TV Special  TV Mov') for i in df_movies['year'].tolist()]\n\nPrinting the data again to check for the date entries:\n\ndf_movies['year'].unique()\n\narray(['1950', '1951', '1952', '1957', '1953', '1954', '1955', '1956',\n       '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965',\n       '1966', '1967', '1968', '1969', '1979', '1970', '1971', '1972',\n       '1973', '1974', '1975', '1976', '1977', '1978', '1980', '1981',\n       '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989',\n       '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997',\n       '1998', '2005', '1999', '2000', '2001', '2002', '2003', '2004',\n       '2007', '2006', '2008', '2009', '2012', '2010', '2011', '2013',\n       '2014', '2015', '2016', '2017', '2018', '2019', '2020', 'nan'],\n      dtype=object)\n\n\nConsistency check for the dataframe shape to ensure no funny business\n\ndf_movies.shape\n\n(11876, 5)"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#filtering-out-movies",
    "href": "posts/2020-08-23-imdb_bollywood.html#filtering-out-movies",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Filtering out movies",
    "text": "Filtering out movies\nSince IMDb is a fairly recent rating portal there are lot of movies especially those realeased pre 1980s which have low votes. Also IMDb lists every possible movie that was released in Hindi language. To better focus on credible movies I would filter out movies with low votes\n\nvotes_filter = df_movies['num_votes'] > 50 #Filter out movies which have got less than 100 votes from IMDb users \ndf_movies_filter_votes = df_movies.loc[votes_filter].reset_index(drop=True) #Reset the indices of the new dataframe and drop the old ones -- if not done a different column with old index is appended \n\n\ndf_movies_filter_votes.shape\n\n(3912, 5)"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#convert-year-data-entry-to-pandas-datetime-object-for-convenience",
    "href": "posts/2020-08-23-imdb_bollywood.html#convert-year-data-entry-to-pandas-datetime-object-for-convenience",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Convert year data entry to pandas Datetime object for convenience",
    "text": "Convert year data entry to pandas Datetime object for convenience\n\ndf_movies_filter_votes['year'] = pd.to_datetime(df_movies_filter_votes['year'],format='%Y').dt.year"
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#analyze-annual-movie-releases",
    "href": "posts/2020-08-23-imdb_bollywood.html#analyze-annual-movie-releases",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Analyze annual movie releases",
    "text": "Analyze annual movie releases\nDefining a separate dataframe for doing per-year analysis\n\nstat_list = ['year', 'total_movies_year', 'highest_rated_movie', 'movie_rating','avg_num_votes', 'avg_movie_rating']\nannual_movie_stats = {keys:[] for keys in stat_list} \n\nfor year_entry in df_movies_filter_votes['year'].unique():\n    per_year_column = df_movies_filter_votes.loc[df_movies_filter_votes['year'] == year_entry]\n    \n    try:\n        movie_entry_with_max_ratings = df_movies_filter_votes.loc[per_year_column['rating'].idxmax()]\n        higest_movie_rating = movie_entry_with_max_ratings['rating']\n        highest_rated_movie = movie_entry_with_max_ratings['name']\n        avg_movie_rating = per_year_column['rating'].mean()\n        total_movies = len(per_year_column)\n        avg_num_votes = per_year_column['num_votes'].mean()\n    except ValueError:\n        higest_movie_rating = np.nan\n        highest_rated_movie = np.nan\n        total_movies = np.nan\n        avg_movie_rating = np.nan \n    \n    annual_movie_stats['year'].append(year_entry)\n    annual_movie_stats['highest_rated_movie'].append(highest_rated_movie)\n    annual_movie_stats['movie_rating'].append(higest_movie_rating)\n    annual_movie_stats['avg_movie_rating'].append(avg_movie_rating)\n    annual_movie_stats['total_movies_year'].append(total_movies)\n    annual_movie_stats['avg_num_votes'].append(avg_num_votes)\n\n\ndf_annual_movie_stats = pd.DataFrame(annual_movie_stats, columns=annual_movie_stats.keys())\n\n\ndf_annual_movie_stats.sample(5)\n\n\n\n\n\n  \n    \n      \n      year\n      total_movies_year\n      highest_rated_movie\n      movie_rating\n      avg_num_votes\n      avg_movie_rating\n    \n  \n  \n    \n      49\n      1999\n      67\n      Sarfarosh\n      8.1\n      2201.328358\n      5.583582\n    \n    \n      3\n      1953\n      9\n      Do Bigha Zamin\n      8.4\n      293.000000\n      7.388889\n    \n    \n      69\n      2019\n      141\n      99 Songs\n      8.8\n      4041.056738\n      6.002128\n    \n    \n      9\n      1959\n      11\n      Kaagaz Ke Phool\n      8.0\n      329.454545\n      7.172727\n    \n    \n      34\n      1984\n      36\n      Saaransh\n      8.2\n      286.055556\n      6.427778\n    \n  \n\n\n\n\n\nfig, (ax1,ax2) = plt.subplots(2, 1, figsize=(30,20), sharex=True)\nyear_list = [\"'{}\".format(str(value)[2:]) for value in df_annual_movie_stats.year.to_list()]\nsns.barplot(x=year_list, y='total_movies_year', color='k', alpha=0.8, data=df_annual_movie_stats, ax=ax1)\nax1.set_ylabel('Average movies released')\n\nsns.scatterplot(year_list, 'avg_movie_rating', size='avg_num_votes', color='k', sizes=(40, 400), data=df_annual_movie_stats, ax=ax2);\nax2.set_xlabel('Year')\nax2.set_ylabel('Average movie rating')\nax2.get_legend()\nfor item in ax2.get_xticklabels():\n    item.set_rotation(45)\n    \nplt.tight_layout()\n\n/Users/pghaneka/miniconda3/envs/doodle/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn(\n\n\n\n\n\nThe two plots show the number of films released each year and the average IMDb rating for the movies released in that year. Now we might conclude that movies are getting selectively worse in spite of there being more movies being released, however the confidence in that statement is difficult to justify since the number of votes casted in these movies is an important parameter to keep in mind."
  },
  {
    "objectID": "posts/2020-08-23-imdb_bollywood.html#sort-the-movies-released-as-per-decades",
    "href": "posts/2020-08-23-imdb_bollywood.html#sort-the-movies-released-as-per-decades",
    "title": "Analyze Bollywood movie ratings (1950-2020)",
    "section": "Sort the movies released as per decades",
    "text": "Sort the movies released as per decades\nDefine a new column here as per decade to condense the analysis\n10 * (df_annual_movie_stats['year']//10)\nThis line converts years to a decade entry\n\ndf_annual_movie_stats['decade'] = 10 * (df_annual_movie_stats['year']//10)\n\n\ndf_annual_movie_stats_decade = df_annual_movie_stats.groupby(['decade']).mean()\n\n\ndf_annual_movie_stats_decade.sample(5)\n\n\n\n\n\n  \n    \n      \n      year\n      total_movies_year\n      movie_rating\n      avg_num_votes\n      avg_movie_rating\n    \n    \n      decade\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2000\n      2004.5\n      94.0\n      8.46\n      5160.443252\n      5.399690\n    \n    \n      2010\n      2014.5\n      126.2\n      8.44\n      6305.900985\n      5.748150\n    \n    \n      2020\n      2020.0\n      102.0\n      8.90\n      7485.009804\n      5.785294\n    \n    \n      1960\n      1964.5\n      17.6\n      8.15\n      326.809100\n      7.104778\n    \n    \n      1970\n      1974.5\n      30.4\n      8.18\n      820.688426\n      6.876870\n    \n  \n\n\n\n\n\ndf_annual_movie_stats_decade.index\n\nInt64Index([1950, 1960, 1970, 1980, 1990, 2000, 2010, 2020], dtype='int64', name='decade')\n\n\n\ndecade_list = [\"{}s\".format(str(value)[2:]) for value in df_annual_movie_stats_decade.index.to_list()]\n\n\nfig, (ax1,ax2) = plt.subplots(2, 1, figsize=(15,10), sharex=True)\n\nsns.barplot(x=decade_list, y='total_movies_year', data=df_annual_movie_stats_decade, color='k', alpha=0.8, ax=ax1)\nax1.set_ylabel('Average movies released annually')\n\nsns.scatterplot(decade_list, 'avg_movie_rating', size='avg_num_votes', sizes=(100, 400), data=df_annual_movie_stats_decade, ax=ax2);\nsns.despine()\n\nax2.set_xlabel('Decade')\nax2.set_ylabel('Average movie rating')\nax2.get_legend().remove()\n\nplt.tight_layout()\n\n/Users/pghaneka/miniconda3/envs/doodle/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n  warnings.warn("
  },
  {
    "objectID": "posts/2021-01-11-simple_dropout.html",
    "href": "posts/2021-01-11-simple_dropout.html",
    "title": "Estimating prediction confidence through dropout",
    "section": "",
    "text": "Adapted from Deep Learning online course notes from NYU. Note link\nPaper about using Dropout as a Bayesian Approximation\n\nAnother notebook which uses PyTorch dropout: Link\n\nNew paper on evidential deep learning for guided molecular property prediction\n\nIn addition to predicting a value from a model it is also important to know the confidence in that prediction. Dropout is one way of estimating this. After multiple rounds of predictions, the mean and standard deviation in the prediction can be viewed as the prediction value and the corresponding confidence in the prediction. It is important to note that this is different from the error in the prediction. The model may have error in the prediction but could be precise in that value. It is similar to the idea of accuracy vs precision.\nWhen done with dropout – the weights in the NN are scale by \\(\\frac{1}{1-r}\\) to account for dropping of the weights\nType of uncertainties: Aleaotric and Epistemic uncertainty\n\nAleatoric uncertainty captures noise inherent in the observations\nEpistemic uncertainty accounts for uncertainty in the model\n\nThe ideal way to measure epistemic uncertainty is to train many different models, each time using a different random seed and possibly varying hyperparameters. Then use all of them for each input and see how much the predictions vary. This is very expensive to do, since it involves repeating the whole training process many times. Fortunately, we can approximate the same effect in a less expensive way: by using dropout – effectively training a huge ensemble of different models all at once. Each training sample is evaluated with a different dropout mask, corresponding to a different random subset of the connections in the full model. Usually we only perform dropout during training and use a single averaged mask for prediction. But instead, let’s use dropout for prediction too. We can compute the output for lots of different dropout masks, then see how much the predictions vary. This turns out to give a reasonable estimate of the epistemic uncertainty in the outputs\n\nimport torch \nfrom torch import nn, optim\nimport numpy as np \n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n# Check if GPU present: \nprint(torch.cuda.device_count())\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\n0\ncpu\n\n\n\n# Training set\nm = 40\nx = (torch.rand(m) - 0.5) * 20 #Returns a tensor filled with random numbers from a uniform distribution on the interval [0, 1)\ny = x * torch.sin(x) \n#y = 2 * torch.exp( - torch.sin( (x/2)**2 ))\n\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.plot(x.numpy(), y.numpy(), 'o')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.axis('equal');\n\n\n\n\n\n# Define a simple NN \nclass MLP(nn.Module):\n    def __init__(self, hidden_layers=[20, 20], droprate=0.2, activation='relu'):\n        super(MLP, self).__init__()\n        \n        self.model = nn.Sequential()\n        self.model.add_module('input', nn.Linear(1, hidden_layers[0]))\n        \n        if activation == 'relu':\n            self.model.add_module('relu0', nn.ReLU())\n        \n        elif activation == 'tanh':\n            self.model.add_module('tanh0', nn.Tanh())\n            \n        for i in range(len(hidden_layers)-1):\n            self.model.add_module('dropout'+str(i+1), nn.Dropout(p=droprate))\n            self.model.add_module('hidden'+str(i+1), nn.Linear(hidden_layers[i], hidden_layers[i+1]))\n            \n            if activation == 'relu':\n                self.model.add_module('relu'+str(i+1), nn.ReLU())\n                \n            elif activation == 'tanh':\n                self.model.add_module('tanh'+str(i+1), nn.Tanh())\n                \n        self.model.add_module('dropout'+str(i+2), nn.Dropout(p=droprate))\n        self.model.add_module('final', nn.Linear(hidden_layers[i+1], 1))\n        \n    def forward(self, x):\n        return self.model(x)\n\n\n# Define the model \nnet = MLP(hidden_layers=[200, 100, 80], droprate=0.1).to(device) #Move model to the GPU \nprint(net)\n\nMLP(\n  (model): Sequential(\n    (input): Linear(in_features=1, out_features=200, bias=True)\n    (relu0): ReLU()\n    (dropout1): Dropout(p=0.1, inplace=False)\n    (hidden1): Linear(in_features=200, out_features=100, bias=True)\n    (relu1): ReLU()\n    (dropout2): Dropout(p=0.1, inplace=False)\n    (hidden2): Linear(in_features=100, out_features=80, bias=True)\n    (relu2): ReLU()\n    (dropout3): Dropout(p=0.1, inplace=False)\n    (final): Linear(in_features=80, out_features=1, bias=True)\n  )\n)\n\n\n\n# Objective and optimizer \ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=0.005, weight_decay=0.00001)\n\n\nx_dev = x.view(-1, 1).to(device)\n\n\n# Training loop \nfor epoch in range(6000):\n    x_dev = x.view(-1, 1).to(device)\n    y_dev = y.view(-1, 1).to(device)\n    y_hat = net(x_dev)\n    loss = criterion(y_hat, y_dev)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    if epoch % 500 == 0:\n        print('Epoch[{}] - Loss:{}'.format(epoch, loss.item()))\n\nEpoch[0] - Loss:12.69531536102295\nEpoch[500] - Loss:1.740363359451294\nEpoch[1000] - Loss:1.177356243133545\nEpoch[1500] - Loss:1.9534406661987305\nEpoch[2000] - Loss:1.0815060138702393\nEpoch[2500] - Loss:0.5457165837287903\nEpoch[3000] - Loss:0.24786725640296936\nEpoch[3500] - Loss:0.38788101077079773\nEpoch[4000] - Loss:0.7004671096801758\nEpoch[4500] - Loss:0.4352916181087494\nEpoch[5000] - Loss:0.5015718936920166\nEpoch[5500] - Loss:0.44577136635780334\n\n\nDefine a separate continuous vector XX\n\nXX = torch.linspace(-11, 11, 1000)\n\n\ndef predict_reg(model, X, T=10):\n    '''\n    Running the model in training mode. \n    model = torch.model: NN implemented in pytorch\n    X = torch.tensor: Input vector \n    T = int: number of samples run \n    \n    OUT:\n    Y_hat = sample of predictions from NN model\n    Y_eval = average prediction value from NN model\n    '''\n    \n    model = model.train()\n    Y_hat = list()\n    \n    with torch.no_grad():\n        for t in range(T):\n            X_out = model(X.view(-1,1).to(device))\n            Y_hat.append(X_out.cpu().squeeze())\n            \n    Y_hat = torch.stack(Y_hat)\n    \n    model = model.eval()\n    with torch.no_grad():\n        X_out = model(X.view(-1,1).to(device))\n        Y_eval = X_out.cpu().squeeze()\n\n    return Y_hat, Y_eval\n\n\n%%time \ny_hat, y_eval = predict_reg(net, XX, T=1000)\nmean_y_hat = y_hat.mean(axis=0)\nstd_y_hat = y_hat.std(axis=0)\n\nCPU times: user 11.9 s, sys: 94 ms, total: 12 s\nWall time: 3.04 s\n\n\n\n# Visualise mean and mean ± std -> confidence range\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nax.plot(XX.numpy(), mean_y_hat.numpy(), 'C1', label='prediction')\nax.fill_between(XX.numpy(), (mean_y_hat + std_y_hat).numpy(), (mean_y_hat - std_y_hat).numpy(), alpha=0.5, color='C2', label='confidence')\nax.plot(x.numpy(), y.numpy(), 'oC0', zorder=1, label='ground truth')\nax.plot(XX.numpy(), (XX * torch.sin(XX)).numpy(), 'k--', alpha=0.4, zorder=0, label='original function')\nax.set_title('Plotting the NN predictions and ground truth')\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.axis('equal')\nplt.legend(loc='best', fontsize=10)\n\n<matplotlib.legend.Legend at 0x7fb0b4eb73a0>\n\n\n\n\n\nThe plot above is the combination of ground truth points (blue), original function (grey) and the predicted function (orange) with corresponding confidence interval at each ML-prediction (green). It is seen that the ML model does well for the region of X in the range of original points. Another interesting observation is the uncertainity of the model prediction, which is seen to increase in the space where training points dont exist e.g. X=(5,10) and X > 10 or X < -10. This shows that the model is highly uncertain outside the domain of training data (extrapolation) but does a decent job within the range of training data (interpolation)."
  },
  {
    "objectID": "posts/2019-10-04-lambda_map.html",
    "href": "posts/2019-10-04-lambda_map.html",
    "title": "Lambda, Filter, and Map functions in Python",
    "section": "",
    "text": "Lambda is an important function/operator to create anonymous in-line functions in pyhton.\n\n\nlamda arguments: expression\n\n#This is our usual function where we have to define a name for the function\ndef func(x,y):\n    return(x+y)\nfunc(2,3)\n\n5\n\n\n\n#Lambda function \nadd=lambda x,y:x+y\nadd(2,3)\n\n5\n\n\nlambda functions can be used in place of a iterator when sorting – this allows for selecting the column or the varible according to which sorting has to be done\n\nimport numpy as np \nnp.random.seed(42)\na1=np.random.choice(10,5,replace=False)\nfile_list=[]\nfor i in a1: \n    file_list.append('{0}-{1}'.format('Filename',i))\n\n\nprint(file_list)\n\n['Filename-8', 'Filename-1', 'Filename-5', 'Filename-0', 'Filename-7']\n\n\n\nfile_list=sorted(file_list, key=lambda x:x.split('-')[-1])\n\n\nfile_list\n\n['Filename-0', 'Filename-1', 'Filename-5', 'Filename-7', 'Filename-8']"
  },
  {
    "objectID": "posts/2019-10-04-lambda_map.html#map",
    "href": "posts/2019-10-04-lambda_map.html#map",
    "title": "Lambda, Filter, and Map functions in Python",
    "section": "Map",
    "text": "Map\nWhen you want to have multiple outputs for the functions but do not want to write a for all explicitly you can use map function for pseeding things up\n\ndef square(x):\n    return(x**2)\n\nprint(a1)\nans=[square(i) for i in a1]\nprint(ans)\n\n[8 1 5 0 7]\n[64, 1, 25, 0, 49]\n\n\n\n#Using map function\nmap(square,a1)\n\n<map at 0x7f85058e5eb8>\n\n\n\n#You'd have to first converrt it to list \nlist(map(square,a1))\n\n[64, 1, 25, 0, 49]\n\n\n\nCombining the two:\n\na=np.random.choice(10,5,replace=False)\nb=np.random.choice(50,5,replace=False)\nresult=map(lambda x,y:x*y,a,b)\nprint(a)\nprint(b)\nprint(np.asarray(list(result)))\n\n[0 1 8 5 3]\n[36 16  4  9 45]\n[  0  16  32  45 135]"
  },
  {
    "objectID": "posts/10_04-fingerprints.html",
    "href": "posts/10_04-fingerprints.html",
    "title": "Fingerprints on fingertips",
    "section": "",
    "text": "Fingerprints are a low resolution representations of molecules. Historically they were devised, primarily, as a representation scheme to better estimate the similarity of molecules. Currently, besides the similairty and diversity estimations, fingerprints are the workhorses for most of the data-driven predictive models.\nKey papers in this field: * Willett, Peter, John M. Barnard, and Geoffrey M. Downs. “Chemical similarity searching.” Journal of chemical information and computer sciences 38.6 (1998): 983-996 * PubChem Atom Environments\nBlogs from Greg Landrum (RDKit creator): * Bit collisions in Rdkit * Simulating count fingerprints * Number of Fingerprint Bits * Number of unique fingerprint bits * RSC Open Science Standardization Talk\nResources to consider: * Depth-first on Fingerprints * Applied AI for materials online course by Logan Ward (Argonne National Lab) * Example scripts in GHOST implementation"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#morgan-fingerprints",
    "href": "posts/10_04-fingerprints.html#morgan-fingerprints",
    "title": "Fingerprints on fingertips",
    "section": "1. Morgan fingerprints",
    "text": "1. Morgan fingerprints\nSome discussion on Bit Collisions here: https://rdkit.blogspot.com/2014/02/colliding-bits.html"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#unfolded-type-or-sparse-type",
    "href": "posts/10_04-fingerprints.html#unfolded-type-or-sparse-type",
    "title": "Fingerprints on fingertips",
    "section": "Unfolded type or Sparse type",
    "text": "Unfolded type or Sparse type\n\nfrom rdkit.Chem import AllChem\nfrom rdkit import DataStructs\n\n\nmol_obj = x.iloc[42]['ROMol']\n\n\nmol_obj\n\n\n\n\n\n#Default class to generate FPs - this will make it unfolded by default\nmorgan_fp_default = AllChem.GetMorganFingerprint(mol_obj, radius = 2) # Counts are used by default \n\n\n#Check the use_counts in Get Morgan Fingerprint this is used by default \nmorgan_fp_default_counts = AllChem.GetMorganFingerprint(mol_obj, radius = 2, useCounts=True) # This is used by default \n\n#Feature-based invariants, similar to those used for the FCFP fingerprints, can also be used.\n# https://www.rdkit.org/docs/GettingStartedInPython.html#feature-definitions-used-in-the-morgan-fingerprints\n# Here the atoms are grouped into functional classes before substructures are enumerated \nmorgan_fp_features = AllChem.GetMorganFingerprint(mol_obj, 2, useFeatures=True)\n\n\nmorgan_fp_default\n\n<rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a80661ad0>\n\n\nYou can also use the rdMolDescriptor module in Rdkit for generating the fingerprints. What is the advatange of either?\n\nfrom rdkit.Chem import rdMolDescriptors\n\n\nmorgan_fp_default_rdmoldesc = rdMolDescriptors.GetMorganFingerprint(mol_obj, radius=2)\n\n\nmorgan_fp_default_rdmoldesc.GetNonzeroElements()\n\n{10565946: 3,\n 123085743: 1,\n 354000409: 1,\n 864942730: 3,\n 1451062712: 1,\n 2004727027: 2,\n 2119439498: 2,\n 2132511834: 2,\n 2142032900: 1,\n 2296493092: 2,\n 2422851564: 1,\n 2809361097: 2,\n 2968968094: 3,\n 2976816164: 1,\n 3038691098: 1,\n 3113921857: 2,\n 3217380708: 3,\n 3255046070: 1}\n\n\nTo get a list of bits being ‘active’ in the FPs:\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_default)\n\n{10565946: 3,\n 123085743: 1,\n 354000409: 1,\n 864942730: 3,\n 1451062712: 1,\n 2004727027: 2,\n 2119439498: 2,\n 2132511834: 2,\n 2142032900: 1,\n 2296493092: 2,\n 2422851564: 1,\n 2809361097: 2,\n 2968968094: 3,\n 2976816164: 1,\n 3038691098: 1,\n 3113921857: 2,\n 3217380708: 3,\n 3255046070: 1}\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_default) == morgan_fp_default_rdmoldesc.GetNonzeroElements()\n\nTrue\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetLength(morgan_fp_default)\n\n4294967295\n\n\n\n2**32\n\n4294967296\n\n\n\nmorgan_fp_default_counts\n\n<rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a8066e620>\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_default_counts)\n\n{10565946: 3,\n 123085743: 1,\n 354000409: 1,\n 864942730: 3,\n 1451062712: 1,\n 2004727027: 2,\n 2119439498: 2,\n 2132511834: 2,\n 2142032900: 1,\n 2296493092: 2,\n 2422851564: 1,\n 2809361097: 2,\n 2968968094: 3,\n 2976816164: 1,\n 3038691098: 1,\n 3113921857: 2,\n 3217380708: 3,\n 3255046070: 1}\n\n\n\nmorgan_fp_features\n\n<rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a8066e7b0>\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_features)\n\n{0: 7,\n 1: 2,\n 2: 3,\n 613660066: 1,\n 614173363: 2,\n 1250412363: 2,\n 2407443532: 1,\n 2419043133: 1,\n 3064147743: 1,\n 3205496824: 3,\n 3208849907: 1,\n 3664239091: 2,\n 3766528779: 2,\n 3766532888: 3,\n 4203103696: 1}\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetLength(morgan_fp_features)\n\n4294967295"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#folded-type",
    "href": "posts/10_04-fingerprints.html#folded-type",
    "title": "Fingerprints on fingertips",
    "section": "Folded type",
    "text": "Folded type\n\n#Counts Folded FPs \nmorgan_fp_counts_folded = AllChem.GetMorganFingerprint(mol_obj, 2, useCounts=True, nBits=1024) # This will throw an error - cannot fold the full FPs instead call them separately\n\nArgumentError: Python argument types in\n    rdkit.Chem.rdMolDescriptors.GetMorganFingerprint(Mol, int)\ndid not match C++ signature:\n    GetMorganFingerprint(RDKit::ROMol mol, unsigned int radius, boost::python::api::object invariants=[], boost::python::api::object fromAtoms=[], bool useChirality=False, bool useBondTypes=True, bool useFeatures=False, bool useCounts=True, boost::python::api::object bitInfo=None, bool includeRedundantEnvironments=False)\n\n\nCount-based Morgan FPs\n\n#Hashed FPs - using counts \nmorgan_fp_hashed_folded = AllChem.GetHashedMorganFingerprint(mol_obj, 2, nBits=1024) #Default is 2048 and be used without folding here \n\n\nmorgan_fp_hashed_folded\n\n<rdkit.DataStructs.cDataStructs.UIntSparseIntVect at 0x2b5a8066ef30>\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetLength(morgan_fp_hashed_folded)\n\n1024\n\n\n\nDataStructs.cDataStructs.UIntSparseIntVect.GetNonzeroElements(morgan_fp_hashed_folded)\n\n{4: 1,\n 36: 3,\n 90: 2,\n 138: 2,\n 243: 2,\n 314: 3,\n 321: 2,\n 356: 3,\n 440: 1,\n 537: 1,\n 650: 3,\n 713: 2,\n 794: 1,\n 926: 3,\n 943: 1,\n 950: 1,\n 1004: 1}\n\n\nBit-vector based Morgan FP\n\n#Folded FP bit vectors as per the size of the bits \nmorgan_fp_bit_vect = AllChem.GetMorganFingerprintAsBitVect(mol_obj, 2, nBits=1024)\n\n\nmorgan_fp_bit_vect\n\n<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a8066e4e0>\n\n\n\nDataStructs.cDataStructs.ExplicitBitVect.GetNumBits(morgan_fp_bit_vect)\n\n1024\n\n\n\nDataStructs.cDataStructs.ExplicitBitVect.GetNumOnBits(morgan_fp_bit_vect)\n\n17\n\n\n\nConverting to friendly data type\n\nmorgan_fp_hashed_folded_array = np.zeros((1,))\nmorgan_fp_bit_vect_array = np.zeros((1,))\n\n\nDataStructs.ConvertToNumpyArray(morgan_fp_hashed_folded, morgan_fp_hashed_folded_array) \n\n\nnp.nonzero(morgan_fp_hashed_folded_array)\n\n(array([   4,   36,   90,  138,  243,  314,  321,  356,  440,  537,  650,\n         713,  794,  926,  943,  950, 1004]),)\n\n\n\nnp.unique(morgan_fp_hashed_folded_array)\n\narray([0., 1., 2., 3.])\n\n\n\nmorgan_fp_bit_vect\n\n<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a8066e4e0>\n\n\n\nDataStructs.ConvertToNumpyArray(morgan_fp_bit_vect, morgan_fp_bit_vect_array) \n\n\nnp.nonzero(morgan_fp_bit_vect_array)\n\n(array([   4,   36,   90,  138,  243,  314,  321,  356,  440,  537,  650,\n         713,  794,  926,  943,  950, 1004]),)\n\n\n\nnp.unique(morgan_fp_bit_vect_array)\n\narray([0., 1.])\n\n\nConverting the Morgan FPs between counts and bit-wise representation: https://stackoverflow.com/questions/54809506/how-can-i-compute-a-count-morgan-fingerprint-as-numpy-array\n\nfp = AllChem.GetMorganFingerprintAsBitVect(mol_obj, 2, nBits=1024)\narray = np.zeros((0, ), dtype=np.int16)\nDataStructs.ConvertToNumpyArray(fp, array)\n\n\narray\n\narray([0, 0, 0, ..., 0, 0, 0], dtype=int16)\n\n\n\nbitstring = \"\".join(array.astype(str))\nfp2 = DataStructs.cDataStructs.CreateFromBitString(bitstring)\n\n\nfp2\n\n<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a80688b20>\n\n\n\nlist(fp.GetOnBits()) == list(fp2.GetOnBits())\n\nTrue\n\n\n\nfp3 = AllChem.GetHashedMorganFingerprint(mol_obj, 2, nBits=1024)\narray = np.zeros((0,), dtype=np.int8)\nDataStructs.ConvertToNumpyArray(fp3, array)\nprint(array.nonzero())\n\n(array([   4,   36,   90,  138,  243,  314,  321,  356,  440,  537,  650,\n        713,  794,  926,  943,  950, 1004]),)\n\n\nAlternate way:\n\ndef numpy_2_fp(array):\n    fp = DataStructs.cDataStructs.UIntSparseIntVect(len(array))\n    for ix, value in enumerate(array):\n        fp[ix] = int(value)\n    return fp\n\nfp4 = numpy_2_fp(array)\n\n\nfp3.GetNonzeroElements() == fp4.GetNonzeroElements()\n\nTrue"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#maccs",
    "href": "posts/10_04-fingerprints.html#maccs",
    "title": "Fingerprints on fingertips",
    "section": "2. MACCS",
    "text": "2. MACCS\nThere is a SMARTS-based implementation of the 166 public MACCS keys.\n\nfrom rdkit.Chem import MACCSkeys\n\n\nmaccs_fp = MACCSkeys.GenMACCSKeys(mol_obj)\n\n\nmaccs_fp\n\n<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5a99f013a0>\n\n\n\nmaccs_fp_array = np.zeros((0,))\n\n\nDataStructs.ConvertToNumpyArray(maccs_fp, maccs_fp_array) \n\n\nmaccs_fp_array.shape\n\n(167,)\n\n\n\nnp.nonzero(maccs_fp_array)\n\n(array([ 11,  37,  43,  53,  66,  77,  80,  89,  90,  91,  92,  97,  98,\n        105, 106, 110, 112, 117, 118, 120, 121, 127, 131, 136, 137, 142,\n        143, 146, 147, 151, 154, 156, 158, 159, 161, 163, 164, 165]),)\n\n\n\nnp.unique(maccs_fp_array)\n\narray([0., 1.])"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#atom-pairs",
    "href": "posts/10_04-fingerprints.html#atom-pairs",
    "title": "Fingerprints on fingertips",
    "section": "3. Atom Pairs",
    "text": "3. Atom Pairs\n\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\n\nap_full = Pairs.GetAtomPairFingerprint(mol_obj) # Fully unfolded ones  - The standard form is as fingerprint including counts for each bit instead of just zeros and ones\nap_bit = Pairs.GetAtomPairFingerprintAsBitVect(mol_obj) # Bit vector \nap_counts = Pairs.GetHashedAtomPairFingerprint(mol_obj, nBits=1024) #These are count based AP, default = 2048\n\n\nap_full\n\n<rdkit.DataStructs.cDataStructs.IntSparseIntVect at 0x2b5a9a0e82b0>\n\n\n\nDataStructs.cDataStructs.IntSparseIntVect.GetLength(ap_full)\n\n8388608\n\n\n\nDataStructs.cDataStructs.IntSparseIntVect.GetNonzeroElements(ap_full)\n\n{558145: 2,\n 558146: 1,\n 590913: 2,\n 590914: 1,\n 705602: 4,\n 705603: 2,\n 705604: 2,\n 705605: 1,\n 705665: 2,\n 705667: 1,\n 705890: 3,\n 1082435: 4,\n 1082436: 2,\n 1082498: 2,\n 1082721: 4,\n 1082723: 2,\n 1083458: 1,\n 1721411: 4,\n 1721412: 2,\n 1721413: 2,\n 1721414: 1,\n 1721474: 2,\n 1721476: 1,\n 1721697: 3,\n 1721699: 6,\n 1722434: 4,\n 1722436: 2,\n 1723684: 3}\n\n\n\nap_bit\n\n<rdkit.DataStructs.cDataStructs.SparseBitVect at 0x2b5a99f2ca70>\n\n\n\nap_bit_array = np.zeros((0,), dtype=np.int32)\n\n\nDataStructs.ConvertToNumpyArray(ap_bit, ap_bit_array) \n\nArgumentError: Python argument types in\n    rdkit.DataStructs.cDataStructs.ConvertToNumpyArray(SparseBitVect, numpy.ndarray)\ndid not match C++ signature:\n    ConvertToNumpyArray(RDKit::SparseIntVect<unsigned long> bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::SparseIntVect<unsigned int> bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::SparseIntVect<long> bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::SparseIntVect<int> bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(RDKit::DiscreteValueVect bv, boost::python::api::object destArray)\n    ConvertToNumpyArray(ExplicitBitVect bv, boost::python::api::object destArray)\n\n\n\nap_counts_array = np.array((1,))\n\n\nDataStructs.ConvertToNumpyArray(ap_counts, ap_counts_array) \n\n\nap_counts_array.shape\n\n(1024,)"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#rdkit-fingerprint",
    "href": "posts/10_04-fingerprints.html#rdkit-fingerprint",
    "title": "Fingerprints on fingertips",
    "section": "4. RDKIT Fingerprint",
    "text": "4. RDKIT Fingerprint\na Daylight-like fingerprint based on hashing molecular subgraphs\n\nrdkit_fp = Chem.RDKFingerprint(mol_obj) \n\n\nrdkit_fp\n\n<rdkit.DataStructs.cDataStructs.ExplicitBitVect at 0x2b5aa2582350>\n\n\n\nrdkit_fp_array = np.zeros((0,))\n\n\nDataStructs.ConvertToNumpyArray(rdkit_fp, rdkit_fp_array) \n\n\nnp.unique(rdkit_fp_array)\n\narray([0., 1.])"
  },
  {
    "objectID": "posts/10_04-fingerprints.html#descriptors",
    "href": "posts/10_04-fingerprints.html#descriptors",
    "title": "Fingerprints on fingertips",
    "section": "5. Descriptors",
    "text": "5. Descriptors\nCompute the RDKit2D fingerprint (200 topological properties) using the descriptastorus library. Adopted from https://github.com/rinikerlab/GHOST/blob/main/notebooks/library_example.ipynb\n\nfrom descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors\n\nCan be looped with different methods\nfps1 = [Chem.RDKFingerprint(x, fpSize=1024, minPath=1, maxPath=4) for x in suppl]\nfps2 = [Chem.GetHashedMorganFingerprint(x, radius=2, nBits=1024) for x in suppl]\nfps3 = [Chem.GetMorganFingerprint(x, radius=2, useCounts= True) for x in suppl]\nfps4 = [Pairs.GetAtomPairFingerprintAsIntVect(x) for x in suppl]\narr = np.zeros((4,1024), dtype = np.int8)\nfor i in range(0,len(suppl)):\n    DataStructs.ConvertToNumpyArray(fps2[i], arr[i])\nprint(arr)\n\nCombine it together\nGeneral purpose function to generate morgan fingerprints using BaseEstimator and TransformerMixin from Scikit-learn to use all the wonderful scikit-learn routines\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom rdkit.Chem import rdFingerprintGenerator\nfrom rdkit.Chem import AllChem\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import MACCSkeys\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\nfrom rdkit import DataStructs\nfrom rdkit.Chem import rdMolDescriptors\n\ndef mol_to_smiles(mol: Chem.Mol, canonical: bool = True) -> str:\n    \"\"\"Generate Smiles from mol.\n    :param mol: the input molecule\n    :param canonical: whether to return the canonical Smiles or not\n    :return: The Smiles of the molecule (canonical by default). NAN for failed molecules.\"\"\"\n\n    if mol is None:\n        return np.nan\n    try:\n        smi = Chem.MolToSmiles(mol, canonical=canonical)\n        return smi\n    except:\n        return np.nan\n\n\ndef smiles_to_mol(smiles: str) -> Chem.Mol:\n    \"\"\"Generate a RDKit Molecule from a Smiles.\n    :param smiles: the input string\n    :returns: The RDKit Molecule. If the Smiles parsing failed, NAN is returned instead.\n    \"\"\"\n\n    try:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol is not None:\n            return mol\n        return np.nan\n    except:\n        return np.nan\n    \ndef transform_to_mol(smiles: list, smiles_column : str = None, to_binary : bool = False) -> Chem.Mol:\n    \"\"\"\n    Converts a list of smiles to RDKit mol object. \n    Provision to preserve molecules in form a binary object\n    Refer: https://www.rdkit.org/docs/GettingStartedInPython.html#preserving-molecules\n    \"\"\"\n    \n    try: \n        if isinstance(smiles, list):\n            mol_ls = [Chem.MolFromSmiles(x) for x in smiles]\n            return mol_ls \n        \n        elif isinstance(smiles, pd.DataFrame):\n            smiles = smiles.copy() # To ensure I am using another instance \n            smiles[\"Mol\"] = smiles.apply(Chem.MolFromSmiles)\n            return smiles\n\n        elif isinstance(smiles, str):\n            mol_ls = Chem.MolFromSmiles(smiles)\n            return mol_ls \n        else: \n            return np.nan \n    except:\n        return np.nan \n    \n    if to_binary:\n        if type(smiles) == list:\n            binary_out = [mol.ToBinary() for mol in mol_ls] # m2 = Chem.Mol(binStr) to convert back \n        else:\n            binary_out = mol_ls.ToBinary() \n            \n        return binary_out \n\n\n    \n# Descriptor generation from RDKIT \n\ndef compute_fingerprint(smiles: str, type_fp: str = 'Morgan', sub_type: str = 'bv', radius: int = 2, num_bits: int = 2048) -> np.ndarray:\n    \"\"\"\n    Generates a fingerprint for a smiles string or mol object.\n    fp_type = {'Morgan', 'Morgan_sparse', 'FeatMorgan', 'FeatMorgan_sparse', 'AtomPair', 'AtomPair_sparse', 'RDkit', 'TT'}\n    sub_type = {'sparse', 'bv', 'counts', 'object'}\n    \n    :param smiles: A smiles string for a molecule.\n    :param radius: The radius of the fingerprint.\n    :param num_bits: The number of bits to use in the fingerprint.\n    :param use_counts: Whether to use counts or just a bit vector for the fingerprint\n    :return: A 1-D numpy array containing the morgan fingerprint.\n    \"\"\"\n    if isinstance(smiles, str):\n        mol = Chem.MolFromSmiles(smiles)\n \n    else:\n        mol = smiles\n    \n    if type_fp == 'Morgan': \n        if sub_type == 'sparse' or sub_type == 'object':\n            fp_vect = rdMolDescriptors.GetMorganFingerprint(mol, radius) # Counts by default\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n    \n    if type_fp == 'FeatMorgan':\n        if sub_type == 'sparse' or sub_type == 'object':\n            fp_vect = rdMolDescriptors.GetMorganFingerprint(mol, radius, useFeatures=True)\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedMorganFingerprint(mol, radius, nBits=num_bits, useFeatures=True)\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits, useFeatures=True)\n    \n    if type_fp == 'AtomPair':\n        if sub_type == 'sparse' or sub_type == 'object':\n            fp_vect = rdMolDescriptors.GetAtomPairFingerprint(mol)\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedAtomPairFingerprint(mol, nBits=num_bits)\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=num_bits)\n        \n    if type_fp == 'MACCS': \n        fp_vect = MACCSkeys.GenMACCSKeys(mol)\n        \n    if type_fp == 'Rdkit':\n        fp_vect = Chem.RDKFingerprint(mol)\n    \n    if type_fp == 'TT':\n        if sub_type == 'counts':\n            fp_vect = rdMolDescriptors.GetHashedTopologicalTorsionFingerprint(mol, nBits=num_bits) #2048 by default\n        if sub_type == 'bv':\n            fp_vect = rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(mol, nBits=num_bits)\n            \n    # Compute the RDKit2D fingerprint (200 topological properties) using the descriptastorus library\n    # Adopted from https://github.com/rinikerlab/GHOST/blob/main/notebooks/library_example.ipynb\n    if type_fp == 'Rdkit2D' or type_fp == 'Rdkit2D_norm':\n        try:\n            from descriptastorus.descriptors import rdDescriptors, rdNormalizedDescriptors\n            generator =  rdNormalizedDescriptors.RDKit2DNormalized() if type_fp == 'Rdkit2D_norm' else rdDescriptors.RDKit2D()\n\n            # process needs input as smiles\n            assert isinstance(smiles, str)\n            \n            smi = smiles \n            data = generator.process(smi)\n            \n            if data[0] == True:\n                data.pop(0)\n            if data[0] == False:\n                data.pop(0)\n                \n            data = np.float32(data)\n            data[np.isposinf(data)] = np.finfo('float32').max\n            data[np.isneginf(data)] = np.finfo('float32').min\n            fp_vect = np.nan_to_num(data)\n\n        except:\n            print('Failed to process the smiles using RDKit 2D features.')        \n            fp_vect = np.zeros(shape=(200))\n        \n    if sub_type == 'object':\n        return fp_vect \n    \n    elif sub_type == 'sparse':\n        try:\n            key_dict, len_arry = fp_vect.GetNonzeroElements() , fp_vect.GetLength()\n            sparse_row = np.zeros(len(list(key_dict.keys())))\n            sparse_col = np.array(list(key_dict.keys()))\n            sparse_data = np.array(list(key_dict.values()), dtype=np.int16)\n            fp = sp.sparse.csr_matrix((sparse_data, (sparse_row, sparse_col)), shape=(1, len_arry))\n            assert isinstance(fp, sp.sparse.csr_matrix)\n            \n        except: \n            key_dict, len_arry = fp_vect.GetNumOnBits(), fp_vect.GetNumBits()\n            key_dict, len_arry = fp\n            sparse_row = np.zeros(len(list(key_dict.keys())))\n            sparse_col = np.array(list(key_dict.keys()))\n            sparse_data = np.array(list(key_dict.values()), dtype=np.int16)\n            fp = sp.sparse.csr_matrix((sparse_data, (sparse_row, sparse_col)), shape=(1, len_arry))\n            assert isinstance(fp, sp.sparse.csr_matrix)\n\n    else:\n        try: \n            fp = np.zeros((0,), dtype=np.int16)\n            DataStructs.ConvertToNumpyArray(fp_vect, fp)\n        except: \n            fp = fp_vect \n    return fp\n\n## Have a dataframe output like Logan Ward does? \n\nclass FingerprintTransformer(BaseEstimator):\n    \"\"\"Class that converts SMILES strings to fingerprint vectors\"\"\"\n    \n    def __init__(self, smiles_column: str = 'SMILES', type_fp: str = 'Morgan', sub_type: str = 'bv', radius: int = 2, num_bits: int = 1024):\n        self.smiles_column = smiles_column\n        self.type_fp = type_fp\n        self.sub_type = sub_type \n        self.num_bits = num_bits\n        self.radius = radius\n    \n    def fit(self, X, y=None):\n        return self  # Do need to do anything\n    \n    def transform(self, X, y=None):\n        \"\"\"\n        Compute the fingerprints\n        :param X: List of SMILES strings\n        :return: Array of fingerprints\n        \"\"\"\n        if isinstance(X, list):\n            X_input = transform_to_mol(X) if isinstance(X[0], Chem.Mol) else X\n            fing = [ compute_fingerprint(m, type_fp = self.type_fp, sub_type = self.sub_type, radius = self.radius, num_bits = self.num_bits) for m in X_input ]\n            return np.vstack(fing)\n        \n        elif isinstance(X, pd.DataFrame): \n            \n            X = X.copy() # To ensure I am changing a separate array instance \n            X_mol_list = list(X[self.smiles_column])\n            fing = []\n\n            for i, entry in enumerate(X_mol_list):\n                fing.append( compute_fingerprint(entry, type_fp = self.type_fp, sub_type = self.sub_type, radius = self.radius, num_bits = self.num_bits) )\n            \n            if self.type_fp == 'Rdkit2D' or self.type_fp == 'Rdkit2D_norm':\n                X['{0}'.format(self.type_fp)] = fing\n            else: \n                X['{0}-{1}'.format(self.type_fp, self.sub_type)] = fing\n            return X\n        \n        else: #If it is a single entry \n            X_mol = X if isinstance(X, str) else transform_to_mol(X)\n            fing = compute_fingerprint(X_mol, type_fp = self.type_fp, sub_type = self.sub_type, radius = self.radius, num_bits = self.num_bits)\n            return fing\n\n\nfp_transform = FingerprintTransformer(num_bits=1024,\n radius=3,\\\n smiles_column = 'SMILES',\\\n sub_type = 'counts',\\\n type_fp = 'Morgan')\n\n\nfp_transform.get_params()\n\n{'num_bits': 1024,\n 'radius': 3,\n 'smiles_column': 'SMILES',\n 'sub_type': 'counts',\n 'type_fp': 'Morgan'}\n\n\n\nx_fp = fp_transform.transform(x)\n\n\nx_fp.sample(3)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      logP\n      ROMol\n      Morgan-counts\n    \n  \n  \n    \n      846\n      O=C1CNC(=O)N1\n      -0.40\n      \n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n    \n    \n      159\n      Cc1ccc(Cl)cc1\n      -3.08\n      \n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n    \n    \n      502\n      Cn2c(=O)on(c1ccc(Cl)c(Cl)c1)c2=O\n      -2.82\n      \n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "",
    "text": "Walkthrough on reading, visualizing, manipulating molecules and their properties using Pandas and RDKit for Cheminformatics-related tasks. In this file we will be primarly using SMILES to describe the molecules of choice."
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#install-necessary-modules",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#install-necessary-modules",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Install necessary modules",
    "text": "Install necessary modules\n\n# collapse_output\n# Install requirements for the tutorial\n!pip install pandas rdkit-pypi mols2grid matplotlib scikit-learn ipywidgets\n\nRequirement already satisfied: pandas in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (1.3.4)\nRequirement already satisfied: rdkit-pypi in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (2021.9.2.1)\nRequirement already satisfied: mols2grid in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (0.1.0)\nRequirement already satisfied: matplotlib in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (3.5.1)\nRequirement already satisfied: scikit-learn in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (1.0.2)\nRequirement already satisfied: pytz>=2017.3 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from pandas) (2021.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: numpy>=1.21.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from pandas) (1.21.4)\nRequirement already satisfied: jinja2 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from mols2grid) (3.0.3)\nRequirement already satisfied: pillow>=6.2.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (8.4.0)\nRequirement already satisfied: cycler>=0.10 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (3.0.6)\nRequirement already satisfied: fonttools>=4.22.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (4.28.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: packaging>=20.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: joblib>=0.11 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from scikit-learn) (1.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from scikit-learn) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: six>=1.5 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /Users/pghaneka/miniconda3/envs/small_mols/lib/python3.10/site-packages (from jinja2->mols2grid) (2.0.1)\n\n\n\nimport os \nimport pandas as pd\nimport numpy as np \n\nThe majority of the basic molecular functionality is found in module rdkit.Chem\n\n# RDkit imports\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.2\n\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 15,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 12,\n'ytick.labelsize' : 12,\n}\n \nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#basics",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#basics",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Basics",
    "text": "Basics\n\n# Beneze molecule using SMILES representation\nmol = Chem.MolFromSmiles(\"c1ccccc1\")\n\nmol is a special type of RDkit object\n\ntype(mol)\n\nrdkit.Chem.rdchem.Mol\n\n\nTo display the molecule:\n\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\nBy default SMILES (atleast the ones we deal with RDkit) accounts H atoms connected with C atoms implicitly based on the valence of the bond. You can add H explicitly using the command below:\n\nChem.AddHs(mol)\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChem.RemoveHs(mol)\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Convenience function to get atom index\ndef mol_with_atom_index(mol):\n    for atom in mol.GetAtoms():\n        atom.SetAtomMapNum(atom.GetIdx())\n    return mol\n\n\n# With atom index\nmol_with_atom_index(mol)\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Another option using in-built index for atoms \nIPythonConsole.drawOptions.addAtomIndices = True\nmol = Chem.MolFromSmiles(\"c1ccccc1\")\nmol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptors for molecules\nWe can find more information about the molecule using rdkit.Chem.Descriptors : More information here\n\nfrom rdkit.Chem import Descriptors\n\n\n# To get molecular weight\nmol_wt = Descriptors.ExactMolWt(mol)\nprint('Mol Wt: {:0.3f}'.format(mol_wt))\n\nMol Wt: 78.047\n\n\n\n# To get heavy atom weight, this ignore H atoms \nheavy_mol_wt = Descriptors.HeavyAtomMolWt(mol)\nprint('Heavy Mol Wt: {:0.3f}'.format(heavy_mol_wt))\n\nHeavy Mol Wt: 72.066\n\n\n\n# To get number of rings \nring_count = Descriptors.RingCount(mol)\nprint('Number of rings: {:0.3f}'.format(ring_count))\n\nNumber of rings: 1.000\n\n\n\n# To get number of rotational bonds \nrotatable_bonds = Descriptors.NumRotatableBonds(mol)\nprint('Number of rotatable bonds: {:0.3f}'.format(rotatable_bonds))\n\nNumber of rotatable bonds: 0.000\n\n\n\n# To get number of rings \nnum_aromatic_rings = Descriptors.NumAromaticRings(mol)\nprint('Number of aromatic rings: {:0.3f}'.format(num_aromatic_rings))\n\nNumber of aromatic rings: 1.000\n\n\nGet some more information about the molecule:\nMolToMolBlock: To get Coordinates and bonding details for the molecule. More details on this file type can be found here\n\nmol_block = Chem.MolToMolBlock(mol)\nprint(mol_block)\n\n\n     RDKit          2D\n\n  6  6  0  0  0  0  0  0  0  0999 V2000\n    1.5000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.7500   -1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -0.7500   -1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -1.5000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n   -0.7500    1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n    0.7500    1.2990    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n  1  2  2  0\n  2  3  1  0\n  3  4  2  0\n  4  5  1  0\n  5  6  2  0\n  6  1  1  0\nM  END\n\n\n\n\nmol"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#little-more-on-the-molecule-drawing",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#little-more-on-the-molecule-drawing",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Little more on the molecule drawing",
    "text": "Little more on the molecule drawing\nAdditional discussion on different ways to represnt and draw molecules in RDkit. This section will work in RDkit version > 2020.03.\nI am following the code introduced in the official RDkit blogpost\n\nNice example found on Pen’s blogpost\n\n\nfrom collections import defaultdict\nfrom rdkit.Chem.Draw import rdMolDraw2D\nfrom IPython.display import SVG\n\n\ndiclofenac = Chem.MolFromSmiles('O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl')\ndiclofenac\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubstructure highlights:\nLet’s look at the the C=O and the -NH species in the molecule\n\n# Code from : https://www.rdkit.org/docs/GettingStartedInPython.html?highlight=maccs#drawing-molecules\nsub_pattern = Chem.MolFromSmarts('O=CCccN')\nhit_ats = list(diclofenac.GetSubstructMatch(sub_pattern))\nhit_bonds = []\n\nfor bond in sub_pattern.GetBonds():\n    aid1 = hit_ats[bond.GetBeginAtomIdx()]\n    aid2 = hit_ats[bond.GetEndAtomIdx()]\n    \n    hit_bonds.append( diclofenac.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n\nd2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\nrdMolDraw2D.PrepareAndDrawMolecule(d2d, diclofenac, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\nd2d.FinishDrawing()\nSVG(d2d.GetDrawingText())\n\n\n\n\nSpecify individual color and bonds\n\nrings = diclofenac.GetRingInfo()\ntype(rings)\n\nrdkit.Chem.rdchem.RingInfo\n\n\n\n# Code from: http://rdkit.blogspot.com/2020/04/new-drawing-options-in-202003-release.html\n    \ncolors = [(0.8,0.0,0.8),(0.8,0.8,0),(0,0.8,0.8),(0,0,0.8)]\n\nathighlights = defaultdict(list)\narads = {}\n\nfor i,rng in enumerate(rings.AtomRings()):\n    for aid in rng:\n        athighlights[aid].append(colors[i])\n        arads[aid] = 0.3\n\nbndhighlights = defaultdict(list)\nfor i,rng in enumerate(rings.BondRings()):\n    for bid in rng:\n        bndhighlights[bid].append(colors[i])\n\n\nd2d = rdMolDraw2D.MolDraw2DSVG(400,400)\nd2d.DrawMoleculeWithHighlights(diclofenac,'diclofenac',dict(athighlights),dict(bndhighlights),arads,{})\nd2d.FinishDrawing()\nSVG(d2d.GetDrawingText())"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#reading-dataset-of-molecules-from-a-csv-file",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#reading-dataset-of-molecules-from-a-csv-file",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Reading dataset of molecules from a csv file",
    "text": "Reading dataset of molecules from a csv file\nHere we will use Pandas, RDkit to make molecule object for the small sample of molecules."
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#sample-data",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#sample-data",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Sample data",
    "text": "Sample data\n\nsample_df = pd.read_csv('https://raw.githubusercontent.com/pgg1610/data_files/main/simple_sample_molecules.csv',  sep=',')\n\n\nsample_df.head(5)\n\n\n\n\n\n  \n    \n      \n      Name\n      SMILE\n    \n  \n  \n    \n      0\n      Cyclopropane\n      C1CC1\n    \n    \n      1\n      Ethylene\n      C=C\n    \n    \n      2\n      Methane\n      C\n    \n    \n      3\n      t-Butanol\n      CC(C)(C)O\n    \n    \n      4\n      ethane\n      CC\n    \n  \n\n\n\n\n\nsample_df.shape\n\n(115, 2)\n\n\n\n# Adding to Pandas dataframe\nfrom rdkit.Chem import PandasTools\n\nPandasTools module helps add mol molecule objects from RDKit as per the SMILES in the dataframe\n\nPandasTools.AddMoleculeColumnToFrame(sample_df, smilesCol='SMILE')\n\nCheck the new ROMol columns being appended in the dataframe\n\nsample_df.columns\n\nIndex(['Name', 'SMILE', 'ROMol'], dtype='object')\n\n\n\nsample_df.head(1)\n\n\n\n\n\n  \n    \n      \n      Name\n      SMILE\n      ROMol\n    \n  \n  \n    \n      0\n      Cyclopropane\n      C1CC1\n      \n    \n  \n\n\n\n\nVisualize the dataframe, add properties of interest at the bottom, you can add index too if need\n\nPandasTools.FrameToGridImage(sample_df[:20], legendsCol='Name', molsPerRow=4)\n\n\n\n\n\nQuickly sort / search the dataset using a substructure search\n\nsub_pattern_to_match = Chem.MolFromSmarts('C(=O)N')\nsub_pattern_to_match\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmatch_df = pd.DataFrame()\nfor index, row in sample_df.iterrows():\n    mol = Chem.MolFromSmiles(row['SMILE'])\n    mol_sub_match = mol.HasSubstructMatch(sub_pattern_to_match)\n    if mol_sub_match == True: \n        match_df = match_df.append(row)\n\n\nPandasTools.FrameToGridImage(match_df, legendsCol='Name', molsPerRow=4)\n\n\n\n\n\n\nLogP Dataset\n(From Wikipedia) The partition coefficient, abbreviated P, is defined as the ratio of the concentrations of a solute between two immisible solvents at equilibrium. Most commonly, one of the solvents is water, while the second is hydrophobic, such as 1-octanol.\n\\[\\log P_\\text{oct/wat} = \\log\\left(\\frac{\\big[\\text{solute}\\big]_\\text{octanol}^\\text{un-ionized}}{\\big[\\text{solute}\\big]_\\text{water}^\\text{un-ionized}}\\right)\\]\nHence the partition coefficient measures how hydrophilic (“water-loving”) or hydrophobic (“water-fearing”) a chemical substance is. Partition coefficients are useful in estimating the distribution of drugs within the body. Hydrophobic drugs with high octanol-water partition coefficients are mainly distributed to hydrophobic areas such as lipid bilayers of cells. Conversely, hydrophilic drugs (low octanol/water partition coefficients) are found primarily in aqueous regions such as blood serum.\nThe dataset used in this notebook is obtained from Kaggle. This dataset features relatively simple molecules along with their LogP value. This is a synthetic dataset created using XLogP and does not contain experimental validation.\n\nlogP_df = pd.read_csv('https://raw.githubusercontent.com/pgg1610/data_files/main/logP_dataset.csv', sep=',', header=None, names=['SMILES', 'LogP'])\n\n\nlogP_df.head(5)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      LogP\n    \n  \n  \n    \n      0\n      C[C@H]([C@@H](C)Cl)Cl\n      2.3\n    \n    \n      1\n      C(C=CBr)N\n      0.3\n    \n    \n      2\n      CCC(CO)Br\n      1.3\n    \n    \n      3\n      [13CH3][13CH2][13CH2][13CH2][13CH2][13CH2]O\n      2.0\n    \n    \n      4\n      CCCOCCP\n      0.6\n    \n  \n\n\n\n\n\nlogP_df.shape\n\n(14610, 2)\n\n\n\n\nVisualize the SMILE string\n\nmol_temp = logP_df.iloc[420]\n\n\nmol_temp\n\nSMILES    [2H][C]([2H])[Cl+]Cl\nLogP                       1.6\nName: 420, dtype: object\n\n\n\nmol_obj = Chem.MolFromSmiles(mol_temp['SMILES'])\nmol_obj\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# To output x y z of the molecule \nprint(Chem.MolToMolBlock(mol_obj))\n\n\n     RDKit          2D\n\n  5  4  0  0  0  0  0  0  0  0999 V2000\n    1.2990    0.7500    0.0000 H   0  0  0  0  0  0  0  0  0  0  0  0\n    0.0000    0.0000    0.0000 C   0  0  0  0  0  3  0  0  0  0  0  0\n   -1.2990    0.7500    0.0000 H   0  0  0  0  0  0  0  0  0  0  0  0\n   -0.0000   -1.5000    0.0000 Cl  0  0  0  0  0  2  0  0  0  0  0  0\n   -1.2990   -2.2500    0.0000 Cl  0  0  0  0  0  0  0  0  0  0  0  0\n  1  2  1  0\n  2  3  1  0\n  2  4  1  0\n  4  5  1  0\nM  CHG  1   4   1\nM  RAD  1   2   2\nM  ISO  2   1   2   3   2\nM  END\n\n\n\nTake a small sample from QM9 dataset\n\nlogP_df_smol = logP_df.sample(20).reset_index(drop=True)\n\n\nlogP_df_smol.head(2)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      LogP\n    \n  \n  \n    \n      0\n      C(CCCN)CCN\n      -0.2\n    \n    \n      1\n      CC(CF)CBr\n      2.1\n    \n  \n\n\n\n\n\nlogP_df_smol.shape\n\n(20, 2)\n\n\nPandasTools module helps add mol molecule objects from RDKit as per the SMILES in the dataframe\n\nPandasTools.AddMoleculeColumnToFrame(logP_df_smol, smilesCol='SMILES')\n\nCheck the new ROMol columns being appended in the dataframe\n\nlogP_df_smol.columns\n\nIndex(['SMILES', 'LogP', 'ROMol'], dtype='object')\n\n\n\nlogP_df_smol['ROMol'][0]\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualize the dataframe, add properties of interest at the bottom, you can add index too if need\n\nimport mols2grid \n\n\n#collapse_output\n#mols2grid.display(logP_df_smol['ROMol'])\n\n\nPandasTools.FrameToGridImage(logP_df_smol, legendsCol='LogP', molsPerRow=3, subImgSize=(200,200))"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#vanilla-linear-regression",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#vanilla-linear-regression",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Vanilla linear regression",
    "text": "Vanilla linear regression\nLet’s try building a model to predict a molecule’s logP value given other descriptors. We will try simple molecular descriptors and check the performance. Some molecule discriptors we will consider: 1. Molecular weight 2. Number of rotatable bonds 3. Number of aromatic compounds\n\nlogP_df.head(4)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      LogP\n    \n  \n  \n    \n      0\n      C[C@H]([C@@H](C)Cl)Cl\n      2.3\n    \n    \n      1\n      C(C=CBr)N\n      0.3\n    \n    \n      2\n      CCC(CO)Br\n      1.3\n    \n    \n      3\n      [13CH3][13CH2][13CH2][13CH2][13CH2][13CH2]O\n      2.0\n    \n  \n\n\n\n\nAs before we will first convert the SMILES string into a rdkit.Chem.rdchem.Mol object, let’s write a convenience function to do so\n\n# Getting count of aromatic elements \n_count = 0\nfor i in range(mol.GetNumAtoms()):\n    if mol.GetAtomWithIdx(i).GetIsAromatic():\n        _count = _count + 1\nprint(_count)\n\n6\n\n\n\ndef generate_variables(smiles_list):\n    \n    variable_array = {'SMILES':[], 'ROMol':[], 'Mol_Wt':[],'Num_Aromatic_rings':[], 'Num_rotate_bonds':[], 'Ratio_Aromatic':[], 'Valence_electrons':[]} \n    \n    for smile_entry in smiles_list: \n        mol_object = Chem.MolFromSmiles(smile_entry)\n        \n        mol_wt = Descriptors.MolWt(mol_object)\n        mol_aromatic_rings = Descriptors.NumAromaticRings(mol_object)\n        mol_rotatable_bonds = Descriptors.NumRotatableBonds(mol_object)\n        \n        # Calculate % of aromatic atoms in the compd\n        mol_num_heavy_atom = Descriptors.HeavyAtomCount(mol_object)\n        \n        _count_aromatic = 0 \n        for i in range(mol_object.GetNumAtoms()):\n            if mol_object.GetAtomWithIdx(i).GetIsAromatic() == True:\n                _count_aromatic = _count_aromatic + 1 \n        \n        mol_aromatic_ratio = _count_aromatic / mol_num_heavy_atom\n        \n        mol_val_electrons = Descriptors.NumValenceElectrons(mol_object)\n        \n        variable_array['SMILES'].append(smile_entry)\n        variable_array['ROMol'].append(mol_object)\n        variable_array['Mol_Wt'].append(mol_wt)\n        variable_array['Num_Aromatic_rings'].append(mol_aromatic_rings)\n        variable_array['Num_rotate_bonds'].append(mol_rotatable_bonds)\n        variable_array['Ratio_Aromatic'].append(mol_aromatic_ratio)\n        variable_array['Valence_electrons'].append(mol_val_electrons)\n        \n    return variable_array\n\n\nLook at a subset from the total logP data\n\nlogP_df.shape\n\n(14610, 2)\n\n\n\n# Look at random 10_000 entries to keep the analysis tractable \ndf_10k = logP_df.sample(10_000, random_state=42)\n\n\nvariable_dict = generate_variables(df_10k.SMILES)\nvariable_df = pd.DataFrame(variable_dict, columns=variable_dict.keys())\n\n\ndf_var_10k = df_10k.merge(variable_df, on='SMILES')\ndf_var_10k.head(2)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      LogP\n      ROMol\n      Mol_Wt\n      Num_Aromatic_rings\n      Num_rotate_bonds\n      Ratio_Aromatic\n      Valence_electrons\n    \n  \n  \n    \n      0\n      CNCSC\n      0.5\n      \n      91.179\n      0\n      2\n      0.0\n      32\n    \n    \n      1\n      CNCSC=C\n      1.0\n      \n      103.190\n      0\n      3\n      0.0\n      36\n    \n  \n\n\n\n\n\n\nSetup model\n\ndf_var_10k.columns\n\nIndex(['SMILES', 'LogP', 'ROMol', 'Mol_Wt', 'Num_Aromatic_rings',\n       'Num_rotate_bonds', 'Ratio_Aromatic', 'Valence_electrons'],\n      dtype='object')\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\ndf_var_10k.hist(ax = ax);\n\n/var/folders/_r/6hhq_8ps5118p6sqqz231j480000gq/T/ipykernel_26421/2485801931.py:2: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n  df_var_10k.hist(ax = ax);\n\n\n\n\n\nSplit into train and validation set\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df_var_10k, test_size=0.3, random_state=42)\n\n\nprint(df_train.shape, df_test.shape)\n\n(7000, 8) (3000, 8)\n\n\nDrop some columns that arent that useful for prediction\n\nX_train = df_train.drop(columns = ['LogP','ROMol','SMILES', 'Ratio_Aromatic', 'Num_Aromatic_rings']).values\ny_train = df_train.LogP.values\n\nPre-process input data to normalize the scale of the descriptors\n\n# Standard Scaling X\nstd_scaler_X = StandardScaler()\nX_train_std = std_scaler_X.fit_transform(X_train)\n\n\nfrom sklearn.linear_model import LinearRegression\n\n\nmodel = LinearRegression()\nmodel.fit(X_train_std, y_train)\n\nLinearRegression()\n\n\n\n# predict use the trained model -- we are still using training set here \ny_pred = model.predict(X_train_std)\n\n\nplt.scatter(y_train, y_pred, alpha=0.6)\nplt.xlabel('True Value')\nplt.ylabel('Predicted')\n\nText(0, 0.5, 'Predicted')\n\n\n\n\n\n\n# Fancier looking plot \nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_train, y_pred, alpha=0.6, label='Linear Regression')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_train, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best');\n\n\n\n\n\n\nEvaluate model success\nOne of the simplest ways we can evaluate the success of a linear model is using the coefficient of determination (R2) which compares the variation in y alone to the variation remaining after we fit a model. Another way of thinking about it is comparing our fit line with the model that just predicts the mean of y for any value of x.\nAnother common practice is to look at a plot of the residuals to evaluate our ansatz that the errors were normally distributed.\nIn practice, now that we have seen some results, we should move on to try and improve the model. We won’t do that here, but know that your work isn’t done after your first model (especially one as cruddy as this one). It’s only just begun!\nCalculate R2 using: \\[R^2 =1 -  \\frac{\\sum (y_i - \\hat{y})^2}{\\sum (y_i - \\bar{y})^2}\\]\n\n# R2 score evaluation\nSS_residuals = np.sum( (y_train - y_pred)**2 ) \nSS_total = np.sum( (y_train - np.mean(y_train))**2 )\nr2 = 1 - SS_residuals / SS_total\nprint(r2)\n\n0.13532814881109834\n\n\n\nfrom sklearn.metrics import r2_score\nprint('R2 score: {}'.format(r2_score(y_train, y_pred)))\n\nR2 score: 0.13532814881109834"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#using-ensemble-based-model",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#using-ensemble-based-model",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Using ensemble-based model",
    "text": "Using ensemble-based model\n\nfrom sklearn.ensemble import RandomForestRegressor\n\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train_std, y_train)\n\nRandomForestRegressor()\n\n\n\ny_pred = model.predict(X_train_std)\n\n\n# Fancier looking plot \nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_train, y_pred, alpha=0.6, label='Linear Regression')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_train, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best');\n\n\n\n\n\ndef display_performance(y_true, y_pred):\n    from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n    r2 = r2_score(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    print('R2: {0:0.2f}\\n'\n          'MAE: {1:0.2f}\\n'\n          'RMSE: {2:0.2f}'.format(r2, mae, rmse))\n    return(r2, mae, rmse)\n\n\ndisplay_performance(y_train,y_pred);\n\nR2: 0.91\nMAE: 0.29\nRMSE: 0.40"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#fingerprints",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#fingerprints",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Fingerprints",
    "text": "Fingerprints\nCompress molecules into vectors for mathetical operations and comparisons. First we will look at MorganFingerprint method. For this method we have to define the radius and the size of the vector being used.\nMore information on different Circular Fingerprints can be read at this blogpost. Highly recommended\n\nPresentation by Gregory Landrum (creator of RDkit) on Fingerprints\nRDkit Blog entry of visualizing the fingerprint bitvectors. Using the new fingerprint bit rendering code\n\n\n# Fingerprints\nfrom rdkit.Chem import AllChem\n\n\nradius = 2 # How far from the center node should we look at? \necfp_power = 10 # Size of the fingerprint vectors  \nECFP = [ np.array(AllChem.GetMorganFingerprintAsBitVect(m, radius, nBits = 2**ecfp_power)) for m in df_train['ROMol'] ]\n\n\nlen(ECFP)\n\n7000\n\n\n\ndf_train['ECFP'] = ECFP\n\n\ndf_train.sample(2)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      LogP\n      ROMol\n      Mol_Wt\n      Num_Aromatic_rings\n      Num_rotate_bonds\n      Ratio_Aromatic\n      Valence_electrons\n      ECFP\n    \n  \n  \n    \n      6160\n      C[NH+](C)CCl\n      1.0\n      \n      94.565\n      0\n      1\n      0.0\n      32\n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n    \n    \n      1564\n      CCCNCO\n      0.1\n      \n      89.138\n      0\n      3\n      0.0\n      38\n      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n    \n  \n\n\n\n\n\nX_train = df_train.ECFP.values\nX_train = np.stack(X_train, axis=0)\n\ny_train = df_train.LogP.values\n\n\n# Standard Scaling\nstd_scaler = StandardScaler()\nX_train_std = std_scaler.fit_transform(X_train)\n\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train_std, y_train)\n\nRandomForestRegressor()\n\n\n\ny_pred = model.predict(X_train_std)\n\n\n# Fancier looking plot \nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_train, y_pred, alpha=0.6, label='Linear Regression')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_train, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best');\n\n\n\n\n\ndisplay_performance(y_train,y_pred);\n\nR2: 0.97\nMAE: 0.15\nRMSE: 0.22"
  },
  {
    "objectID": "posts/2021-05-11-cheminfo_basics_rdkit.html#similarity",
    "href": "posts/2021-05-11-cheminfo_basics_rdkit.html#similarity",
    "title": "Cheminformatics basics - RDkit, regression models, similarity",
    "section": "Similarity",
    "text": "Similarity\nRDKit provides tools for different kinds of similarity search, including Tanimoto, Dice, Cosine, Sokal, Russel… and more. Tanimoto is a very widely use similarity search metric because it incorporates substructure matching. Here is an example\n\nref_mol = df_var_10k.iloc[4234]['ROMol']\n\n\nref_mol\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Generate finger print based representation for that molecule \nref_ECFP4_fps = AllChem.GetMorganFingerprintAsBitVect(ref_mol, radius=2)\n\n\ndf_var_10k_ECFP4_fps = [AllChem.GetMorganFingerprintAsBitVect(x,2) for x in df_var_10k['ROMol']]\n\nEstimate the similarity of the molecules in the dataset to the reference dataset, there are multiple ways of doing it: we are using Tanimoto fingerprints\n\nfrom rdkit import DataStructs\nsimilarity_efcp4 = [DataStructs.FingerprintSimilarity(ref_ECFP4_fps, x) for x in df_var_10k_ECFP4_fps]\n\n\ndf_var_10k['Tanimoto_Similarity (ECFP4)'] = similarity_efcp4\ndf_var_10k['Tanimoto_Similarity (ECFP4)'] = df_var_10k['Tanimoto_Similarity (ECFP4)'].round(3)\nPandasTools.FrameToGridImage(df_var_10k[:10], legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)\n\n\n\n\nSorting the molecule similarity for clarity:\n\ndf_var_10k = df_var_10k.sort_values(['Tanimoto_Similarity (ECFP4)'], ascending=False)\nPandasTools.FrameToGridImage(df_var_10k[:10], legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)"
  },
  {
    "objectID": "posts/2020-07-18-creating_meshes.html",
    "href": "posts/2020-07-18-creating_meshes.html",
    "title": "Plotting surface in matplotlib",
    "section": "",
    "text": "This is adapted from the following Tutorial: Link"
  },
  {
    "objectID": "posts/2020-07-18-creating_meshes.html#meshgrid",
    "href": "posts/2020-07-18-creating_meshes.html#meshgrid",
    "title": "Plotting surface in matplotlib",
    "section": "Meshgrid",
    "text": "Meshgrid\nMesh is important to create a surface since just looking at the x, y vector by themselves what you would look at is the diagonal of the matrix formed by combination of all the possible x values with y values. For the given x and y vector, every entry in x vector can have the entire y vector as a possible point. So it is important to generate an array which captures all these possible pairing.\nSo using mesh-grid if x-vector is of dimensions M and y-vector is of dimensions N – the final resulting matrix is NxM dimensions where every \\(n^{th}\\) entry in y all the entries of x are added. Finally the ouput is given as x coordinate of that matrix and y coordinate of that matrix.\nExample: * \\(X\\) : \\(\\begin{bmatrix} x_{1} & x_{2} & x_{3} \\end{bmatrix}\\) * \\(Y\\) : \\(\\begin{bmatrix} y_{1} & y_{2} \\end{bmatrix}\\)\nThen resulting mesh would be: \\[ X-Y-Mesh = \\begin{bmatrix} x_{1}y_{1} & x_{2}y_{1} & x_{3}y_{1} \\\\ x_{1}y_{2} & x_{2}y_{2} & x_{3}y_{2}  \\end{bmatrix}\\]\n\\[ X-path = \\begin{bmatrix} x_{1} & x_{2} & x_{3} \\\\ x_{1} & x_{2} & x_{3}  \\end{bmatrix}\\]\n\\[ X-path = \\begin{bmatrix} y_{1} & y_{1} & y_{1} \\\\ y_{2} & y_{2} & y_{2}  \\end{bmatrix}\\]\n\n#Setting the bounds of the x and y axis \nx_axis_range = np.arange(-2,2.1,1)\ny_axis_range = np.arange(-4,4.1,1)\n\n#Make the meshgrid for the x and y \n(x,y) = np.meshgrid(x_axis_range, y_axis_range, sparse=True)\n\n\nz = x + y \n\n\nfig = plt.figure(1, clear=True)\nax = fig.add_subplot(1,1,1, projection='3d')\nax.plot_surface(x, y, z)\nfig.tight_layout()\n\n\n\n\nPlotting this 2D function: \\[ z = e^{-\\sqrt {x^2 + y^2}}cos(4x)cos(4y) \\] using the surface\n\nimport matplotlib.cm as cm \n\nx_axis_bound = np.linspace(-1.8,1.8,100)\ny_axis_bound = np.linspace(-1.8,1.8,100)\n\n(x,y) = np.meshgrid(x_axis_bound, y_axis_bound, sparse=True)\n\ndef f(x,y):\n    return np.exp(-np.sqrt( x**2 + y**2 )) * np.cos(4*x) * np.cos(4*y)\n\nZ = f(x,y)\n\nfig = plt.figure(1, clear=True)\nax = fig.add_subplot(1,1,1, projection='3d')\nax.plot_surface(x, y, Z, cmap=cm.hot)\nax.set_xlabel('x')\nax.set_ylabel('y')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html",
    "title": "Material-informatics Literature and Resources",
    "section": "",
    "text": "Last update: 4th July 2021\nMaterial Informatics is the solid-state, inorganic chemistry focused cousin to its organic chemistry contemporary: Cheminformatics. In spirit, the aim of Material Informatics is similar to Cheminformatics; it offers a promising avenue to augment traditional material R&D processes. Amplify the conventional material discovery task using data, analytics, and identify chemical spaces, and structure in the data, which are interesting and probe those rigorously using first-principles techniques and/or experimentation.\nThe potential application of material informatics can be seen in: Microelectronics, aerospace, and automotive to defense, clean energy, and health services, where ever there’s a demand for new advanced materials at even greater rates and lower costs.\nApplication of material informatics in atomic-scale modeling:\nIn case of molecular-level modeling of material properties, concepts developed in material informatics, statistics, and ML can be used for:\nMachine learning in atomic-scale modeling is often used to replace expensive ab initio methods with cheaper approximations. While certainly lucractive an additional consideration for ML use-case is its utility as a surrogate model to help researchers identify interesting regions in the material space. It also helps to decode the ‘intuition’ and serendipity involved in material development and hopefully provide a rigorous data driven basis for a design decision.\nBelow are few reviews, articles, and resources I’ve found that document the state-of-the-art for material informatics. It goes without saying that this is a highly biased and a non-exhaustive listing of articles covering only the ones I’ve read. The idea with this document is to provide a starting point in understanding the general status of the field."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#special-issues-and-collections",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#special-issues-and-collections",
    "title": "Material-informatics Literature and Resources",
    "section": "Special Issues and Collections:",
    "text": "Special Issues and Collections:\n\nNature Materials collection of review articles discussing the role of computation for material design\nMatter journal’s Material prediction using data and ML prediction\nNature Communications compendium on ML for material modelling"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#reviews",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#reviews",
    "title": "Material-informatics Literature and Resources",
    "section": "Reviews:",
    "text": "Reviews:\n\nC. Chen, Y. Zuo, W. Ye, X. Li, Z. Deng, and S. P. Ong, “A Critical Review of Machine Learning of Energy Materials,” Adv. Energy Mater., vol. 1903242, p. 1903242, Jan. 2020.\nJ. Schmidt, M. R. G. Marques, S. Botti, and M. A. L. Marques, “Recent advances and applications of machine learning in solid-state materials science,” npj Comput. Mater., vol. 5, no. 1, p. 83, Dec. 2019.\nJ. Noh, G. H. Gu, S. Kim, and Y. Jung, “Machine-enabled inverse design of inorganic solid materials: promises and challenges,” Chem. Sci., vol. 11, no. 19, pp. 4871–4881, 2020.\nS. M. Moosavi, K. M. Jablonka, and B. Smit, “The Role of Machine Learning in the Understanding and Design of Materials,” J. Am. Chem. Soc., no. Figure 1, p. jacs.0c09105, Nov. 2020.\nF. Häse, L. M. Roch, P. Friederich, and A. Aspuru-Guzik, “Designing and understanding light-harvesting devices with machine learning,” Nat. Commun., vol. 11, no. 1, pp. 1–11, 2020.\nM. Moliner, Y. Román-Leshkov, and A. Corma, “Machine Learning Applied to Zeolite Synthesis: The Missing Link for Realizing High-Throughput Discovery,” Acc. Chem. Res., vol. 52, no. 10, pp. 2971–2980, 2019.\nTao, H., Wu, T., Aldeghi, M. et al. Nanoparticle synthesis assisted by machine learning. Nat Rev Mater, 2021\n\n\nBest practices in material informatics:\nA. Y. T. Wang et al., “Machine Learning for Materials Scientists: An Introductory Guide toward Best Practices,” Chem. Mater., vol. 32, no. 12, pp. 4954–4965, 2020."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#featurizations-possible",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#featurizations-possible",
    "title": "Material-informatics Literature and Resources",
    "section": "Featurizations possible:",
    "text": "Featurizations possible:\nSimilar to other machine-learning development efforts – featurization or descriptors used to convert material entries in machine-readable format is crucial for the eventual performance of any statistical model. Over the years there has been tremendous progress in describing the periodic solid crystal structures. Some of the key articles I’ve liked are mentioned below:\nReviews:\n\nA. P. Bartók, R. Kondor, and G. Csányi, “On representing chemical environments,” Phys. Rev. B - Condens. Matter Mater. Phys., vol. 87, no. 18, pp. 1–16, 2013.\nA. Seko, H. Hayashi, K. Nakayama, A. Takahashi, and I. Tanaka, “Representation of compounds for machine-learning prediction of physical properties,” Phys. Rev. B, vol. 95, no. 14, pp. 1–11, 2017.\nK. T. Schütt, H. Glawe, F. Brockherde, A. Sanna, K. R. Müller, and E. K. U. Gross, “How to represent crystal structures for machine learning: Towards fast prediction of electronic properties,” Phys. Rev. B - Condens. Matter Mater. Phys., vol. 89, no. 20, pp. 1–5, 2014.\n\nArticles:\n1. Composition based:\n\nL. Ward et al., “Including crystal structure attributes in machine learning models of formation energies via Voronoi tessellations,” Phys. Rev. B, vol. 96, no. 2, 2017\n\nPredicting properties of crystalline compounds using a representation consisting of attributes derived from the Voronoi tessellation of its structure and composition based features is both twice as accurate as existing methods and can scale to large training set sizes. Also the representations are insensitive to changes in the volume of a crystal, which makes it possible to predict the properties of the crystal without needing to compute the DFT-relaxed geometry as input. Random forrest algorithm used for the prediction\n\nA. Wang, S. Kauwe, R. Murdock, and T. Sparks, “Compositionally-Restricted Attention-Based Network for Materials Property Prediction (CrabNet).” 20-Feb-2020.\n\nUsing attention-based graph networks on material composition to predict material properties.\n\nGoodall, R.E.A., Lee, A.A. Predicting materials properties without crystal structure: deep representation learning from stoichiometry (Roost). Nat Commun 11, 6280 (2020)\n\nSimilar to the previous article in spirit, here authors use material composition to generate weighted graphs and predict material properties. Consider ensemble-based uncertainty estimates.\n2. Structural based:\n\nT. Xie and J. C. Grossman, “Crystal Graph Convolutional Neural Networks for an Accurate and Interpretable Prediction of Material Properties,” Phys. Rev. Lett., vol. 120, no. 14, p. 145301, 2018."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#material-modeling-benchmark-studies",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#material-modeling-benchmark-studies",
    "title": "Material-informatics Literature and Resources",
    "section": "Material modeling benchmark studies:",
    "text": "Material modeling benchmark studies:\n\nBartel, C.J., Trewartha, A., Wang, Q. et al. A critical examination of compound stability predictions from machine-learned formation energies. npj Comput Mater 6, 97 (2020)\n\nInvestigate if ML models can distinguish materials wrt thermodynamic stability and not just formation energies. Learning formation energy from composition alone is fine for MAE and RMSE representations. Propose that graph-based methods reduce the MAE by roughly 50% compared with the best performing compositional model. Show that including structural information is advantageous when predicting formation energies.\n\nA. J. Chowdhury, W. Yang, E. Walker, O. Mamun, A. Heyden, and G. A. Terejanu, “Prediction of Adsorption Energies for Chemical Species on Metal Catalyst Surfaces Using Machine Learning,” J. Phys. Chem. C, vol. 122, no. 49, pp. 28142–28150, 2018\n\nConsider various encoding scheme and machine learning models to predict single adsorbate binding energy for carbon-based adsorabtes on transition metal surfaces. They show linear methods and scaling relationship hold well compared to ML methods. They found that for ML models to succeed, it is not necessary to use advanced (geometric) coordinate-based descriptors; simple descriptors, such as bond count, can provide satisfactory results. As many catalysis and materials science problems require significant time to generate each data point, in many cases the ML models would need to work with a relatively small-sized dataset\n\nRosen, Andrew; Iyer, Shaelyn; Ray, Debmalya; Yao, Zhenpeng; Aspuru-Guzik, Alan; Gagliardi, Laura; et al. (2020): Machine Learning the Quantum-Chemical Properties of Metal–Organic Frameworks for Accelerated Materials Discovery with a New Electronic Structure Database. ChemRxiv. Preprint\nFung, V., Zhang, J., Juarez, E. et al. Benchmarking graph neural networks for materials chemistry. npj Comput Mater 7, 84 (2021)"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#articles",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#articles",
    "title": "Material-informatics Literature and Resources",
    "section": "Articles:",
    "text": "Articles:\nThere is a rich and long history of using statistical model and data mining for predicting bulk inorganic crystal properties. The review articles mentioned in the above section discuss those areas quite nicely.\n\nThis section particularly focusses on works applying informatics to encode surfaces for modeling heterogeneous catalyst surfaces, which is fairly new and very active research direction:\n\n\nMa, X., Li, Z., Achenie, L.E.K., and Xin, H. (2015). Machine-learning-augmented chemisorption model for CO2 electroreduction catalyst screening. J. Phys. Chem. Lett. 6, 3528–3533.\nF. Liu, S. Yang, and A. J. Medford, “Scalable approach to high coverages on oxides via iterative training of a machine-learning algorithm,” ChemCatChem, vol. 12, no. 17, pp. 4317–4330, 2020.\nC. S. Praveen and A. Comas-Vives, “Design of an Accurate Machine Learning Algorithm to Predict the Binding Energies of Several Adsorbates on Multiple Sites of Metal Surfaces,” ChemCatChem, vol. n/a, no. n/a, 2020.\nZ. Li, L. E. K. Achenie, and H. Xin, “An Adaptive Machine Learning Strategy for Accelerating Discovery of Perovskite Electrocatalysts,” ACS Catal., vol. 10, no. 7, pp. 4377–4384, 2020.\nR. García-Muelas and N. López, “Statistical learning goes beyond the d-band model providing the thermochemistry of adsorbates on transition metals,” Nat. Commun., vol. 10, no. 1, p. 4687, Dec. 2019.\nM. Rueck, B. Garlyyev, F. Mayr, A. S. Bandarenka, and A. Gagliardi, “Oxygen Reduction Activities of Strained Platinum Core-Shell Electrocatalysts Predicted by Machine Learning,” J. Phys. Chem. Lett., 2020.\nW. Xu, M. Andersen, and K. Reuter, “Data-Driven Descriptor Engineering and Refined Scaling Relations for Predicting Transition Metal Oxide Reactivity,” ACS Catal., vol. 11, no. 2, pp. 734–742, Jan. 2021.\nLiu, F., Yang, S. & Medford, A. J. Scalable approach to high coverages on oxides via iterative training of a machine-learning algorithm. ChemCatChem 12, 4317–4330 (2020).\n\nGraph-network based approaches for encoding and predicting surface binding energies:\n\nBack, S. et al. Convolutional Neural Network of Atomic Surface Structures to Predict Binding Energies for High-Throughput Screening of Catalysts. J. Phys. Chem. Lett. 10, 4401–4408 (2019)\nLym, J., Gu, G. H., Jung, Y. & Vlachos, D. G. Lattice convolutional neural network modeling of adsorbate coverage effects. J. Phys. Chem. C 123, 18951–18959 (2019).\n\nAdsorbate binding predictions have been recently extended to cover high-entropy alloy surfaces as well:\n\nT. A. A. Batchelor et al., “Complex solid solution electrocatalyst discovery by computational prediction and high‐throughput experimentation,” Angew. Chemie Int. Ed., p. anie.202014374, Dec. 2020.\nJ. K. Pedersen, T. A. A. Batchelor, D. Yan, L. E. J. Skjegstad, and J. Rossmeisl, “Surface electrocatalysis on high-entropy alloys,” Curr. Opin. Electrochem., vol. 26, p. 100651, Apr. 2021.\nZ. Lu, Z. W. Chen, and C. V. Singh, “Neural Network-Assisted Development of High-Entropy Alloy Catalysts: Decoupling Ligand and Coordination Effects,” Matter, vol. 3, no. 4, pp. 1318–1333, 2020.\n\nMiscellaneous\n\nJang, Jidon, et al. “Structure-based synthesizability prediction of crystals using partially supervised learning.” Journal of the American Chemical Society 142.44 (2020): 18836-18843.\n\nCGCNN as a binary classification for synthesizability. The metric is identified only for the positive cases (that is experimental data) and used a proxy to train the model to learn what makes the material positive."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#global-optimization-methods",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#global-optimization-methods",
    "title": "Material-informatics Literature and Resources",
    "section": "Global optimization methods:",
    "text": "Global optimization methods:\n\nM. K. Bisbo and B. Hammer, “Efficient global structure optimization with a machine learned surrogate model,” Phys. Rev. Lett., vol. 124, no. 8, p. 86102, 2019.\nJ. Dean, M. G. Taylor, and G. Mpourmpakis, “Unfolding adsorption on metal nanoparticles: Connecting stability with catalysis,” Sci. Adv., vol. 5, no. 9, 2019."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#uncertainty-quantification-uq",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#uncertainty-quantification-uq",
    "title": "Material-informatics Literature and Resources",
    "section": "Uncertainty quantification (UQ):",
    "text": "Uncertainty quantification (UQ):\n\nA. Wang et al., “A Framework for Quantifying Uncertainty in DFT Energy Corrections.” 19-May-2021\n\nMethod to comment on the uncertainty of DFT errors which accounts for both sources of uncertainty: experimental and model parameters. Fit energy corrections using a set of 222 binary and ternary compounds for which experimental and computed values are present. Quantifying this uncertainty can help reveal cases wherein empirically-corrected DFT calculations are limited to differentiate between stable and unstable phases. Validate this approach on Sc-W-O phase diagram analysis.\n\nFeng, J., Lansford, J. L., Katsoulakis, M. A., & Vlachos, D. G. (2020). Explainable and trustworthy artificial intelligence for correctable modeling in chemical sciences. Science advances, 6(42)\n\nPropose Bayesian networks, type of probabilistic graphical models, to integrate physics- and chemistry-based data and uncertainty. Demonstrate this framework in searching for the optimal reaction rate and oxygen binding energy for the oxygen reduction reaction (ORR) using the volcano model. Their model is able to comment on the source of uncertainty in the model.\n\nK. Tran, W. Neiswanger, J. Yoon, Q. Zhang, E. Xing, and Z. W. Ulissi, “Methods for comparing uncertainty quantifications for material property predictions,” pp. 1–29, Dec. 2019\n\nHelpful overview and benchmark of various model flavors and metrics to understand ways of reporting the confidence in model predictions for material properties. Interesting convolution-Fed Gaussian Process (CFGP) model framework looked into which is a combination of CGCNN and GP: pooled outputs of the convolutional layers of the network as features in a new GP. This was also their best model from the collection. Nice overview of different metrics used for comparing methods for UQ."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#active-learning",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#active-learning",
    "title": "Material-informatics Literature and Resources",
    "section": "Active learning:",
    "text": "Active learning:\n\nA. Seko and S. Ishiwata, “Prediction of perovskite-related structures in ACuO3-x (A = Ca, Sr, Ba, Sc, Y, La) using density functional theory and Ba,” Phys. Rev. B, vol. 101, no. 13, p. 134101, Apr. 2020.\nK. Tran and Z. W. Ulissi, Active learning across intermetallics to guide discovery of electrocatalysts for CO2 reduction and H2 evolution, vol. 1, no. 9. Springer US, 2018.\nD. Xue, P. V. Balachandran, J. Hogden, J. Theiler, D. Xue, and T. Lookman, “Accelerated search for materials with targeted properties by adaptive design,” Nat. Commun., vol. 7, pp. 1–9, 2016.\nDeshwal A, Simon C, Doppa JR. Bayesian optimization of nanoporous materials. ChemRxiv. 2021\nJablonka, Kevin Maik, et al. “Bias free multiobjective active learning for materials design and discovery.” Nature communications 12.1 (2021): 1-10.\n\nActive learning algorithm to find Pareto front for multi-objective optimization. Apply algorithm to de-novo polymer design. Ranking materials in a multi-objective optimization tasks is sometimes biased. Instead of ranking the candidates, the authors want to identify an approximate pareto front. Selection of candidates happens based on their promixity to the pareto front, which itself is defined by following geometric rules."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#surrogate-optimizer-and-accelerating-ts-searches",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#surrogate-optimizer-and-accelerating-ts-searches",
    "title": "Material-informatics Literature and Resources",
    "section": "Surrogate optimizer and accelerating TS searches:",
    "text": "Surrogate optimizer and accelerating TS searches:\n\nO.-P. Koistinen, F. B. Dagbjartsdóttir, V. Ásgeirsson, A. Vehtari, and H. Jónsson, “Nudged elastic band calculations accelerated with Gaussian process regression,” J. Chem. Phys., vol. 147, no. 15, p. 152720, Oct. 2017.\nJ. A. Garrido Torres, P. C. Jennings, M. H. Hansen, J. R. Boes, and T. Bligaard, “Low-Scaling Algorithm for Nudged Elastic Band Calculations Using a Surrogate Machine Learning Model,” Phys. Rev. Lett., vol. 122, no. 15, pp. 1–6, 2019.\nE. Garijo del Río, J. J. Mortensen, and K. W. Jacobsen, “Local Bayesian optimizer for atomic structures,” Phys. Rev. B, vol. 100, no. 10, pp. 1–9, 2019."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#combining-experiments-theory",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#combining-experiments-theory",
    "title": "Material-informatics Literature and Resources",
    "section": "Combining experiments + theory:",
    "text": "Combining experiments + theory:\n\nE. O. Ebikade, Y. Wang, N. Samulewicz, B. Hasa, and D. Vlachos, “Active learning-driven quantitative synthesis–structure–property relations for improving performance and revealing active sites of nitrogen-doped carbon for the hydrogen evolution reaction,” React. Chem. Eng., 2020.\nA. Smith, A. Keane, J. A. Dumesic, G. W. Huber, and V. M. Zavala, “A machine learning framework for the analysis and prediction of catalytic activity from experimental data,” Appl. Catal. B Environ., vol. 263, no. October 2019, p. 118257, 2020.\nM. Zhong et al., Accelerated discovery of CO2 electrocatalysts using active machine learning, vol. 581, no. 7807. 2020.\nA. J. Saadun et al., “Performance of Metal-Catalyzed Hydrodebromination of Dibromomethane Analyzed by Descriptors Derived from Statistical Learning,” ACS Catal., vol. 10, no. 11, pp. 6129–6143, Jun. 2020.\nJ. L. Lansford and D. G. Vlachos, “Infrared spectroscopy data- and physics-driven machine learning for characterizing surface microstructure of complex materials,” Nat. Commun., vol. 11, no. 1, p. 1513, Dec. 2020\nAccelerated discovery of metallic glasses through iteration of machine learning and high-throughput experiments\nMaterials genes of heterogeneous catalysis from clean experiments and artificial intelligence\nN. Artrith, Z. Lin, and J. G. Chen, “Predicting the Activity and Selectivity of Bimetallic Metal Catalysts for Ethanol Reforming using Machine Learning,” ACS Catal., vol. 10, no. 16, pp. 9438–9444, Aug. 2020.\nS. Nellaiappan et al., “High-Entropy Alloys as Catalysts for the CO2 and CO Reduction Reactions: Experimental Realization,” ACS Catal., vol. 10, no. 6, pp. 3658–3663, 2020."
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#reaction-network-predictions",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#reaction-network-predictions",
    "title": "Material-informatics Literature and Resources",
    "section": "Reaction Network Predictions:",
    "text": "Reaction Network Predictions:\n\n“Rational Solid-State Synthesis Routes for Inorganic Materials” Muratahan Aykol, Joseph H. Montoya, and Jens Hummelshøj Journal of the American Chemical Society 2021 143 (24), 9244-9259\nM. Liu et al., “Reaction Mechanism Generator v3.0: Advances in Automatic Mechanism Generation,” J. Chem. Inf. Model., May 2021.\n\nNewest version of RMG (v3) is updated to Python v3. It has ability to generate heterogeneous catalyst models, uncertainty analysis to conduct first order sensitivity analysis. RMG dataset for the thermochemical and kinetic parameters have been expanded.\n\nA Chemically Consistent Graph Architecture for Massive Reaction Networks Applied to Solid-Electrolyte Interphase Formation. ChemRxiv. Blau, Samuel; Patel, Hetal; Spotte-Smith, Evan; Xie, Xiaowei; Dwaraknath, Shyam; Persson, Kristin (2020)\n\nDevelop a multi-reactant representation scheme to look at arbitrary reactant product pairs. Apply this technique to understand electrochemical reaction network for Li-ion solid electrolyte interphase.\n\nMcDermott, M.J., Dwaraknath, S.S. & Persson, K.A. A graph-based network for predicting chemical reaction pathways in solid-state materials synthesis. Nat Commun 12, 3097 (2021)\n\nChemical reaction network model to predict synthesis pathway for exotic oxides. Solid-state synthesis procedures for YMnO3, Y2Mn2O7, Fe2SiS4, and YBa2Cu3O6.5 are proposed and compared to literature pathways. Finally apply the algorithm to search for a probable synthesis route to make MgMo3(PO4)3O, battery cathode material that has yet to be synthesized.\n\nDiscovering Competing Electrocatalytic Mechanisms and Their Overpotentials: Automated Enumeration of Oxygen Evolution Pathways, A. Govind Rajan and E. A. Carter, J. Phys. Chem. C, vol. 124, no. 45, pp. 24883–24898, Nov. 2020.\nAccurate Thermochemistry of Complex Lignin Structures via Density Functional Theory, Group Additivity, and Machine Learning, Q. Li, G. Wittreich, Y. Wang, H. Bhattacharjee, U. Gupta, and D. G. Vlachos, ACS Sustain. Chem. Eng., vol. 9, no. 8, pp. 3043–3049, Mar. 2021.\nZiyun Wang, Yuguang Li, Jacob Boes et al. CO2 Electrocatalyst Design Using Graph Theory, 21 September 2020, Preprint"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#generative-models",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#generative-models",
    "title": "Material-informatics Literature and Resources",
    "section": "Generative Models:",
    "text": "Generative Models:\nReview:\nJ. Noh et al., “Inverse Design of Solid-State Materials via a Continuous Representation,” Matter, vol. 1, no. 5, pp. 1370–1384, 2019.\nArticles:\n\nS. Kim, J. Noh, G. H. Gu, A. Aspuru-Guzik, and Y. Jung, “Generative Adversarial Networks for Crystal Structure Prediction,” pp. 1–37, 2020\nB. Kim, S. Lee, and J. Kim, “Inverse design of porous materials using artificial neural networks,” Sci. Adv., vol. 6, no. 1, 2020\nZ. Yao et al., “Inverse Design of Nanoporous Crystalline Reticular Materials with Deep Generative Models,” 2020\n\nSemantically constrained graph-based code for presenting a MOFs. Target property directed optimization. Encode MOFs as edges, vertices, topologies. Edges are molecular fragments with two connecting points, verticies contain node information, topologies indicate a definite framework. Supramolecular Variational Autoencoder (SmVAE) with several corresponding components that oversee encoding and decoding each part of the MOF: Map the frameworks with discrete representations (RFcodes) into continuous vectors (z) and then back.\n\nDiscovering Relationships between OSDAs and Zeolites through Data Mining and Generative Neural Networks"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#datasets",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#datasets",
    "title": "Material-informatics Literature and Resources",
    "section": "Datasets:",
    "text": "Datasets:\nWhile we can attribute the recent interest in material informatics to democratization of data analytics and ML packages, growing set of benchmark datasets of materials from multiple research institution has been crucial for development of new methods, algorithms and providing a consistent set of comparison.\n\nOC20 dataset (CMU + Facebook). Paper. Github\n\nDataset comprising of surface heterogeneous adsorbates.\n\nCatalysis Hub from SUNCAT. Website\n\nSurface Reactions database contains thousands of reaction energies and barriers from density functional theory (DFT) calculations on surface systems\n\nMaterials Project\n\nBesides providing a collection of over 130,000 inorganic compounds and 49,000 molecules and counting, with calculated phase diagrams, structural, thermodynamic, electronic, magnetic, and topological properties it also provides analysis tools for post-processing.\n\nOQMD from Chris Wolverton’s Group\n\n815,000+ materials with calculated thermodynamic and structural properties.\n\nICSD\n\n210,000+ inorganic crystal structures from literature. Requires subscription.\n\nJARVIS by NIST\n\nIncludes calculated materials properties, 2D materials, and tools for ML and high-throughput tight-binding.\n\nC2DB\n\nStructural, thermodynamic, elastic, electronic, magnetic, and optical properties of around 4000 two-dimensional (2D) materials distributed over more than 40 different crystal structures.\n\nAFLOW\n\nMillions of materials and calculated properties, focusing on alloys.\n\nCitrination\n\nContributed and curated datasets from Citrine Informatics\n\nMDPS\n\nFascinating resource linking scientific publications using the Pauling File database (relational database of published literature for material scientists)\n\nCurated list of material informatics packages"
  },
  {
    "objectID": "posts/2021-05-21-MaterialInformatics_Resources.html#packages",
    "href": "posts/2021-05-21-MaterialInformatics_Resources.html#packages",
    "title": "Material-informatics Literature and Resources",
    "section": "Packages:",
    "text": "Packages:\n\nPerovskite oxide stability\nDOSNet\nOpen catalysis dataset\nAENet\nAMP\nAMPtorch (PyTorch implementation of AMP)\nFeature engineering for Perovskite’s electronic structure properties\nMEGNET\nSISSO\nCatlearn\nMatminer\nMat2Vec\nPyePAL\n\nActive learning approach to efficiently and confidently identify the Pareto front with any regression model that can output a mean and a standard deviation."
  },
  {
    "objectID": "posts/2020-09-18-smiles_from_pubchem.html",
    "href": "posts/2020-09-18-smiles_from_pubchem.html",
    "title": "Get SMILES from PubChem using DASK",
    "section": "",
    "text": "Dask implementation to acquire CanonicalSMILES from PubChem using the pubchem API. At the end of the notebook there is another dask based implementation of using RDKit to get InChIKey from the SMILES. While Dask is not necessary required in the case of InChIKeys it is a much more elegant implementation of dask.dataframes and map_partitions"
  },
  {
    "objectID": "posts/2020-09-18-smiles_from_pubchem.html#get-smiles-from-pubchem",
    "href": "posts/2020-09-18-smiles_from_pubchem.html#get-smiles-from-pubchem",
    "title": "Get SMILES from PubChem using DASK",
    "section": "Get SMILES from Pubchem",
    "text": "Get SMILES from Pubchem\n\nUpdate: Parallelized using dask\n\n\ndf_100 = pd.read_csv('./DASK_SMILES/sample_chemical_names.csv', sep=',', header=0)\n\n\ndf_100.shape\n\n(147, 1)\n\n\n\nfrom dask.distributed import Client, progress\nimport dask.dataframe as dd\nfrom dask import delayed, compute\nfrom dask.multiprocessing import get\nclient = Client()\nclient\n\n\n\n\n\nClient\n\n  Scheduler: tcp://127.0.0.1:45859\n  Dashboard: http://127.0.0.1:8787/status\n\n\n\nCluster\n\n  Workers: 4\n  Cores: 8\n  Memory: 39.85 GB\n\n\n\n\n\n\n\ndef get_smile(cmpd_name):\n    try:\n        #delayed(f)(x, args=a)\n        name = delayed(pcp.get_properties)(['CanonicalSMILES'], cmpd_name, 'name')\n        time.sleep(5)\n        smile = name[0]['CanonicalSMILES']\n    except:\n        smile = 'X'\n        print(cta_name, smile)\n    return smile\n\ndef dask_smiles(df):\n    df['CanonicalSMILES'] = df['CTA'].map(get_smile)\n    return df #Map paritions works here -- but not with to_list() in the previous implementation \n\n\ndf_dask = dd.from_pandas(df_100, npartitions=10)\n\n\ndf_dask\n\n\nDask DataFrame Structure:\n\n\n\n  \n    \n      \n      CTA\n    \n    \n      npartitions=10\n      \n    \n  \n  \n    \n      0\n      object\n    \n    \n      15\n      ...\n    \n    \n      ...\n      ...\n    \n    \n      135\n      ...\n    \n    \n      146\n      ...\n    \n  \n\n\nDask Name: from_pandas, 10 tasks\n\n\ndf_dask.visualize()\n\n%time ddf_out  = df_dask.map_partitions(dask_smiles)\n\nCPU times: user 567 ms, sys: 92.3 ms, total: 660 ms\nWall time: 10 s\n\n\n\nddf_out.iloc[:,0]\n\nDask Series Structure:\nnpartitions=10\n0      object\n15        ...\n        ...  \n135       ...\n146       ...\nName: CTA, dtype: object\nDask Name: getitem, 30 tasks\n\n\nddf_out.visualize()\n\n%time results = ddf_out.persist(scheduler=client).compute()\n\nCPU times: user 9.42 s, sys: 1.27 s, total: 10.7 s\nWall time: 2min 43s\n\n\n\ntype(results)\n\npandas.core.frame.DataFrame\n\n\n\nresults.loc[0]\n\nCTA                                                     Cyclopropane\nCanonicalSMILES    Delayed('getitem-e98dc8d7261c3d694a3c944735b3c...\nName: 0, dtype: object\n\n\n\ncompute(results['CanonicalSMILES'].iloc[0])[0] #Compute result for one entry \n\n'C1CC1'\n\n\n\n%time results['CanonicalSMILES'] = [value[0] for value in results['CanonicalSMILES'].map(compute)]\n\nCPU times: user 3.73 s, sys: 443 ms, total: 4.17 s\nWall time: 31.1 s\n\n\n\ntype(results)\n\npandas.core.frame.DataFrame\n\n\n\nresults[results['CanonicalSMILES'] == 'X']\n\n\n\n\n\n  \n    \n      \n      CTA\n      CanonicalSMILES\n    \n  \n  \n  \n\n\n\n\n\nresults\n\n\n\n\n\n  \n    \n      \n      CTA\n      CanonicalSMILES\n    \n  \n  \n    \n      0\n      Cyclopropane\n      C1CC1\n    \n    \n      1\n      Ethylene\n      C=C\n    \n    \n      2\n      Methane\n      C\n    \n    \n      3\n      t-Butanol\n      CC(C)(C)O\n    \n    \n      4\n      ethane\n      CC\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      142\n      Cyclohexane-1,3-dicarbaldehyde\n      C1CC(CC(C1)C=O)C=O\n    \n    \n      143\n      isobutene\n      CC(=C)C\n    \n    \n      144\n      propanal\n      CCC=O\n    \n    \n      145\n      methyl methacrylate\n      CC(=C)C(=O)OC\n    \n    \n      146\n      vinyl acetate\n      CC(=O)OC=C\n    \n  \n\n147 rows × 2 columns\n\n\n\nresults.to_pickle(“cta_smiles_table_100_less.pkl”)"
  },
  {
    "objectID": "posts/2020-09-18-smiles_from_pubchem.html#dask-to-get-inchikey",
    "href": "posts/2020-09-18-smiles_from_pubchem.html#dask-to-get-inchikey",
    "title": "Get SMILES from PubChem using DASK",
    "section": "## Dask to get InChIKey",
    "text": "## Dask to get InChIKey\nThis implementation in my opinion is more elegant use of dask’s apply command wrapper around conventional pandas apply. Also here we are defining the meta key for the variable since the code doesn’t seem to recognise the type of entries we expect in the final output\nMore information about meta here: https://docs.dask.org/en/latest/dataframe-api.html\n\nimport rdkit\nfrom rdkit import Chem\nfrom rdkit.Chem import PandasTools\nfrom rdkit.Chem import Draw\n\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n\ndef get_InChiKey(x):\n    try:\n        inchi_key =  Chem.MolToInchiKey(Chem.MolFromSmiles(x))\n    except:\n        inchi_key = 'X'\n    return inchi_key\n\ndef dask_smiles(df):\n    df['INCHI'] = df['smiles'].map(get_name)\n    return df\n\n\nresults_dask = dd.from_pandas(results, npartitions=10)\n\n\ninchi = results_dask['CanonicalSMILES'].apply(lambda x: Chem.MolToInchiKey(Chem.MolFromSmiles(x)), meta=('inchi_key',str))\n\n\ninchi\n\nDask Series Structure:\nnpartitions=10\n0      object\n15        ...\n        ...  \n135       ...\n146       ...\nName: inchi_key, dtype: object\nDask Name: apply, 30 tasks\n\n\ninchi.visualize()\ninchi is a new Pandas series which has the delayed graphs for computing InChIKeys. We can compute it directly in the results dataframe as a new column. This is slightly different from the SMILES implementation above.\n\n%time results['INCHI'] = compute(inchi, scheduler = client)[0]\n\nCPU times: user 125 ms, sys: 17.3 ms, total: 142 ms\nWall time: 1.02 s\n\n\n\nresults\n\n\n\n\n\n  \n    \n      \n      CTA\n      CanonicalSMILES\n      INCHI\n    \n  \n  \n    \n      0\n      Cyclopropane\n      C1CC1\n      LVZWSLJZHVFIQJ-UHFFFAOYSA-N\n    \n    \n      1\n      Ethylene\n      C=C\n      VGGSQFUCUMXWEO-UHFFFAOYSA-N\n    \n    \n      2\n      Methane\n      C\n      VNWKTOKETHGBQD-UHFFFAOYSA-N\n    \n    \n      3\n      t-Butanol\n      CC(C)(C)O\n      DKGAVHZHDRPRBM-UHFFFAOYSA-N\n    \n    \n      4\n      ethane\n      CC\n      OTMSDBZUPAUEDD-UHFFFAOYSA-N\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      142\n      Cyclohexane-1,3-dicarbaldehyde\n      C1CC(CC(C1)C=O)C=O\n      WHKHKMGAZGBKCK-UHFFFAOYSA-N\n    \n    \n      143\n      isobutene\n      CC(=C)C\n      VQTUBCCKSQIDNK-UHFFFAOYSA-N\n    \n    \n      144\n      propanal\n      CCC=O\n      NBBJYMSMWIIQGU-UHFFFAOYSA-N\n    \n    \n      145\n      methyl methacrylate\n      CC(=C)C(=O)OC\n      VVQNEPGJFQJSBK-UHFFFAOYSA-N\n    \n    \n      146\n      vinyl acetate\n      CC(=O)OC=C\n      XTXRWKRVRITETP-UHFFFAOYSA-N\n    \n  \n\n147 rows × 3 columns"
  },
  {
    "objectID": "posts/2021-10-10-Rdkit.html",
    "href": "posts/2021-10-10-Rdkit.html",
    "title": "Rdkit quick tips",
    "section": "",
    "text": "Rdkit code snippets and recipes that I revisit now and again. The snippets are adopted from different python scripts written over time, ignore the variable names.\nTutorials & Walkthroughs\n\nRSC_OpenScience\n\n*Mute warnings\nfrom rdkit import RDLogger   \nRDLogger.DisableLog('rdApp.*') \n\nFingerprints\nQuick ECFP fingerprint\nfrom rdkit.Chem import AllChem\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import rdFingerprintGenerator\n\n# Convert to Chem.Mol: \nmol = Chem.MolFromSmiles(smiles)\n\n# Counts by default - unfolded \nrdMolDescriptors.GetMorganFingerprint(mol, radius) \n\n# Folded counts \nrdMolDescriptors.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n\n#Folded FP bit vectors as per the size of the bits \nmorgan_fp_bit_vect = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n\n# Convert to numpy \nfp = np.zeros((0,), dtype=np.int16)\nDataStructs.ConvertToNumpyArray(morgan_fp_bit_vect, fp)\n\n\nLoading data\nTanimoto similarity matrix\nAdapted from Andrew White:\nimport itertools\ndef tanimoto_matrix(slist):\n    '''\n    Compute pair-wise Tanimoto similarity between a list of smiles with ECFP4 FPs\n    '''\n    fp = [ AllChem.GetMorganFingerprint( Chem.MolFromSmiles(s), 2 ) for s in slist ]\n    ts = list(\n    DataStructs.cDataStructs.TanimotoSimilarity(x,y) for x, y, in itertools.product(fp, repeat=2)\n    )\n    return np.array(ts).reshape(len(fp), len(fp))\nLoading ZINC dataset\nAdapted from Andrew White:\ntranches = pd.read_csv('https://gist.githubusercontent.com/whitead/f47887e45bbd2f38332182d2d422da6b/raw/a3948beac9b9034dab432b697c5ec238503ac5d0/tranches.txt')\ndef get_mol_batch(batch_size = 32):\n  for t in tranches.values:\n    d = pd.read_csv(t[0], sep=' ')    \n    for i in range(len(d) // batch_size):\n      yield d.iloc[i * batch_size:(i + 1) * batch_size, 0].values\n\n\nViewing molecules\nSDF\n\nRDKit blog\n\nSimple implementation\ninf = open('./example.sdf','rb')\n#import gzip \n#inf = gzip.open('gzip_file')\nfsuppl = Chem.ForwardSDMolSupplier(inf)\nmol_list = []\nfor mol in fsuppl:\n  if mol is None:\n    continue\n  print(mol.GetNumAtoms())\n  mol_list.append(mol)\nAs a Pandas DataFrame\nsdf_df = PandasTools.LoadSDF('./example.sdf')\nsdf_df['NumHeavyAtoms']= sdf_df.apply(lambda x: x['ROMol'].GetNumHeavyAtoms(), axis=1)\nPandasTools.WriteSDF(sdf_df, 'out.sdf', molColName='ROMol', idName='ID', properties=list(sdf_df.columns), allNumeric=False)\nViewing molecules inline\nfrom rdkit.Chem.Draw import IPythonConsole\nfrom rdkit.Chem.Draw import MolsToGridImage \nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\n\nsample_mol_list = [Chem.MolFromSmiles(x) for x  in smiles_list]\nMolsToGridImage(sample_mol_list, molsPerRow=5)\nViewing molecules in a grid\nimport pandas as pd\nfrom rdkit.Chem import PandasTools\n\n>> PandasTools.AddMoleculeColumnToFrame(df, smilesCol='smiles')\n>> esol_data.head(1)\n\n>> PandasTools.FrameToGridImage(df.head(8), legendsCol=\"logSolubility\", molsPerRow=4)\nAdding new values as a column\ndf[\"n_Atoms\"] = df['ROMol'].map(lambda x: x.GetNumAtoms())\ndf.head(1)\nMolecules in a xlsx file\nimport pandas as pd\nfrom rdkit import Chem\nfrom rdkit.Chem import PandasTools\n\n>> smiles = ['c1ccccc1', 'c1ccccc1O', 'c1cc(O)ccc1O']\n>> df = pd.DataFrame({'ID':['Benzene', 'Phenol', 'Hydroquinone'], 'SMILES':smiles})\n>> df['Mol Image'] = [Chem.MolFromSmiles(s) for s in df['SMILES']]\n>> PandasTools.SaveXlsxFromFrame(df, 'test.xlsx', molCol='Mol Image')\nViewing substructures\ndef viz_substruct(main_smile, substructure_smarts):\n    \n    mol_file = Chem.MolFromSmiles(main_smile)\n    sub_pattern = Chem.MolFromSmarts(substructure_smarts)\n    \n    hit_ats = list(mol_file.GetSubstructMatch(sub_pattern)) # Returns the indices of the molecule’s atoms that match a substructure query\n    hit_bonds = []\n\n    for bond in sub_pattern.GetBonds():\n        aid1 = hit_ats[bond.GetBeginAtomIdx()]\n        aid2 = hit_ats[bond.GetEndAtomIdx()]\n\n        hit_bonds.append( mol_file.GetBondBetweenAtoms(aid1, aid2).GetIdx() )\n\n    d2d = rdMolDraw2D.MolDraw2DSVG(400, 400) # or MolDraw2DCairo to get PNGs\n    rdMolDraw2D.PrepareAndDrawMolecule(d2d, mol_file, highlightAtoms=hit_ats,  highlightBonds=hit_bonds)\n    d2d.FinishDrawing()\n    return SVG(d2d.GetDrawingText())\n\n>> diclofenac = 'O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl'\n>> substruct_smarts = 'O=CCccN'\n>> viz_substruct(diclofenac, substruct_smarts)\nQuick substructure filter in-line to Pandas df\ndef NO_NO(smile):\n    ''' Detects a Tau binder fragment'''\n    mol = Chem.MolFromSmiles(smile)\n    smt1= Chem.MolFromSmarts('[NR1][OR1]')\n    if mol.HasSubstructMatch(smt1):\n      return True\n    else:\n      return False\n\n>> linker_2_stereos['Ring_NO'] = linker_2_stereos['SMILES'].apply(NO_NO)\nStandardize molecules\nBorrowed from here\nfrom rdkit.Chem.MolStandardize import rdMolStandardize\n\ndef standardize(mol):\n    # follows the steps in\n    # https://github.com/greglandrum/RSC_OpenScience_Standardization_202104/blob/main/MolStandardize%20pieces.ipynb\n    # as described **excellently** (by Greg) in\n    # https://www.youtube.com/watch?v=eWTApNX8dJQ\n    # removeHs, disconnect metal atoms, normalize the molecule, reionize the molecule\n    clean_mol = rdMolStandardize.Cleanup(mol) \n     \n    # if many fragments, get the \"parent\" (the actual mol we are interested in) \n    parent_clean_mol = rdMolStandardize.FragmentParent(clean_mol)\n         \n    # try to neutralize molecule\n    uncharger = rdMolStandardize.Uncharger() # annoying, but necessary as no convenience method exists\n    uncharged_parent_clean_mol = uncharger.uncharge(parent_clean_mol)\n     \n    # note that no attempt is made at reionization at this step\n    # nor at ionization at some pH (rdkit has no pKa caculator)\n    # the main aim to to represent all molecules from different sources\n    # in a (single) standard way, for use in ML, catalogue, etc.\n     \n    te = rdMolStandardize.TautomerEnumerator() # idem\n    taut_uncharged_parent_clean_mol = te.Canonicalize(uncharged_parent_clean_mol)\n     \n    return taut_uncharged_parent_clean_mol\nFind and change atoms in the molecule\ndef find_UI_change_to_12(smile, attach_type='UI'):\n  mol1 = Chem.MolFromSmiles(smile)\n  sub_pattern = Chem.MolFromSmarts('[U]*.[I]*')\n  hit_ats = list(mol1.GetSubstructMatch(sub_pattern))\n  emol = Chem.EditableMol(mol1) #Chem.RWMol()\n  emol.RemoveBond(hit_ats[0], hit_ats[1])\n  emol.RemoveBond(hit_ats[2], hit_ats[3])\n  mol2 = emol.GetMol()\n  \n  if attach_type == 'UI':\n    # Attached to U \n    mol2.GetAtomWithIdx(hit_ats[1]).SetIsotope(2)\n    # Attached to I \n    mol2.GetAtomWithIdx(hit_ats[3]).SetIsotope(1)\n  \n  else:\n    # Attached to U \n    mol2.GetAtomWithIdx(hit_ats[1]).SetIsotope(1)\n    # Attached to I\n    mol2.GetAtomWithIdx(hit_ats[3]).SetIsotope(2)\n    \n  mol2 = standardize(mol2)\n  return(mol2, Chem.MolToSmiles(mol2))\n\n\nReactions\nView a reaction\nrxn = AllChem.ReactionFromSmarts('[C:1]=[C:2].[C:3]=[*:4][*:5]=[C:6]>>[C:1]1[C:2][C:3][*:4]=[*:5][C:6]1')\nGet changed atoms in a reaction: https://greglandrum.github.io/rdkit-blog/tutorial/reactions/2021/11/26/highlighting-changed-bonds-in-reactions.html\nRun enumerations\nBorrowed and inspired from Pat Walters gist\nrxn = AllChem.ReactionFromSmarts(\"[#6:10]-[#7H2:9].[#7]-[c:4]1[c:5][c:6][c:7][c:8][c:3]1-[#6](-[OH])=O.[#6H:1](-[#6:2])=O>>[#6:10]-[#7:9]-c1n[c:1](-[#6:2])n[c:4]2[c:5][c:6][c:7][c:8][c:3]12\")\n\nreact_dict = {'R1':[],'R2':[],'R3':[], 'product':[]}\nfor r1, r2, r3 in product( *[primary_amines_list, amino_benzoic_list, aldehyde_list]):\n  react_dict['R1'].append(r1)\n  react_dict['R2'].append(r2)\n  react_dict['R3'].append(r3)\n  r1_mol = Chem.MolFromSmiles(r1)\n  r2_mol = Chem.MolFromSmiles(r2)\n  r3_mol = Chem.MolFromSmiles(r3)\n  for prod in rxn.RunReactants([r1_mol,r2_mol,r3_mol]):\n    prod_mol = prod[0]\n    Chem.SanitizeMol(prod_mol)\n    react_dict['product'].append(Chem.MolToSmiles(prod_mol))\n\nreact_df = pd.DataFrame(react_dict)\nZip molecules\nmolzip lets you take a molecule containing multiple fragments and ‘zip’ them together. Atoms which should be bonded to the final molecule are labelled by connecting them to dummy atoms. The code looks at matching dummy atoms (with same isotopic labels) in the fragment and adds bonds between them.\nsample = Chem.MolFromSmiles('[*:1]c1nc([*:2])nc([*:3])c1.CO[*:1].[*:2]N(CO)C.Cl[*:3]')\nsample\n\nChem.molzip(sample)\nRDKit documentation on Molzip and R-group decomposition\nMolZip documentation and early version here\nMore examples here\nEdit, merge, react molecules\nMolecule tinkering using Rdkit: http://asteeves.github.io/blog/2015/01/14/editing-in-rdkit/\nUsing mol2grid\nmols2grid is an interactive chemical viewer for 2D structures of small molecules, based on RDKit.\n\nJupyter notebook explaining simple application\n\nUseful set of functions in RDkit\nPat Walters has made a GitHub repo collecting useful RDKit functions here."
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html",
    "href": "posts/2023-01-16-auto3d.html",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "",
    "text": "import os\nimport sys\nimport copy"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html#view-the-test-molecules",
    "href": "posts/2023-01-16-auto3d.html#view-the-test-molecules",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "View the test molecules",
    "text": "View the test molecules\n\nimport pandas as pd\nimport numpy as np \nfrom rdkit.Chem import PandasTools\nimport rdkit\nfrom rdkit import Chem #This gives us most of RDkits's functionality\nfrom rdkit.Chem import Draw\nfrom rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\nIPythonConsole.ipython_useSVG=True  #SVG's tend to look nicer than the png counterparts\nprint(rdkit.__version__)\n\n# Mute all errors except critical\nChem.WrapLogs()\nlg = rdkit.RDLogger.logger() \nlg.setLevel(rdkit.RDLogger.CRITICAL)\n\n2021.09.4\n\n\n\ntest_smi = pd.read_csv('./tauto.smi', sep=' ', header=None, names=['SMILES','Name'])\n\n\ntest_smi.sample(2)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      Name\n    \n  \n  \n    \n      1\n      C1(=CC(=NC(=C1)Cl)Cl)O\n      Cl-pyridone\n    \n    \n      4\n      N=C(C1=C(OCC2=C(F)C=CC=C2)C=CC=C1)O\n      boo\n    \n  \n\n\n\n\n\nPandasTools.AddMoleculeColumnToFrame(test_smi, smilesCol='SMILES')\nPandasTools.FrameToGridImage(test_smi, legendsCol='Name', molsPerRow=4)"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html#read-the-sdf-files",
    "href": "posts/2023-01-16-auto3d.html#read-the-sdf-files",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "Read the SDF files",
    "text": "Read the SDF files\n\nimport mols2grid\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\n\n\nsdf_df = PandasTools.LoadSDF(out)\n\n\nsdf_df\n\n\n\n\n\n  \n    \n      \n      ID\n      E_tot\n      fmax\n      Converged\n      E_rel(kcal/mol)\n      ROMol\n    \n  \n  \n    \n      0\n      Cl-pyridone@taut1\n      -1242.4485217285633\n      0.0028711010236293077\n      True\n      0.0\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      1\n      Cl-pyridone@taut2\n      -1242.4576208991289\n      0.0029037443455308676\n      True\n      0.0\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      2\n      benzene-fused@taut1\n      -646.5230541429044\n      0.0028541951905936003\n      True\n      0.0\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABmJLR0QA/wD/AP+gvaeTAAAe2klEQVR4nO2deVzU1frHPzPDwAwwbCoqSiSmKIiUinu5pDftel3TRAO31KybVlej1J8t18KtcitxSc0wTS0VUzMXRKWriAsIbogKyioCwzDszPn9cZTgOyyzfec7Q+f94g84Z+acZ+DDOef7nPM8R0QIAYNhasRCG8BomjBhMXiBCYvBC0xYDF5gwmLwAhMWgxeYsBi8wITF4AUmLAYvMGExeIEJi8ELTFgMXmDCYvACExaDF5iwGLzAhMXgBSYsBi8wYTF4gQmLwQtMWAxeYMJi8AITFoMXmLAYvMCExeAFJiwGLzBhMXiBCYvBC0xYDF5gwmLwAhMWgxeYsBi8wITF4AUmLAYv2AhtwN+eqCj8+iuyswHAxwfBwejYUWibTAAbsYSDEMycicGDceECvLxgb4/t2+Hnh+3bhbbMFBCGUKxbRwCyZs1fJaWlZPx4IpWSK1eEM8s0iAhLbisU7dujbVtER9cqVCrh4YGgIGzZIpBZpoFNhQLx8CHu3sXAgdxyZ2d0746zZwUwyaQwYQlEZiYAeHrWUeXlhfR0M5tjcpiwBEIkAoCqqjqqKishtvq/i9V/AGulTRsAePCgjqq0NLRta2ZzTA4TlkC0bo1OnXDiBLc8NxeXLmHQICFsMiVMWMLx4Ye4cAErVvxVUlaGadMgFmPuXOHMMg3M3SAooaFYuRIBAQgMRHk5Tp5EXh527sTo0QBQWQkba90aYcISmnPnsGcPsrIAoFMnTJ+OZ5+FRoOZMxEZidu34eoqtImGwIRlqQwbhmPHsHEjZs0S2hRDYGssCyAhARcucAuDggBg1y7zm2MS2IglNHv3YsIEDByIqKha5YWFaNUKZWVIS3vim7Aq2IglNMOGwd4e0dG4f79WuZMThg2DRoM9e4QxzDiYsIRGocCIESAEe/dyq+hsuHu3+Y0yHiYsC6C+5dS//gUnJ8TGIjnZ/EYZCROWBTB8OFxccOUKrl+vVS6TYeRIANY4GzJhWQB2dhg7FgB+/plbNXEiAOzcaW6TjIY9FVoGJ05g6FC0b487d2qVV1SgdWs8foyEBPj7C2ScIbARyzIYNAitWiElBXFxtcqlUowbB1jfEp4JyzKQSDB+PFDXEn7CBAB3zp0zu01GwYRlMVQ7Fzin/wYOHNG/f4czZy5evCiIXYbBhGUx9O6Ndu2QkcE98C6RdAwMBBARESGMYQbBhGUxiET5wcHfvfTSmuPHOTVBQUEA9uzZU1XnUWaLhD0VWhDXrl3r2rWrq6trVlaWra1tzSofH5/bt28fP358yJAhQpmnF2zEsiD8/f27dOmSn59/QuvI8uuvvw5gl/UcdrBWYf3wA1asgFpdq/D77xEZKZBBJmLixImoS0CTJk0C8Ouvv5aVlQlglgEIGIVtDN27E4DMm1ersEsXEhQkkEEmIiUlRSQSKRQKtVrNqXr++ecB7N+/XxDD9MVaRywArq749lskJAhth0nx9vYODAxUqVSHDx/mVNElvLXMhvwKKyMj4+7du3l5eUql0uSNv/IKunbF7NnQaEzetpDQ2XC3lqs9KChILBb/9ttvRUVFQtilH3w9FVZUVHzyyScnTpyo6daTSqWOjo4ymUwulzs4ONja2jo5OUkkEldX12bNumk0H9nawsEBcjlkMjg6QiqFszMkEri4QCqFoyNkMsjlaNECgwbBxwcffICePfHNN0/Cpfz94e+Pn37i4wOZj8zMTE9PT6lUmpWV5ezsXLPqxRdfPHfuXERExOTJk4UyT1d4mmLnz58PwM3Nzdvb29XV1cnJqWEz/P1nA0THr507SffuZNIkQggJCSEuLiQzk5AmscaiDBw4EMD27ds55d9++y2Af/7zn4JYpRe8hK398ssvq1atsrOzO3bsWI8eParLy8vL1Wp1SUlJaWlpUVFRRUWFUqmsqqoqKCgQi9s+foyyMhQXo7gYZWUoLERVFfLzUVWFwkKUl0OtRkkJSkvRrNlffa1YgchIzJ8Pq/JLN0JQUNDp06d37do1ZcqUmuXjxo1bsmRJW6sIwDe5VFNSUugAvqZmSjFTUz1iEUI2biQAiY5uOiNWXl6era2tjY1NVlYWIeTMmTNhYWHDhw9fvHjxvn370tLShDawcUwsrOLi4oCAAADjxo0zbcscagqrspJ060b69iV+fk1EWISQV199FcC3334bFxdna2vLWWwpFIp+/frNnTv3hx9+SExMrKqqEtpeLiaeChcsWBAfH+/j47Nt2zbTttwAEgm++w59+0IsRteuZuuWX+bOnfvqq68OHTp0yJAh5eXlU6ZMGTly5KWnZGRkxMTExMTE0Bc3b968ew28vLyENR4w6VS4c+dOAHK5PD4+3oTN1knNEYvy9tsEaDojFuW1114D0K1bt9LS0prlSqXy7Nmzq1evDg4O9vX1FdfOp+Xo6FhzPKusrDS/5SYT1s2bNx0dHQGsX7++zhcUFRXl5eWVlZWZpLvQUMJZwuXmktdfJ6tXm6R5i+D7778HoFAokpOTG35lYWGhpenMNH6skpKS3r17JyQkTJo0aWc9J/9Hjhx56NAh+r29vb2dnZ1cLqc+LZlM1rXrigcPBisUkErh4gLq0KKuLFdXeHpi+PBGbKiqQkQEzp/Hhg3GfyDhuXHjRmBgoFqt3r59O+fZsFFUKlV8fHz1vHnz5k1NDSeyg4NDp06dfH196bzZs2dPzkkK02ASec6ZMweAj4+PSqWq7zWjR492dXWVSqV1mjFw4J8NOK5Gj27chqwsYm9PRCJy8aJJPpOQFBcXd+nSBcAbb7xhfGsNj2e2tra+vr7BwcGrV68+e/asqaYUE4xYERERwcHBcrn8/PnzXXVbPKvVaurTKi8vLy4uLisrKyvzKi5urlSiogKFhSgtRUkJVCpUVKCgAIGBePPNxpsNDcWKFXj1VWjts1kZ8+bNW7t2rY+PT1xcHF1gmJDc3Fw6kl2+fPnSpUv3a4f2u7i4dOvWbfLkydOnTzeqGyOFeePGDfrJv/vuO1MI3SgePSKOjgQgsbFCm2IEBw4cEIlEtra2cXFxZuhOpVLVHM8kEgmA/v37L1q0yJhmjRJWcXGxv78/TDRim4T58wlARo4U2g5DSU1NdXV1BbBq1SpBDHj8+PHWrVtFIpGjo2MDC5tGMUpYs2bNAtCpUydjLDAt1YOWNa60KisrX3rpJQAjRozQaDQCWtKvXz/UtVmpO4YLa8eOHQDkcnlCQoLBjfDBBx8QgIwZI7Qd+rN06VIArVu3zsnJEdaSLVu2ABgwYIDBLRgorOvXr9Ol1caNGw3umyeqHw+vXhXaFH04d+6cjY2NRCKJiooS2haiUqkcHR1FIlGjLrT6MERYarWaPgwHBwcb1ivfvPceAcj48ULboTOPHz/29PQEEBoaKrQtTwgJCQGwePFiw95uiLDefPNNAJ07d7acpRWHzEwilxORiFjYLF0v48aNA9CnT5+KigqhbXlCVFQUgLZt2xrmqddbWD/88AMAe3v7a9euGdCf2Zg7lwBk4kSh7dCBTZs2AXB1dU1NTRXKhqKiIk6JRqNp3749gD/++MOABvUTVlJSkoODA4DNmzcb0Jk5ycggcjkRi4ll65/Ex8fLZDIAe/fuFcqG999/38HBIVbL+/f5558DCDJoY18PYanVaj8/PwAhISEG9GR+Zs8mAJk/P1FoQ+qluLiY/kqnT58uoBkLFy4EMGvWLE75gwcPJBKJTCbLy8vTt009hDVt2jQAvr6+2sOmZXL/fmVAQD8bG5s7d+4IbUvdvPPOO3S1Kuyv9Pbt2yKRyMnJSTuYcejQoQA2bNigb5u6Cmv79u10aZWYaLkDgDZ0d9wyh9j9+/dTR6AlrFZffPFFAD/++COn/KeffgLQs2dPfRvUSViJiYl0abV161Z9OxCWtLQ0Ozs7iURy69YtoW2pxf379+nWzbp164S2hRBCtm7dCmDw4MGc8pKSEmqnvm7wxoVVVFTk6+sLYMqUKXo1bSHMnj0bwNSpU4U25C8qKyvpCDFal/NAZqGoqEihUIhEIu1lAx3158+fr1eDjQuLRnZb0dKKQ2pqqq2trUQiuX37ttC2POGzzz4D4OXlZcCimD+mTp0K4JNPPuGUx8bGAmjZsmV5ebnurTUiLDpCKhQKS5tK9GLmzJmCP3lVc+rUKbFYLJFIzpw5I7QttYiOjqZy1475ocfsDh48qHtrDQnr6tWr1MXy008/GWKpxUAHLalUmpKSIqwlubm5NNx0yZIlwlqijUajee655wCcOHGCU7Vq1Sp9J+56hVVYWNixY0cA06ZNM9BSS2LGjBkA3nzzTWHNGDNmDIBBgwZZYCQgIeS///0vgMmTJ3PKs7OzpVKpjY1NJs1loAP1CuvLL7+0tLNWxnD//n06aN29e1coGzZs2ACgWbNmDx48EMqGhqn2iObn53OqRo0aBeDrr7/Wsal6hbVmzRp7e3sLeRg2CdTBq+1fNg90XSESiX777TdBDNAR6hENDw/nlB84cABAly5ddGynXmFt3LgRQGBgYJ210dHRkZGROvZhIdy5c8fGxkYqld67d8/MXavVauqyefvtt83ctb5Qj2ivXr045RUVFa1atQKg40n8eoVVWlraunVrAKdPn+ZUnTlzBoCnp6dez5+WAA3QGzBgwM6dOyMjI6OiouLi4lJSUrKzs4uLi/nr96233gLw/PPPcwKaLZAGPKL/+c9/ALzzzju6tNNQ+FdYWNjChQuHDx9+5MgRTlVgYGBcXNyWLVvoothaOHDgwIwZM/Ly8hp4jUwmc30KDaZt9Ed3d3cbm3qzYPz8888TJ060t7e/ePEiHbcsnDlz5oSHh8+fP3/lypU1y5OSkrp06eLm5paenk7dBQ3QkLAKCwufeeYZpVJ5+fLlF154oWbV3r17J0yY4OPjc/36dU4ApMVSVVXVu3fvuLi4rl27+vr6qlQqlUpVVFRUUFBQWFioUqkMTkgsk8kUCoVCoXB1dVUoFI6OjtU/AggPD1cqlevXr6dbzpZPbGxsr1693N3dHz58yAkw7tWrV2xs7M8//zxhwoSGG2kkYHXBggWrVq2aPHky576Nqqqqzp07Jycn79+/f/To0QZ/BnNCB+AOHTrEx8fL5fI6X0OTwpWUlOQ/RZcfc3JyGrgzomPHjs7OztR/bS0EBAQkJCQcPHhwJL2J8ynh4eFz5swZNmzY0aNHG2mi4Zny4cOHNAOY9oI3PDwcBu17C8L169ft7OxEIpH2ktF41Gp1VlZWcnJyXFzcyZMnDx48GBERsWHDhmXLltGT425ubtonUiyZ+jyiBQUF9vb2YrG40eRvje8V0qf0d999l1NevbqPjo7Wy2jzo9FoaLzezJkzzd977969AWzatMn8XRtMAx5RepXBF1980XALjQvr5s2bYrHY3t5eO9jtiy++gDXkWqWeybZt2yqVSvP3TjOz+/r6ChuDqi90Evzqq6845cePHwfQoUOHhj+OTuexaB/a+94FBQXOzs4ikcgSjqrVR1paGs3ZfOjQIUEMqKioeOaZZwAcO3ZMEAMMg55D9PPz45RXVVXRjIFnz55t4O06Cev8+fN0oaC9vUN9GxYbYEieJvMcX3+QYWxs7Llz5+Lj41NSUvLy8vgIwFq2bBmA4cOHm7xl/qj2iGoHWSxZsgSNnRbRNY0RTV2/du3ad999t2Z5enq6t7c3ISQ5OdkiUl/WZvfu3UFBQW5ubtevX2/ZsmWdr3nhhReuXr3KKaQOKh39WNU/Ojs71+l8yc/P9/T0LC4uTkpK6ty5s+k/Jz/Mmzdvw4YN69evp0k6qrl//3779u3t7e0zMzPrzbKko34jIyNRj7edru7ncS5MsgBycnKaN28OYNu2bQ28LCQkpE+fPv7+/s8++6yrq6sxbjmFQlFf3AE9h/nWW2/x8lH5IT09vb7jDPVdcVCNriMWIaRr166JiYna923cunXL19dXJpOlpqbSP6SFEBIS8uOPP/7jH/84duyYvu+lzip9fVoFBQXff/89/U/jkJyc3KlTJ5lMlpaW1qzmDQjWCXVoTZw4sd5Lo3TXL82w7e/vr/04QFf3n3/+ue6t8Q314Dk6Ot6/f99snRYUFDSQapGu9sLCwsxmD09oNJqxY8fa2NhoR/VUo4ewysvL6dPNkSNHOFV0dd+sWTMLORdPN6Ogz/khM/DHH38AaNOmjdVt3nOgbqYWLVo04CbVL8T+q6++Qj1pk/r374/6c3GbGfqE0bdvX0s7qEkPj1v1Ue8jR47QM/snT55s4GX6CauoqIiuD/78809OFU213a5dO8HzpZw9e1YsFtva2lqgd23z5s0AevToIbQhBpKSkkJ31k3geedA4/zHaCXM02g0NGmWsP+OJSUlPj4+sMhoBUJIaWkp9XrExMQIbYveqNXq6ouSGt1F0FtY2dnZcrlcJBIlJSVxqmgYfkBAgIB7F9R35+fnZ6p85SZn8eLFACZMmCC0IXpDvQGdO3cuLCxs9MWGJF6j5yFnzJjBKa9e3Qu1d3Ht2jUam3r+/HlBDNCFjIwMaqSAYR0GQO/gdHJyunHjhi6vN0RYKSkpEonEzs4uPT2dU/X111+jrhQAZqCysrJnz56o6yCGpREcHAxgwYIFQhuiK2fOnKEn/nbv3q3jWwxMbjt+/HgAH374Iae8enX/v//9z7CWDYZq2tvb20JcHg1w6dIlAC4uLlYRWpeenk43Dd977z3d32WgsOgV4k5OTtoBaB999BEMTQNnMHfu3LG3twdw9OhRc/ZrMPR8mOVH15WVlfXp04f6mPR63jc8z/vgwYMBLFu2jFOekZExb948c+Y602g0gwYNgmUfsuDw66+/AujQoYOledo4fPaZsl27Ye7u7voG2RouLLoB17Jly5KSEoMbMQl0r6lly5a5ubnCWqI7VVVVNHWsUKfEdGHfPiISETc3TXS03inzjbrypFu3bhD60G1WVpabmxuAXbt2CWiGAdBF4csvvyy0IXVz7RpxcCAAWbvWkLcbJSwaNdu+fXtBLoel0MeIUaNGCWWAwRQWFtIrxK9a3hUa+fnkuecIQAzOV2eUsCorK+l4vm/fPmPaMRi6UnFxcdF2fFgF7733HiwmcVc1Gg35178IQLp3JwYvc4y9r3DdunWoP8UDr+Tl5dEwIUu4KtEw7t27Rz2CWVlZQtvyF198QQDSvDkx5sCRscJSq9UtWrQAcOrUKSOb0heap++ll16yrugXDjTc97PPPhPakCccPUrEYiKREIPuo/gLE9wJTTNq+vr6hoeH79mz5+TJk1euXElNTeXV+3f8+HGRSCSXy606hyUh5PTp0wDc3d0Ff7gmhNy9S9zcCECMP7JpgjuhHz16NGbMmISEBJVKpV1bM9yAg4eHR+vWren3zZs31/0u9ZKSkoCAgOTk5C+//PLjjz820n7B6dmz58WLFw24rd60lJSgb19cvYqxY7FvH0Qio1ozgbAoCxcufPToUV5tiouLdXy7VCp1q4dmzZrV/MbJySk0NHTFihXdunW7cOFCA2lerIUdO3ZMmTLF398/Pj5eZOTf0whmzsSWLejcGRcuQKEwtjWTCatOSktL8/LyHj9+zBGcdolardaxTRsbGxsbm4qKipiYmF69evFnvNkoLy9/9tlnMzMzo6KiaPSL+dmyBTNnwskJFy6gUycTNMjvv7tMJvPw8PDw8NDlxTUjXmqSmZmZkZFR/WNubq5MJpNKpVaRa0oXbG1t58yZs2TJktWrVwslLG9vtGyJlStNoypAnygdC6GsrIxe6/Dpp59q10ZFRfXt2/fAgQPmN8wYcnJy5HK5WCzmdY/1xg0SGko4Psdr10hoKMnJIYsXk6VLuW85coQsXWrIze3WJyxCyNmzZwE4Ozs/fvyYU0Vvyfbz87PwzV1taG7EuXPn8tfFoUMEIHI5qaneffsIQG7cIP/3fwQgHNcNfYsB5yatIxkfh/79+7/88stKpZJGDdVk6tSpPj4+SUlJu3fvFsS2hrl37159KdpoqPTmzZvlcrmHh4efn9/QoUNDQkLmzZu3fPnyHTt2HDp06NKlSxkZGZWVlcbYoFDg/feNaUA3jP0vEIg///wTgIODQ3Z2Nqdqx44dADp06CB4vBAHlUrVrl273r171xm3ThPrc1Iz1olcLn/mmWd69er1zjvbpk0jH31EvvmGRESQP/4g8fEkI4PU97np8LNuHQFI9WKBpxHLWp/V+/TpM3z48KNHj65cuZKTg3XSpElhYWE3btyIiIigFw9ZCPPnz793717z5s21ExFcvnx5yZIlIpHo2LFjvXv3rvnIov1NTk5OWlpaWlqaTBYUHV13Xy1aPPlq1Qru7mjRAt7ecHYGgKFDMWoU3noLAwc+KeEFvaVoMcTFxYlEIplM9vDhQ04VnQe9vLwsJ1bn2LFj1Nrr169zqsrLy2lYlY4pQ1QqVXJyckxMzOHD6Zs2kc8/J+++SyZOJAMHEj8/4u5ORCICcL8CAp4MPzdvkps3iZ0doWfuq0esN94gABk0qNaXhwcBDNnesdYRC0D37t1Hjhx58ODB5cuXr127tmbVhAkTwsLC4uPjt23bRu8rFBaVSkVvxFi4cKF2GqPly5fHx8d7e3vTzJ+N4ujo+Nxzz9ELleqkqgqPHuHRI2RnIzsbjx4hJwc1R0kfHyxYgOXLERLyV+GDBwDQt2+tppRKZGSgqEgXu2qjtxQtiWvXronFYjs7O+0kAr/88gsADw8PXm8G0BGaiLtHjx7ay76EhARbW1uRSNRwxLpJqB6xCCFlZcTHh/TrR/bu5WWNZd3CIoTQhOOzZ8/mlGs0msDAQABrDTsBaTpOnz5NQ/7j4+M5VeXl5TSBvnmy7tYUFiHk8GECPJkBmbC43Lp1i96Qo30XIU0n0apVKwFTYdMnQdTjzg0LCwNAb2kwgzEcYRFCxo4lYjETVj288cYbqOdeRZoKe9WqVea3ijJv3jwA3bt3154EExMTaer548ePm8cYbWFlZhJnZyasekhOTraxsZFIJDdr/s4IIYT8/vvvAJo3b65LugGTEx0dLRaLpVKp9qn2yspKuoNuzntGExLIrFmEc1h11y4yaxbJzCTjxpHx47nC2ryZjB9PtBKiNU5TEBYhZPr06ajralDyNDS00bQ7Jqe4uJheUVtn3psVK1YA8PT0LCgoMLNh5qGJCIteoCoWi7UXyKdOnQLg4uJi5ivjaaLybt26aU+CSUlJdnZ2AA4fPmxOk8xJExEWeZoD57XXXtOuonHS2hcg8AdN/iaVSq9cucKpqqyspCu/kJAQs9ljfpqOsNLT02niLu2/ZUxMDAAnJyft0xB8UFxcTJO/LVq0SLuWbpy3adOmqU6ClKYjLELI3LlzAYwcOVK76pVXXgHw8ccfm8GM0NBQAP7+/tobSrdv36Y32llyZL1JaFLCyszMpDlntBOvXbx4USQSOTg48B3BFxsbK5FIpFLp5cuXOVWVlZU0c0udDxlNjCYlLELIggULAAwbNky7asSIEQA++OAD/novKSmhW4F1Do1r1qyhDlsrSl5iME1NWLm5uQqFAnXdonj58uX6TkOYCppf1M/PT/tS8eTkZDqaHjx4kKfeLYqmJixCyKJFi1BPusqxY8cC+Pe//81HvxcvXqR+Wu2JWKPRDBgwAMDrr7/OR9cWSBMUVn5+Ps1Frh31n5iYSPeDtW8iNpKysjJ6OYB2+kxCyPr16wG0bNny0aNHpu3XYmmCwiJPo/779eunXTVu3DgACxcuNG2Pn376aX2T4J07dxwcHADs2bPHtJ1aMk1TWCqViqYq+f333zlVSUlJGzZsMO1tNpcuXWpgEqTu2To9t02Ypiks8vRESvfu3c2QiyYqKqpNmzZ1pgGn11G7u7v/fSZBSpMVVlFREb1cJDIy0gzdFRQUaJ/6SklJoZOgVd/KZBhNVljk6eaJv7+/IMGrGo2GJpYeO3as+XsXnKYsrJKSkrZt20KgTJb0oi83N7f6br9t2jRlYZGnz/nmj7hPTU11cnIC0MAdpE2bJi6ssrIyeuTcnKscjUYzZMgQ1HX53t+HJi4sQsimTZsAeHl5RUVFXb169e7du3l5ebwOYFu3bqWTYEZGBn+9WDj8Jl6zBMrLy319fQkhd+/e5VRVp7GUy+XaKS21C93c3GQyWcPdPXz4sEuXLkqlUvDUj8LS9IUFoLS0dOnSpadPny58Sn5+vmFNubq6OtXG2dnZxcWl+sfw8PDz58+PGjXqwIEDpv0U1sXfQlj1UTOHYGlpqXZKQU5hXl5eWVlZw216enoqlcqEhAQvLy/zfArL5G8tLH3RaDRKpbKgoKCwNgUFBUqlkn4fEBAwefJkesHf3xkmLAYvWGVGP4blw4TF4AUmLAYvMGExeIEJi8ELTFgMXmDCYvACExaDF5iwGLzAhMXgBSYsBi8wYTF4gQmLwQtMWAxeYMJi8AITFoMXmLAYvMCExeAFJiwGLzBhMXiBCYvBC0xYDF5gwmLwAhMWgxeYsBi8wITF4AUmLAYvMGExeIEJi8ELTFgMXmDCYvACExaDF/4fZQzagMbpajEAAAFyelRYdHJka2l0UEtMIHJka2l0IDIwMjEuMDkuNAAAeJx7v2/tPQYg4GVAAH4gFgTiBkYOBg0gzczE5gCmWdgcMkA0MyOcwe5gAWIwMuNWgk8GbgpYCZIhEJqbgVGDiZEpgYk5g4mZJYGFNYGVLYOJjT2BnSODiYMzgZMrg4mLO4GbJ4OJhzeBly+DiZcjgY8xgY81QYSZjZGPlQXodjZ2Dl4+VjZOLm4eXg7xfUCDGaGYgb9n52T7UyGGDj8N1exePzpmfyn/vL3K9HprTmk7hzOxq+03zdXfZxQa47BU57Dtgzkb93FvVXPouV2x3/7Ynn3S8+bZWylH7f+mEbNvl+cbu9MLGQ8If2rc1yWfvL+v9Of+C5tv7p3FcXh/fqPJfqPQDbZBO6wOvMiS3p+tXWbX4BF/wGGJvH1y/U27+/6aB2Qt7ts/l31up7Vy9X5VtptAd8y34+yy3x+045/dUh1mO05pPftFW67bpUo+2iMGAGn3azzpsO3OAAAB0XpUWHRNT0wgcmRraXQgMjAyMS4wOS40AAB4nH2TzY4TMQzH732KvEAjfyVObmzbFUJopxIU7iCKxGUvdC88PXYybTIcmKmjGc8vjv23+/36+uf6et3/fPt9/fHu9u3thrvg16fTx1+38Lj4tDM//OdXaw1fGQB2L8EfwuH5/YclHC9Ph7vneP6yXD4HTAHV9ti9ZZ8u55e7B8M5YMQkCBAoqkKxB4iYiWHaSeFoXErsnzFmgtw4AK4zx8ZRrArSOObiG/YWUDHNoBjIUYS0x6mJO8iSNxFTWCxiBlkDVSVcyVx0JnPLkbhS/17SnSQ/eyLVSIiSW0p7ikAprWSv8EEWIz1U0RYUY5VS14ogbySqjppGxNoBhYS9uJJxJhEcNZlQ12MzaEdJmnIDRUdNqFJ6Y6wvXXkh2WSK1INmabVgVOmtiZJwG5NNUsuUBbF3s7Ytpij+Q0ovX6VQD1W1k0hlW1JqkuYCuGaHaz+BNM/k83LaTGCfycN5OY2ZJLcxemLGY8LEbcyR32lMi72EPEZCzHT0XczKaK6Y1dFAMcO5TeIL4tQN8QVpUl18QZ7UFV9QJhXFF0yTWs3zOBo9UfOOuNodeZZtFsnf7396e979BVWe1C3hFMHmAAAA7npUWHRTTUlMRVMgcmRraXQgMjAyMS4wOS40AAB4nCWPO24EMQxDr5IyAWYMUX/DSJ9uD7BI5X5PsIeP5BQ2oGeaFB/fG3s/Xz+/m/feUudVN/jj/YkBU1w8IigvGnCWhWEmeWE4kxckkrl4zCAtKJJ53SUN2JKhytGaadJU1FvrpEc0g3GwZ5Qvy+Qe0/4xlwUNddh18yA2O7TSV6sySo0xNedJJJdVs7FEz0GGjk7Hqu8Tcb47RWNW0nXXgpndrIp1F2XNFrtWFkaozKYGbWdRoHvPeqyl0bRyNLlFM5qCE7W0J+H44fQmDv96/wFM80q6WlGlEgAAAABJRU5ErkJggg==\" alt=\"Mol\"/>\n    \n    \n      3\n      benzene-fused@taut2\n      -646.5449096909285\n      0.00297327502630651\n      True\n      0.0\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      4\n      benzene-fused@taut3\n      -646.5199764570714\n      0.0022692130878567696\n      True\n      0.0\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      228\n      sildenafil@taut9\n      -1883.1668644994259\n      0.0027246379759162664\n      True\n      2.6457204767372136\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      229\n      sildenafil@taut9\n      -1883.166294679022\n      0.0028603156097233295\n      True\n      3.0032881786646404\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2deVyU1f7HP88MMIAgCCJiiEIiiyjkljcQ0Lx5RbumRq6oaWEuUamFdk3Mm4qWV9pU1Ew0/RVmJe65lKVc5SIuqAkGKEssKvs+y/f3xxmHyRRne2ZYnveLP+Z55jnnfGf4zFm/53s4IoKAgKERmdoAgbaJICwBXhCEJcALgrAEeEEQlgAvCMIS4AVBWAK8IAhLgBcEYQnwgiAsAV4QhCXAC4KwBHhBEJYALwjCEuAFQVgCvCAIS4AXBGEJ8IIgLAFeEIQlwAuCsAR4QRCWAC8IwhLgBUFYArwgCEuAFwRhCfCCICwBXhCEJcALgrAEeEEQlgAvCMIS4AVBWAK8IAhLgBcEYQnwgiAsAV4QhCXAC3oJ67vvvhs4cOCqVasMZY1Am0EvYeXk5Fy4cKG0tNRQ1gi0GfQSVlVVFQBbW1sDGSPQdjDTJ3FlZSWAjh07GsiYNkdVFRYsQGYmzM0hkWDTJvTqZWqbjIRewhJqrMewciVcXZGQAACHDyMiAv/9r6ltMhJ6NYVCjfUY9u3DW28pX4eFobwcBQUmNch4CH0sPrl3D46OTZdduqC4GAAUClNZZDSEGotPunXD7dvK1woFcnLQsycUCkyciFdfhUymdYaVlWglR9QYQFhCjfVIZs/GkiVobASADRswZAgcHHDxIvbvx7ZtmDoV9fWaZvXdd/DzQ0QEAgIQHd0K5EV60LNnTwDZ2dn6ZNKWkctpzRoaOpSGDqXXXqPKSuX9s2fJyYkAGjyYiosfn09hIXl4UEkJEZFUSs8/T998w6PZhkAvYTk4OAC4e/euoaxp45w/T7W1ytfp6eTmRgD5+korbj0m4e7d9NprTZf799O0aXwZaSCEptBYnDuH0FAMGaIcGPr5IS0NQ4eWTu58Lad/dfWZ5tLeuwcHh6ZLBwfcu8evtXqju7Dq6upkMplEIrGwsDCgQW2WDh3QuTOuXMGwYcjKAgBHR/rxSOkkW5ms9ObNURUVRx5MIpfj/fdRUgIPD2RmNt2/cQNPPmk8y3VD57quuLgYgJOTkwHrzzbO3bsUFEQAdepEp0/fv6vIz38nNRUXLoiLiz9VPauoKaORIwmg4cOpsZF8fenAAVIo6OZN8vKiq1dN8gk0R3dh3bx5E4CHh4cBrWn7VFXRmDEEyJ8JKC/br7pdWLgqNZVLTUVl5Ukiqq1NT0/3qJsxlNzc6OJF2reP8vNp+nQaNoxGj1YTZctFd2FduHABQEBAgAGtaRfIZPLlb1875XThgrik5HPV7bt3d96+PY9IoVBI09OfTE3FjcuDKfMGvfgiAbR2rQlN1gHd1wrZtLswO6o1YrHo/XVd7vbOzZ2bmzu/vj6je/cNgMjRMUKhqLx2zY/jzCQSzw4dBrm4rMi+OM/9/A2uUyc89ZSp7dYO3YUlDAn1oXPnV8zMnHJyppSUfNLYmOvuvhsQ/fFHTN++uSKRNZFUJiv97Td/qUWxRfwI1yc/R+/epjZZO3QfFQo1lp7Y24/19DwiFneqrb0gl5dznAhAefkPRFKOMzc3d3ZwmG5v/0K3kd+3OlVBH2E9tMYqKirS16L2hI1NsLf3WU/Po+bm3TjOonfvn8vLf7h61bO09KuGhhy5vNzR8WVAbGozdUFfYanXWN9++62bm9uKFSvkcrkBTGsfWFr6WFr6stdWVn4eHone3sm5uVGlpf939+7WrKyxly51zMgIKin5uLEx17SmaoW+TaGNjY3qzrlz56RS6fvvvz9ixIhbt27pb1w7Q9HQkAMAEHGc2M5ulIvLMisrfyJZdfXZvLw309Pdb9x4Jikp69o1ExuqETqPJ3fs2OHr6+vp6ZmRkaG6eezYMVdXVwBWVlaxsbFyudwQQ9d2gVR6JyvrxczMkTduBJaWfqN+/+7dhKys8IsXbf/3P5GLixwgJyeKiKDERKqqUj42dCgdO6Z8HRVFav8T06C7sBoaGtzd3QHY2dl9+eWXqvvl5eWRkZFMtSNGjMjNzTWAmW2dysoTBQXLZLLyZp6RySry849Pm0YODgQo/zp1osmT6YcfyMmJAgKUa9xhYXTxopEsfxR6eTeUlZWpNPT3v/89Ly9P9VZiYmLnzp2Z7OLj4/W2s43z229Pp6aiqOhDDZ+/epViYmjAAOI4Aigignr0oDVraNkyojYgLIa6hnbu3Km6X1RU9M9//pPJbsKECSXMnUjgL5SVfZ+aisuXn5DL67RN+9tvtHYtnTxJPXpQfT316UO//dZWhEVERUVFY8eOZRoKDw9X99BKSEhgUxJdunT5/vvvDVJc20J+7ZpfaiqKi+P0yaVHDyKio0dp5Mg2JCyGSkPOzs5JSUmq+zdu3Bg8eDAAjuPmzZsnk8kMWGhrp7R0b2oqrlxx1aG6UocJi4hefJEcHCg5md59l2pq9DdQRwwpLCK6devWsGHDmIYiIyOr7g9aFApFfHy8tbX19OnTDVtiK0d+7Vqf1FSoO8xoS1ERXbvWJKzCQrK3p/HjCSA/P7pxwyB2ao2BhUVqGgLg7u5+Ws3HIy0tTfBjVqe09OvUVFy50lOhaNAth8ZGCg4mW1s6depP9zMzKSCAALK0pG3bDGCqthheWIzr168PHDgQgEgkioqKqq+v56mg1otCIbt61Sc1FSUlm3TOZOXKUwC5uNAffzz4Vl0dRUUpZyUiIpq87Y0DR7xtJJLJZOvXr1++fHljY6Ofn9+uXbsCAgJ4Kqs1Ulq6OydnmkTi3qdPBseZ65BDQkLCzJkzQ0JeWb166zPPoL6+vq6urrKysrGxsbKysq6urr6+/sCBivj4xoaGKlfXusmT683MKhobG6uqqp5//nkfH58n+XNx5lu5ly9f9vf3B2Bubh4TEyP03BkKhTQ93TM1FXfubNUth7q6OkdHRwC2trZ2dnba/t/79u1raWkZGxvL03+ExxpLRU1Nzdtvv71582YimjZt2q5du/guseXzv//tMzefJxZb+fllcpyOu1E++uijt99+W3UpkUisra1tbW0tLCzs7OzULzt0sDt/3rKq6l5e3p7AwMCJEyeePn163759RDR8+PDt27f36NHDQJ/sPnyo9aGcPXvW2dk5NDT0559/NlqhLROZTObl5dW5c4eUlK/0yaeqqiorK6u4uLisrEyT5z/++FNzc3MAzz77bFFR0dmzZ3v16gV+FnaNJywimjhxIoA9e/YYs9AWyLZt2wB4eXkZv2OQlpbG+lWdO3c+cuRIRUVFZGQkx3EAAgMDMzMzDVWQUYUVHh4OIDEx0ZiFtjQaGhpYu6O+/GVMKioqJkyYAIDjuOjoaJlMtnfvXrYoZ29vn5iY9dBUNTU1xcXFWVlZqampP//888GDBw8dOtRMKUYV1gsvvACgnS/sxMfHA/Dx8THhOEYuly9fvlwkEgEIDg7esGFDTEyMn5+fk1MAx73s7BweFDRiyJAhfn5+PXv27NSpE3vyAaytrSsqKh5VhFGFNXr0aAAHDx40ZqEtivr6ejc3txbSHzh9+rSLi0v//v016YtbWlp27tzZw8PjqaeeCgoaam9vD2D58uWPylyvUJHaIpVKAbD+Y/vkiy++yM3N7devH+tumpbg4OBz585lZGTs27fP3t7e1tbWxsZGobD5+uuOKSl2gE1goO2HH9p4e9vb2tqamTVJZfly3L6dHRS0ZsmSJY/M3Zg/EbaMeOqB1Yd2Q21trYuLC1pDLzMxUelOaGdHD3jTyWQ0bBiJRHTmTHM5GPVkinZeY23durWwsNDf3//FF180tS2PITwcqakIDUVFBebMwZw58PZGbi4AiMWoq8OJEwgMbC4HowpLJpMBUK9U2w+1tbVr1qwBEBMTw4b3LRx3d/z0ExIT4eyM0FDU1yMqSvlWbi6GDXtMcqHGMgZSqfT1118vKiry8/NTeUS2CsLDkZGB3r0xYADEYuzfr2lCQVj8UldXt3btWldX1+3btzs4OHh7ez906N6SUa1Drl+PJUtQU6NRKkFYfCGVSrdu3err67tkyZKSkhIPD4+Kior9+/ez8E+tkZ49MXMmYmM1elgQluFR1VKRkZG3bt0aMGBAUlLS77///sorr0il0uaG6C2ehQtx7BgaGjR4lNdR6wOwpYxbtx4Xy7XVUltbGxsb26VLF/bdMkk1NjbGxcUNGDDg9u3bLCLBL7/8YmpLtSM9nebOVb7+5Rfy9398EqMKq1u3bgDy8/ONWahxeKikFAoFezcwMBDAypUrV65cCWDw4MGqt1oLNTX03nu0VWPnMaMKi33vxZpENm89PCCpgQMHqkuKce7cOY7jbGxssrOzu3fvDmD37t2mMlg3rl8ngDw9NX3eqMLq1KkTgNLSUmMWyh9MUk5OTipJHT9+/FEPM8+OyMjI7du3A3B1da0x4eYs7Tl+nAAKDdX0eaMKi4WmUe0Ja9XU19f/5z//YZLy8fHZs2dP845y2dnZEolELBZfvnyZrfuuWbPGaNbqz44dBNDUqZo+b1RhSSQSAG1jx86mTZsA9O7d+7GSUvHWW28BCAsLO3XqFABbW9vCwkK+7TQUq1YRQO+8o+nzRhUWmxtsA7GNGhoaWFfphx9+0DxVaWkp2/7w448/jho1CsC8efP4M9KwzJtHAMVpHAbAeMJiYf5EIpHRSuSPrVu3AujXr5+2g7v169cD8Pf3T09PNzMzE4vFV1v8UQCMsWMJoL17NX3eeMJKTU0FwDoZRiuUD6RSqYeHB4Cvv/5a27R1dXXDhg3bvXu3XC4fPXp0ly5dTreG0wCIaOBAAig5WdPnjSEsuVy+bt06iUTCVvXFYvGcOXNab1SjnTt3AvDy8mJtenl5uXpgMM0JDQ0F8Pnnnz/+0RaAiwsBdPu2ps/zLqwbN24MGjSINYILFy7817/+ZWlpCcDa2jomJqauTq8QK8ZHLpd7e3sD2LFjB7sTExNjYWHx2WefaZXPuXPnANjZ2TXjNt5ykErlXbsWchw1aBxigkdhyeXy2NhYKysrNm2jmuPJzc2NiIhgA3VXV9eEhAQdpqE3b9588+ZN9jo9PV31b+abxMREAL169WJbIUpLS9kqzfnz57XKZ9KkSQDeeustfsw0MPn5+QDc3HponoQvYeXl5Y0YMYKpJzIysrz8weiaP/30E9t6DyAkJOSilpHCxo0bp1pxO3jw4IwZMwxidvMoFApmM9vVTURsiea5557TKp/ff/9dLBZbWFjo1oYaH1a/9u/fX/MkvAhr/34KDb0jEpl17NhRPe5tcXGxes0vl8sTEhKcnZ1ZQxkREVFUVKRhEZoIKyODVEGTCgrozh1dPos6SUlJANzc3BobG4mosrKSnTGrbQc8KioKwLQWf0qqin379gF4/vnnNU9iYGFVVdGrrypD58yefVLdkSE+Pt7Ozm7y5MkPJCkrK4uOjmZzpzY2NjExMZrMoI4bN27IkCGjRo0aNWrUwIEDHyqs0FAaOpRYM7t8OW3Zos8nIyJicQnj7k/mrFu3DkBwcLBWmdy9e9fa2prjuCtXruhrkLH45JNPALymfnzw4zCksH76SXnMsY0NxceTquNUXl4+ffp0VatX+7BITZmZmWw1jfVgmtnH8sEHHxw+fHjcuHFHjx6tqKioqKjYu3fvo4T17LPEVnv1F9aPP/4IwMXFhQ04amtrWV17TBVeXTM++OADHVpP0xIdHc28MzRPYhhh1ddTVJQyNPTQoaR+rP2JEyfYJLWlpeX69eubn3Y/ceJE3759mbyGDx/+19+0QqG4ePFi165dQ0NDm2kKZTIqLaXQUEpOpt69qazMAMIKCQkBEBsbyy7Zj/iZZ57RKpO6ujrmB9HMcnULZNq0aQC++OILzZPoIqzdu0lVREoKffYZPf00ASQW07vvNo1Iq6ooIoJCQi6w9iJbXW6PRiqVxsfHM5cBMzOzyMhI9Rmvjz/+ePLkyYcOHbKystp7fxr4wIGDY8fOSEykmBgaM4Y8PMjMjEaOpNBQysqiuDiaP19fYf3yyy8AOnfuXF1dTUQNDQ3sAI79+/c/Nq06bMpeq15wS2D48OEAjh49qnkSXYQ1dy7Z29P160REe/ZQZCQ5OJC/P6nXL2lp1KcPASSR0Nq1X7HeruaUlpZGRUWxjWKdOnWKjY1taGior69PT08fNmzYokWLXn755d69e7/zzjvTpy90dq4AbqsOawBIJKKhQ5XCkkppwAAaP14vYY0cORLAihUr2OWWLVuYPrSaKJHL5V5eXq3RGYuZnZ6ernkSHYW1bBmFhpJCQXv20KJFlJxM1dXKdxsbKTqazMwIIH9/0saYB0lNTQ0KCmIto7+//5QpUzp06ODn5ycWN520Zmdnz3GKLl1ozBiKjqaEBLp6laRSIlIKi4jOniWRSHdhpaSkALC3t2eTJqolnW+++eaxadVhg8oePXpImX2tB+bvpJUjnY7COnSIpk2jHTuUwlJn3TpltREZ2aQ2fTh+/Li3t7e5ublKTxzHeXh4jB07dtmyZYmJiRkZ0ocGbvnoI+UUg1xO0dH06686GsB2Ai5dupRdsiWdPn36aOumMXToUAAbNmzQ0Q4TIZfLd+zY8f7772uVSndhFRaSpydt3vygsCoracgQOnBAh4wfCQv94+bmFh8fn5ycXFlZqXlaqZS6dyeRSMd5rMuXLzOvYhZIXLWkk5CQoFU+ycnJABwdHasN8mtr8eguLCL65BN68skHhcUHzzzzDAD1uVbNkUopLIwA0i3OGQsLs3DhQnb5zTffAPD09NQ2uhWL1/Duu+/qYkQrRC9hyeX09NO8C+v69esAOnbsqO1vPSWFBg2iSZPo008JoL9MzT6eS5cuiUQiKysrlavnihUrxGKxti4JN2/eFIvFlpaWbWwjSTPoIqzbt4kt/WVm0po1yuEhf7DZudmzZ2ubMDubALK3p5s3CSAHB9KwlqmpqUlISBgzZoyFhYWjo+OoUaPU371586a2Thnz5s0D8Morr2iVqlWj1wRpaKh2XoU60NjYyCa4zzQfjukReHkRQL/+Sn37ygcPLkpNbW6vrEKhOHPmzPz581Ubbxhubm4PXS3QkJKSEmtra5FIdMNU59qYAr222I8cCQDHjumTx2M4duxYcXGxj49PYPPhmB7BhAkVISGXzp07EBLyRkpK10OHEv76DBGdOXNmzpw5Tk5OQUFBn3/++Z07d/r37x8XF5ednT148ODc3NxYDSMWAADy8/PVY9lv3LixtrZ2zJgxbDaovaCPKtPSCCBXVwOJ/GGMHz8eagsp2nLs2DEAAwYMOHz4MICnn35a/d20tLSoqCj12Pmenp4xMTHqfujJyckcx1lZWeXk5Dy2uMLCwsjISDYzcu3aNSK6d+8eC0j8q86zHa0TvYSlUCg9VnnqZhUXF5ubm5uZmWnuTvMA9fX1NjY2HMfdunXLyspKJBKVlJRkZWXFxMT4+vqq9OTi4hIdHf2ofQ2TJ08GMHHixGYKqq2tXbt2LduRC+CFF164fv16bGysg4ND3759tXI4aRvouwg9bRoBxNOcH9vTMmbMGH0y+cc//mFvb3/69Gm2LNOvXz/VRKuNjc3UqVMPHjzY0KzLbV5eXocOHQA89EyN+vr62NhYVi0BCA8PT09P37t3r6rhCwwMbD7/Nom+wtq1iwD687DJYPTp0wcAO/JFZ4qKitgSyvTp09nKsa2tbURExPHjxzWfi1qxYgWAgIAA9SRyuTw+Pl7VkgYHB585cyYxMVFVF/bv3791eTEYEH2FVVREHEfW1mTwXRFshc7JyUnbBeyHUl5eziqVRYsW/dVP+rHU1tYyAW29H2/lwIEDfn5+TED+/v7Hjx//6aefhgwZwu4wl7JWF1LGgBjAH4ud5GnwX+bcuXNhuO0G7JQsfdzr/u///g9Aly5dysvL7927x46QdXFx2bhxY0pKisrBv2vXrvHx8Qb5MbRqDCCs6GgCaPFi/XNqoqamhp3Bp5WrxqO4ffu2paWlSCTSc69scHAwgMWLFxNRbGzs6tWr09PTw8PDWeiAjh07xsbGtpOlwMdiAGGdOkUA9e2rf05N7N69G8CgQYMMktuMGTNgiM0LaWlpbHdNRkaGamYBgEQiiY6OvqP/bo02hAGE1dBANjbEcVRQoH9mSljLsnHjRv2zSktLE4lEEonEICEqZ8+eDcDHx4cdJqOaWdA/5zaGAYRVXk5vvkk//KA8zlr/+JpZWVkcx1lbW+vQy/4rLK6Lyj1BTwoKCiQSCXN8Cw8Pby0hPYyPAYSVnExAkwNWt276ZsjG9lOmTNE3I6KzZ9NZ78dQoSIyMjKYv8NeXpdIWz+GEVZICPXtSyz0oZ7CksvlPXv2hCH2sSgU9Le/Ub9+v27YsEvPrFS8+uqrAF5//XVDZdhWMYywJk2iNWsoOpqIqFs3ysmhs2dJt1CjJ06cANCjRw/947N9/TUB1L27webYCgsLWbhHDXcctWcMdl7SwoUYMAAzZgDArl1YvhwA7OzQqxd8fdGnDzw84OsLHx80f+THl19+CWDmzJl6Hg3S0IClSwFg+XJYWuqTUxObN29uaGgYP368u7u7YXJsuxhMWBYW2LABCxcCQKdOCAhARgYqKnDhAi5caHrMwQFjx8aLRP/z8vLy9vb29vZ2d3dXnQdWXl7+3XffiUSimTNn6mnPli3IyUGfPnj5ZT1zUlJXV7dx40YAC9mHFGgWfYV16VLT6xEjkJAAqRQLFmDBAgAoK0N2Nq5dw/XryhcZGbh27VBKygFVKgsLi169enl7e3t5ef3xxx91dXXDhw9n3SydqazEypUA8MEHUNsqphdfffXVnTt3hgwZoptnWLtDn3b0ww+J4+i990h1wHF+PjW/wb+8nFJSLu3YsWPp0qXjx4/39fW1sLBQt8fR0XH16tX6WEVEy5YRQIGBembThGqvqbZ7CdstuguLreSYmZGeX7VUKs3MzExKSlq3bh2LPhUYGKjPWlteHllZKT2SDUXdiRO7hg7t5+kpLAJqiI7CWryYADI3N7DDe35+vlgs5jguNTU1KSlJt0ySk+mJJwztyfPccwTIP/rIoJm2ZbQWlkJBc+cqVfXtt4Y36KWXXgLQtWvXKVOmFBQUaHhQ1oUL9M47xCYoKivpvfcoKYnU/bjeflsPmy5cUG730WajbDtHuyG9QoHXXsOmTZBI8P33mDDBcH29+yxatAhAVVXVlClTBg0adP78eU1SZWdj40Zs2wYAdXU4cAClpUhObnpg+3Y9bGJHm0RGwtZWj1zaGZprUKGgBQt4aQEfgLnLOTg4fKTW9GzZsqUZB9+9eykyknx8qLiYiospIIB27PjTTlpHR12tuX2bzMzIwoLa4ml4/KFpjSWXy6dOnXL16geWlkhKwosv8qh1Np6XSCT//e9/VTfXrFlTX1/fTCpbW7zzDhYvbrrz/fcYM0b5p1Doas2nn0Imw6RJeOIJXbNol2iiPrlcztbIJBLJkSM5PGudZDIZm9oOCgpS3XR3d39USPSCAtq7lxYtIoWCgoPpu++UNdaCBVRWpvzTscYqLydbW+I4aj3xQlsIj58glclkU6dOTUxMtLGxOXjwYEhIT761LhaL58+fv3jx4rS0tNdff53dvHfv3l+fLCnB4sXYvRsxMQDAcdi4EeHhkEgAQCLBfacpXdm2DVVV+PvfcT+ApYCGPKYplEqlU6ZMYao6dOgQi8NpBF599VVra+va2tqgoKBZs2bNmjXL9s8dZ4UCW7fCzw+7doHjkJ2tvN+nj0Gb6aefRlgY3nzTcDm2G5qpzRobG1nwHVtbW+Nv5J0wYQKAWbNmsUv1pvDoUWVQBoDCwigzk6qrm0K6NzRQXh7du/en3rZ2zu4nT9I//kGDB9PEiXT//AsBrXiksOrr60ePHs1UpVtADj3Zs2cPx3ESiYSFEGLCKi4unjnzZV/fara1f88eMvwOKxY+lflZnztHHh7C9JUOPFJYCQkJADp06HDq1CljGqSipKSEnY/FQsoePnz4448/Zp7m/fvPX7rUMHEoH8KCBbR9e9PlK680LYUKaMwjhaVQKBYuXGja0/RYEOwuXbokJSX17t0bAMdxERER+bxOKY0dSydPNl3++9+ka0iS9swjR4Ucx7HQCaZi9erVFhYW/fv3T0tLGzt2LBF5enrGxcWFhYXxW3DXrigubrosLsagQfyW2CYxtbIfTkVFBYsS89lnn82YMcPR0XHz5s1GimJ97BiFhCi3HOXnk7s76Rrrpj1jMA9Sw7Jnz57q6upnn312/vz5AA4cOPDmm2+amZmxbX388txzuHoVgwejUydUV2PjRjg7815om0Mvv3L+2LRpE4A5c+awy507d2ZnZ+fl5Rmp+IULkZ6OI0eQmoq8PAwejLo6IxXdZjB1lfkQmEeDi4sL86orKChgB76b4NhIhYKGDCGAliwxdtGtnJZYY7HjAmbMmMEiI+zYsUMmk4WFhbHoVkaF4/DZZxCJ8J//4MYNY5feqjG1sh+ktLSUxXRke/dkMpmbmxuAgwcPmsym2bMJoBEjTGZAK6TFCat227bk0NC3X3qJXR45cgRAz5499d+/qjt//EEdOxJAunpLt0NanLDIx4cAlVvx5JdeAhATE2NSm0j+4YdxAwf29fERwl9pSAsT1tmzBNATTygPhisslDs7nxk+3OSnvTc2Nvr4+AD497//bVpLWgstrPMeHw8AL78Mtjd62zZRcXGgnZ0Juu1/xtzcfMuWLRzHrVq1Kicnx7TGtA5MrWw17t0jKysSiyk3l4hIJlOeXa7NibG8MnXqVAAvvPCCqQ1pBbQkYW3YoHSwYhw+TAD16sWDZ4yOFBUVsciomzZtMrUtLZ0W0xQSKdvB+7Pt2LoVAGbNAseZzKo/4+zsvHTp0uDg4Llz5wYFBZ08edLUFrVgTK3s+0iltHkzhYUpu+0FBcpNVy1vAXjz5s3soAoAo0aNSk5ONrVFLZEWIyyGKuhobCwBNOp0OMgAAAIcSURBVG6cSa15JJWVlbGxsaqTcwIDA3UOCNBWaTHC2rSJ+vShf/6TfH0pIYHKyujTT+nsWVOb1RxVVVXsGCYmr7/97W9JSUnt+TQKdVqGsM6fp6eeoqoqIqKyMvL1pdYTjbiqqiouLq5r165MXv7+/u38sBNGyxDWv/5Fn37adLlqVavzBq6uro6Li3NxcWHy6tevXzuXV8sYFd65g/sNCgA4OuLOHdNZowsdOnR44403fv/997i4uG7dul25cuWll17y9/ffuXOnXC43tXUmoGUIq2dPqE9nZ2dDv1CRpsLa2vqNN97IycmJj493dXVNT0+fMWNGO5WXqatMIiLKzaUnn6RLl4iIzp8nd3dq/efSNDQ0xMfHd+/enX3Pvr6+CQkJRnLbbwG0DGERUUoKjRtHISEUHt6WInDU1NRs2LBBve/1LR/h6loeLUZYbZrGxsaEhARPT08AkyZNMrU5xoAjIpM1w+2MhoaG7du3BwUF9W0HsWsEYQnwQssYFQq0OQRhCfCCICwBXhCEJcALgrAEeEEQlgAvCMIS4AVBWAK8IAhLgBcEYQnwgiAsAV4QhCXAC4KwBHhBEJYALwjCEuAFQVgCvCAIS4AXBGEJ8IIgLAFeEIQlwAuCsAR4QRCWAC8IwhLgBUFYArwgCEuAFwRhCfCCICwBXhCEJcALgrAEeEEQlgAvCMIS4AVBWAK8IAhLgBcEYQnwwv8Dz6JJ6fGdlhEAAALuelRYdHJka2l0UEtMIHJka2l0IDIwMjEuMDkuNAAAeJxlj2tIk1EYx8973nfvpruZblO3uZ2l1lZ0c1iYuHMgFaRQocIsiNmiVkER3VS0plAUUWKiXUgyrewqZWjmZedQSfey+xcLi8yUbppmH/rQa7rs8sDD7znPOf//c57P/guvgBRqMB7RUk6S0seJwC2R40Xglcjz3B+FfaQQ5KPkA/ytQDESoRB4pxgllI8awN8GIgkw4DzWCAFIohgQjhuMtMfmQBjgX23uv+s/3P8ZE/D9W8GNLzS2CPfrDLgAlYATBA5OgTyU1HyMwAt2KMiQTAQyOZArgCLIDhXBKFiJlCqktNqhSu2Fao1bowWaSC/UhiigdoKUoSA0DITpgE4P9AagDwfhESAiFEQa3UaTF5rMyKRym6NAlAVYEUA8QJK7TYBoogB1gowXZHIkKoKVViQX1ZpIo0klhun04RGh4XWc9E0wmiD6x5lj7GVDAWmYk9tWqq1msVsmktRGnn4x+Ningh6cvsJNa9/7WG5+t8tiOEuvD1WznOtl/rTKJnrUeYhlfaB0bvQAddxtYjYrYre7eXazeRGrqO+kr/MH6eGWuSw11sGcznl0ypkslshtZJ1eRPs9gC04JTKTuitJLLpAO56tou1oZhstrPQ3rwuiWzPW4+qUCtfDYSd+0xuPBy5W4WWXDuI1G27h10qeTHo7g5w3H8ErE0vw7kEPaa3ocC0dcpCuaZmkZKGZNH5dTGafMxBv6TSXNIKsTu7HmxvKaWHdLlKbN4yrjDx7UXOWJDwvx/HLr9H0RydJXu8uf1nEU/qk9TKpnHAf73ls8du1+0iTpR1vKErGfcJT3NL00aXJmEqOVu/F7+pS6PHvCeTOIs41v+8EnXwNkh1rO/1LTtuYrk5Llg5dTXLeyGb9nkxSc6Aex20rYsWbZpMa7h5Nq/S11U/fTg1rZzHk2e/Pieumtp5E9m2GlmVkO1nxTj2TOa4koQfTmeEn+qPrBoepwxYAAAONelRYdE1PTCByZGtpdCAyMDIxLjA5LjQAAHicfVbLbiRFELz7K/oH3MpXPfKAxNpeFoTWlljDfSVAsrTigvl/IrNqurs4MOMe1eREZUVGRqX899u33//46+ufb9++f//6z7vfbfH65ennt/fteOnTHeL0P3/uvv2mRHT3eYvF9vDx00/P2+Prh4db5PHl1+fXL5uWTTv24L1iP7y+fL5FeHvc7m337oVo092tVyzuaadKsTr2SiALwmYIy16020AWtnJF6shJJB1h3jv1MpC91QVpEymZinazLoHkXaX3K7Jsz3m6y0yF3+uAmoleoTWgtrdSdQLcbay6c7tC26ipNYvD7lEUsY8VivcrtAdUwUt95Gpik6sz2hE6P/7w6Tu5bfDYIPixtZGxmvjg3qosMjBtL5m8emIViNIGtkpd2sAc5YEfVR55mZISYZF1ntBsGbQsZYrmxDMtmdKCzabRrtRm/4vW7MDuuirB0TU0wDWL2BuNVHvj1TFcAORdSrH0AffCuSi1rBnr9gWOIsuzZUc7NIFCtrJsEAqJoknh1lJ5cDRqa+kdQEheSk2glPSihFlWjg45ofyQQ6BVdhViVl96JGgvfvdap6m7TSMAuV6UuFMG7n0gXdWmp6yvOQWHl1017YBMjaanC/8HGe0pUDDrDfvXVB/QdMoVagmtPIlWEh57uKT+J7IkUaM+22I0G1nbWlHNRtZS5zWtIVfoC+QCbAmEX25ObyKJdCrLfZaeJmK5XVLc5zFX4MyVpcflwKFKZV5SSfvILjF3roOHMikO7+MaGcmt/3VJqpxE1VORGEFWhkGg+0JUo0fREdd+G4wyV+6y+Fh13HlUPSWXltrGuPBxOdYhobb9mFNCi3eJlWhTylUnUSh/Zi8Dq1qlWdTZ3ZAgDlRWlHRAPz4/LVN+zP2Hl+enc+7H++Ah+dZzgjMeO8e04CnnLGY89Zy3jKedMzW+9nNuMh4/p6Lg4evo4wjwZb5xfhzcMMY4Pw56GFYSET0xBoII88EZw8cizAdtDqII88Ec4yQA8PdlbkgCj3LYZ+SoSFI9RI6iJDkDeL3ZHEA56pLQFEA5NbeIQPejLikzclQhwRlAOaqQ0DeA5+k9GlTxy+XKWADl4JwdB1COXbCLReRUVZOzA3vxM2+JvfiVA6jnruCsF7NoHYHz7JYWwNaw/rmxDxwSLPHw7tWp8f323w3Wd/8Cwc27WmoJP/QAAAHpelRYdFNNSUxFUyByZGtpdCAyMDIxLjA5LjQAAHicJVK7juMwDPyVKx3A8fItEkaAA9RslS2uDFL5N/bjb6gUCa0RORyO+Pp+v+bfN8vzMbdLr2v7tz1+bv172pzPbd7mtNt1Xfoz5+05+wYVKNle3+9bJ6BUvuZjfs0/v9tdDtWQsdNBWaY6dkBDWfXsjyG83+mQkYh8jKI4Eb00G6eQFaukGld3X2fise4NNHQojeijayQ6lVKdIC11nAZp/zOY+RB32/ngdEbw8DoFLCiHGEsFKGRIZK5dkcBNaDQMeeEeAMUhSg4ziVMPNcVB3QSJHOVIrIAOPjKteiqgcRqIs9FStTaBLP102CPeigZF5zovlJPX4BKYAXD4ABq8eIM+rrE7g9co1zDWY8boMcOjTxZLHLABkIqqy2C6AC3yhEuMFt1BoHZvVcptqSl5q3TxAizmyAUDVCk6yseIYPBqwcy7odTbl3TKflui4GZg0mprqKzh4rF2IEw+akL8BKdGjeYeGLXxkIiFiy4Th8BhxOLFol7ZNKJDOyZJr5Qdwz/zWJV1TDQ8746pbRU44WVbXmBJgFPJWinMvx4Az7p4SHJZaLnaKu4XDLyflnJVJeQulrB2zxVFvYgMv5BdWQ6jyjI+60xx+/0P0guvwB++SzMAAAAASUVORK5CYII=\" alt=\"Mol\"/>\n    \n    \n      230\n      sildenafil@taut9\n      -1883.1660918444156\n      0.002793555613607168\n      True\n      3.130568815727958\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      231\n      sildenafil@taut9\n      -1883.1657381802559\n      0.002911796560510993\n      True\n      3.3524964267405757\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n    \n      232\n      sildenafil@taut9\n      -1883.1640510409832\n      0.0027946573682129383\n      True\n      4.411192304313834\n      <img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/>\n    \n  \n\n233 rows × 6 columns\n\n\n\n\nsdf_df = sdf_df.sort_values('E_tot', ascending=False)\nsdf_df = sdf_df.drop_duplicates(subset=['ID'])\nsdf_df['parent_id'] = [x.split('@')[0] for x in sdf_df['ID']]\nsdf_df['tauto_id'] = [x.split('@')[1] for x in sdf_df['ID']]\nsdf_df['SMILES'] = [Chem.MolToSmiles(x) for x in sdf_df['ROMol']]\nsdf_df['E_tot'] = sdf_df['E_tot'].astype(float)\n\n\nsdf_df.columns\n\nIndex(['ID', 'E_tot', 'fmax', 'Converged', 'E_rel(kcal/mol)', 'ROMol',\n       'parent_id', 'tauto_id', 'SMILES'],\n      dtype='object')\n\n\n\nsdf_format = sdf_df[['parent_id','tauto_id', 'ID', 'SMILES', 'E_tot', 'fmax', 'Converged', 'E_rel(kcal/mol)']]\n\n\n# convert Hatrees to kcal/mol http://wild.life.nctu.edu.tw/class/common/energy-unit-conv-table.html\nE_rel = []\nfor parent_id in set(list(sdf_format['parent_id'])):\n  sdf_format_per_parent = sdf_format.loc[ sdf_format['parent_id'] == parent_id ]\n  sdf_format_per_parent.loc[sdf_format_per_parent.index, 'E_rel_tauto(kcal/mol)'] = (sdf_format_per_parent['E_tot'] - min(sdf_format_per_parent['E_tot'])) * 627.5095\n  E_rel.append(sdf_format_per_parent)\nsdf_format = pd.concat(E_rel)\n\n/node/scratch/106404095.1.all.normal.q/ipykernel_28232/475714180.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  sdf_format_per_parent.loc[sdf_format_per_parent.index, 'E_rel_tauto(kcal/mol)'] = (sdf_format_per_parent['E_tot'] - min(sdf_format_per_parent['E_tot'])) * 627.5095\n\n\n\nsdf_format\n\n\n\n\n\n  \n    \n      \n      parent_id\n      tauto_id\n      ID\n      SMILES\n      E_tot\n      fmax\n      Converged\n      E_rel(kcal/mol)\n      E_rel_tauto(kcal/mol)\n    \n  \n  \n    \n      167\n      sildenafil\n      taut26\n      sildenafil@taut26\n      CCCc1nn(C)c2c(=O)[nH]c(-c3cc(S(=O)(=O)N4CCN(C)...\n      -1883.237851\n      0.0027714346069842577\n      True\n      0.0\n      0.000000\n    \n    \n      174\n      sildenafil\n      taut27\n      sildenafil@taut27\n      CCCc1nn(C)c2c(=O)nc(-c3cc(S(=O)(=O)N4CCN(C)CC4...\n      -1883.217860\n      0.0029108182061463594\n      True\n      0.0\n      12.544642\n    \n    \n      183\n      sildenafil\n      taut28\n      sildenafil@taut28\n      CCCc1nn(C)c2c(O)nc(-c3cc(S(=O)(=O)N4CCN(C)CC4)...\n      -1883.211783\n      0.002911168849095702\n      True\n      0.0\n      16.358181\n    \n    \n      155\n      sildenafil\n      taut24\n      sildenafil@taut24\n      CC/C=C1/NN(C)c2c1nc(-c1cc(S(=O)(=O)N3CCN(C)CC3...\n      -1883.198682\n      0.002975363051518798\n      True\n      0.0\n      24.578853\n    \n    \n      119\n      sildenafil\n      taut20\n      sildenafil@taut20\n      C/C=C/c1nn(C)c2c1N[C@@H](c1cc(S(=O)(=O)N3CCN(C...\n      -1883.195765\n      0.002867447677999735\n      True\n      0.0\n      26.409780\n    \n    \n      210\n      sildenafil\n      taut5\n      sildenafil@taut5\n      C/C=C/C1=C2NC(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3OC...\n      -1883.185570\n      0.0029683925677090883\n      True\n      0.0\n      32.806838\n    \n    \n      91\n      sildenafil\n      taut17\n      sildenafil@taut17\n      C/C=C/c1nn(C)c2c1N=C(c1cc(S(=O)(=O)N3CCN(C)CC3...\n      -1883.185264\n      0.002987172920256853\n      True\n      0.0\n      32.998937\n    \n    \n      151\n      sildenafil\n      taut23\n      sildenafil@taut23\n      CC/C=C1/NN(C)c2c1[nH]c(-c1cc(S(=O)(=O)N3CCN(C)...\n      -1883.183689\n      0.0029540995601564646\n      True\n      0.0\n      33.987148\n    \n    \n      96\n      sildenafil\n      taut18\n      sildenafil@taut18\n      C/C=C/c1nn(C)c2c1NC(c1cc(S(=O)(=O)N3CCN(C)CC3)...\n      -1883.178366\n      0.0029339187312871218\n      True\n      0.0\n      37.327788\n    \n    \n      81\n      sildenafil\n      taut15\n      sildenafil@taut15\n      C/C=C/[C@@H]1NN(C)c2c1nc(-c1cc(S(=O)(=O)N3CCN(...\n      -1883.176364\n      0.0029547689482569695\n      True\n      0.0\n      38.583651\n    \n    \n      143\n      sildenafil\n      taut22\n      sildenafil@taut22\n      CC/C=C1/NN(C)c2c(O)nc(-c3cc(S(=O)(=O)N4CCN(C)C...\n      -1883.173366\n      0.0019200812093913555\n      True\n      0.0\n      40.464996\n    \n    \n      101\n      sildenafil\n      taut19\n      sildenafil@taut19\n      C/C=C/c1nn(C)c2c1N[C@@H](c1cc(S(=O)(=O)N3CCN(C...\n      -1883.172031\n      0.00290022068656981\n      True\n      0.0\n      41.302550\n    \n    \n      227\n      sildenafil\n      taut9\n      sildenafil@taut9\n      C/C=C/C1=NN(C)[C@@H]2C(=O)NC(c3cc(S(=O)(=O)N4C...\n      -1883.171081\n      0.0029343736823648214\n      True\n      0.0\n      41.899119\n    \n    \n      160\n      sildenafil\n      taut25\n      sildenafil@taut25\n      CCCC1=NN(C)[C@@H]2C(=O)N=C(c3cc(S(=O)(=O)N4CCN...\n      -1883.169082\n      0.0029732126276940107\n      True\n      0.0\n      43.153355\n    \n    \n      187\n      sildenafil\n      taut3\n      sildenafil@taut3\n      C/C=C/C1=C2N=C(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3O...\n      -1883.166379\n      0.002880740910768509\n      True\n      0.0\n      44.849577\n    \n    \n      111\n      sildenafil\n      taut2\n      sildenafil@taut2\n      C/C=C/C1=C2N=C(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3O...\n      -1883.164880\n      0.0029965881258249283\n      True\n      0.0\n      45.789950\n    \n    \n      222\n      sildenafil\n      taut8\n      sildenafil@taut8\n      C/C=C/C1=NN(C)[C@@H]2C(=O)N=C(c3cc(S(=O)(=O)N4...\n      -1883.164851\n      0.0029544399585574865\n      True\n      0.0\n      45.808576\n    \n    \n      213\n      sildenafil\n      taut6\n      sildenafil@taut6\n      C/C=C\\C1=NN(C)C2=C(O)N=C(c3cc(S(=O)(=O)N4CCN(C...\n      -1883.164151\n      0.0029395974706858397\n      True\n      0.0\n      46.247307\n    \n    \n      88\n      sildenafil\n      taut16\n      sildenafil@taut16\n      C/C=C/c1nn(C)c2c1=N[C@@H](c1cc(S(=O)(=O)N3CCN(...\n      -1883.159181\n      0.0029624311719089746\n      True\n      0.0\n      49.366394\n    \n    \n      72\n      sildenafil\n      taut14\n      sildenafil@taut14\n      C/C=C\\[C@@H]1NN(C)c2c1[nH]c(-c1cc(S(=O)(=O)N3C...\n      -1883.159030\n      0.002975861541926861\n      True\n      0.0\n      49.460966\n    \n    \n      55\n      sildenafil\n      taut13\n      sildenafil@taut13\n      C/C=C\\[C@@H]1NN(C)c2c(O)nc(-c3cc(S(=O)(=O)N4CC...\n      -1883.148282\n      0.002590285148471594\n      True\n      0.0\n      56.205456\n    \n    \n      193\n      sildenafil\n      taut4\n      sildenafil@taut4\n      C/C=C/C1=C2NC(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3OC...\n      -1883.144197\n      0.002940340666100383\n      True\n      0.0\n      58.768723\n    \n    \n      217\n      sildenafil\n      taut7\n      sildenafil@taut7\n      C/C=C/C1=NN(C)C2=C(O)NC(c3cc(S(=O)(=O)N4CCN(C)...\n      -1883.144103\n      0.0029915182385593653\n      True\n      0.0\n      58.827650\n    \n    \n      21\n      sildenafil\n      taut10\n      sildenafil@taut10\n      C/C=C/C1=NN(C)[C@@H]2C(O)=NC(c3cc(S(=O)(=O)N4C...\n      -1883.142340\n      0.0029348309617489576\n      True\n      0.0\n      59.933997\n    \n    \n      17\n      sildenafil\n      taut1\n      sildenafil@taut1\n      C/C=C/C1=C2N=C(c3cc(S(=O)(=O)N4CCN(C)CC4)ccc3O...\n      -1883.142246\n      0.0026598710101097822\n      True\n      0.0\n      59.993093\n    \n    \n      29\n      sildenafil\n      taut11\n      sildenafil@taut11\n      C/C=C/C1=NN(C)[C@@H]2C1=NC(c1cc(S(=O)(=O)N3CCN...\n      -1883.141071\n      0.002974058734253049\n      True\n      0.0\n      60.730651\n    \n    \n      129\n      sildenafil\n      taut21\n      sildenafil@taut21\n      CC/C=C1/NN(C)[C@@H]2C(=O)N=C(c3cc(S(=O)(=O)N4C...\n      -1883.140111\n      0.0025039315223693848\n      True\n      0.0\n      61.333093\n    \n    \n      37\n      sildenafil\n      taut12\n      sildenafil@taut12\n      C/C=C\\[C@@H]1NN(C)[C@H]2C(=O)N=C(c3cc(S(=O)(=O...\n      -1883.124047\n      0.002953974064439535\n      True\n      0.0\n      71.413043\n    \n    \n      9\n      boo\n      taut2\n      boo@taut2\n      NC(=O)c1ccccc1OCc1ccccc1F\n      -845.393300\n      0.002969717374071479\n      True\n      0.0\n      0.000000\n    \n    \n      5\n      boo\n      taut1\n      boo@taut1\n      N=C(O)c1ccccc1OCc1ccccc1F\n      -845.367714\n      0.002988976426422596\n      True\n      0.0\n      16.055548\n    \n    \n      15\n      pyridone\n      taut1\n      pyridone@taut1\n      O=c1cc[nH]cc1\n      -323.358696\n      0.002931158524006605\n      True\n      0.0\n      0.000000\n    \n    \n      16\n      pyridone\n      taut2\n      pyridone@taut2\n      Oc1ccncc1\n      -323.357830\n      0.0027759429067373276\n      True\n      0.0\n      0.543535\n    \n    \n      3\n      benzene-fused\n      taut2\n      benzene-fused@taut2\n      O=c1ccnc2ccc3ccc[nH]c3c12\n      -646.544910\n      0.00297327502630651\n      True\n      0.0\n      0.000000\n    \n    \n      2\n      benzene-fused\n      taut1\n      benzene-fused@taut1\n      O=c1cc[nH]c2ccc3cccnc3c12\n      -646.523054\n      0.0028541951905936003\n      True\n      0.0\n      13.714564\n    \n    \n      4\n      benzene-fused\n      taut3\n      benzene-fused@taut3\n      Oc1ccnc2ccc3cccnc3c12\n      -646.519976\n      0.0022692130878567696\n      True\n      0.0\n      15.645841\n    \n    \n      1\n      Cl-pyridone\n      taut2\n      Cl-pyridone@taut2\n      Oc1cc(Cl)nc(Cl)c1\n      -1242.457621\n      0.0029037443455308676\n      True\n      0.0\n      0.000000\n    \n    \n      0\n      Cl-pyridone\n      taut1\n      Cl-pyridone@taut1\n      O=c1cc(Cl)[nH]c(Cl)c1\n      -1242.448522\n      0.0028711010236293077\n      True\n      0.0\n      5.709816\n    \n  \n\n\n\n\n\nmols2grid.display(sdf_format, \n                  # set what's displayed on the grid\n                  subset=[\"parent_id\", \"img\", \"tauto_id\",\"E_rel_tauto(kcal/mol)\"],\n                  # set what's displayed on the hover tooltip\n                  tooltip=[\"parent_id\", \"E_tot\", \"fmax\", \"E_rel_tauto(kcal/mol)\"],\n                  transform={\"E_rel_tauto(kcal/mol)\": lambda x: r\"del_E_tauto: {0:0.3f} kcal/mol\".format(x)},\n                  size=(250,250))"
  },
  {
    "objectID": "posts/2023-01-16-auto3d.html#saving-and-viewing-the-sd-files",
    "href": "posts/2023-01-16-auto3d.html#saving-and-viewing-the-sd-files",
    "title": "Auto3D to make optimize tautomers and 3D conformers",
    "section": "Saving and viewing the SD files",
    "text": "Saving and viewing the SD files\nHere I am looking at the 3D conformers of the original and tautomers\n\ninf = open(os.path.join(out_folder, 'job1','smi_taut_3d.sdf'),'rb')\nwith Chem.ForwardSDMolSupplier(inf) as fsuppl:\n    ms = [x for x in fsuppl if x is not None]\n\n\n## Combine all the conformers for a given molecule in 1 molecule object \nmol_dict = []\nget_og_name = [x.GetProp('ID').split('@')[0] for x in ms]\nfor index, row in test_smi.iterrows():\n  item_index = []\n  for entry_index, og_name in enumerate(get_og_name):\n    if str(row['Name']) == og_name:\n      item_index.append(entry_index)\n  list_sdf = [ms[i] for i in item_index]\n  sdf_dict = {}\n  sdf_dict['parent'] = row['Name']\n  sdf_dict['conformers'] = list_sdf \n  mol_dict.append(sdf_dict)\n\n\ndef to_sdf(mol_dict):\n  parent_id = mol_dict['parent']\n  w = Chem.SDWriter(f'{out_folder}/conformers_{parent_id}.sdf')\n  sdfs = mol_dict['conformers']\n  for entries in sdfs:\n    w.write(entries)\n  w.close()\n\ndef append_conformers_to_mol(mol_dict):\n  parent_id = mol_dict['parent']\n  sdfs = mol_dict['conformers']\n  ref = copy.deepcopy(sdfs[0])\n  for mol in sdfs:\n    conf_mol = mol.GetConformer()\n    mol_props = mol.GetPropsAsDict()\n    for key, value in mol_props.items():\n      conf_mol.SetProp(str(key), str(value))\n    ref.AddConformer(conf_mol, assignId=True)\n  \n  for name in ref.GetPropNames():\n    ref.ClearProp(name)\n  \n  ref.SetProp('_Name',str(parent_id))\n  Chem.rdMolAlign.AlignMolConformers(ref)\n  return ref \n\n\nfor mol_list in mol_dict:\n  print(mol_list['parent'], len(mol_list['conformers']))\n\npyridone 2\nCl-pyridone 2\nbenzene-fused 3\nsildenafil 216\nboo 10\n\n\n\nmol_dict[1]\n\n{'parent': 'Cl-pyridone',\n 'conformers': [<rdkit.Chem.rdchem.Mol at 0x2b29365373a0>,\n  <rdkit.Chem.rdchem.Mol at 0x2b2936537030>]}\n\n\n\nto_sdf(mol_dict[1])\n\n\nref = append_conformers_to_mol(mol_dict[-1])\n\n\n# http://rdkit.blogspot.com/2016/07/using-ipywidgets-and-py3dmol-to-browse.html\nimport py3Dmol\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom ipywidgets import interact, interactive, fixed\n\n\nref.GetNumConformers()\n\n11\n\n\nWhat I want to do is generate a set of conformers for a molecule and scroll through them interactively. Here’s some code for doing that:\n\n# https://birdlet.github.io/2019/10/02/py3dmol_example/\n# http://rdkit.blogspot.com/2016/07/using-ipywidgets-and-py3dmol-to-browse.html\n\nimport py3Dmol\n\ndef MolTo3DView(mol, confId, size=(400, 400), style=\"stick\", surface=False, opacity=0.5):\n    \"\"\"Draw molecule in 3D\n    \n    Args:\n    ----\n        mol: rdMol, molecule to show\n        size: tuple(int, int), canvas size\n        style: str, type of drawing molecule\n               style can be 'line', 'stick', 'sphere', 'carton'\n        surface, bool, display SAS\n        opacity, float, opacity of surface, range 0.0-1.0\n    Return:\n    ----\n        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n    \"\"\"\n    assert style in ('line', 'stick', 'sphere', 'carton')\n    mblock = Chem.MolToMolBlock(mol, confId=confId)\n    viewer = py3Dmol.view(width=size[0], height=size[1])\n    viewer.addModel(mblock, 'sdf')\n    viewer.setStyle({style:{}})\n    if surface:\n        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n    viewer.zoomTo()\n    return viewer\n\n\nref.GetProp('_Name')\n\n'boo'\n\n\n\nfor conf in ref.GetConformers():\n    print(conf.GetId())\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\nfrom ipywidgets import interact,fixed,IntSlider\nimport ipywidgets\n\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\n\ndef conf_viewer(mol, confId=-1):\n    return MolTo3DView(mol, confId).show()\n\ninteract(conf_viewer, mol=fixed(ref), confId=ipywidgets.IntSlider(min=0,max=ref.GetNumConformers()-1, step=1))\n\n\n        You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: \n        jupyter labextension install jupyterlab_3dmol\n        \n\n\n\n\n\n\n<function __main__.conf_viewer(mol, confId=-1)>\n\n\n\nsdf_mol_info = sdf_format.loc[ sdf_format['parent_id'] == ref.GetProp('_Name')]\n\n\nmols2grid.display(sdf_mol_info, \n                  # set what's displayed on the grid\n                  subset=[\"parent_id\", \"img\", \"tauto_id\",\"E_rel_tauto(kcal/mol)\"],\n                  # set what's displayed on the hover tooltip\n                  tooltip=[\"parent_id\", \"E_tot\", \"fmax\", \"E_rel_tauto(kcal/mol)\"],\n                  transform={\"E_rel_tauto(kcal/mol)\": lambda x: f'del_E_tauto: {round(x, 3)} kcal/mol'},\n                  size=(250,250))"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html",
    "href": "posts/2020-02-19-svm_example.html",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "",
    "text": "This tutorial is borrowed from Jake VanderPlas’s example of SVM in his notebook: Python Data Science Handbook"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html#motivation-for-support-vector-machines",
    "href": "posts/2020-02-19-svm_example.html#motivation-for-support-vector-machines",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "Motivation for Support Vector Machines",
    "text": "Motivation for Support Vector Machines\n\nWe want to find a line/curve (in 2D) or a manifold (in n-D) that divides the class from each other. This is a type of Discriminative Classification\nConsider a simple case of classification task, in which the two classes of points are well separated\n\n\n#importing necessary modules\nimport os \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom scipy import stats \nrandom_state = 42 \n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns; sns.set() \n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 30,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples=200, centers=2, \n                 random_state=random_state,\n                 cluster_std=1.5)\n\n\n#---Check what is X and y ----# \nprint('X is a {} array with x-y coordinates of the cluster points\\n'.format(np.shape(X)))\nprint(X[:3])\nprint('\\n')\nprint('y is a {} array with a classification of the points to which cluster they belong to\\n'.format(np.shape(y)))\nprint(y[:3])\nprint('\\n')\nplt.scatter(X[:,0],X[:,1], c=y, s=50, cmap='autumn');\n\nX is a (200, 2) array with x-y coordinates of the cluster points\n\n[[2.24823735 1.07410715]\n [5.12395668 0.73232327]\n [4.6766441  2.72016712]]\n\n\ny is a (200,) array with a classification of the points to which cluster they belong to\n\n[1 1 1]\n\n\n\n\n\n\n\nFor two-dimensional data, as observed in this case, a linear discriminative classifier would attempt to draw a straight line separating the two data-sets and thereby creating a model for (binary) classification. For the 2D data like the shown above, this task could be done by hand. But there is more than one line that can divide this data in two halves!\n\nx_fit = np.linspace(min(X[:,0]),max(X[:,0]))\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(X[:,0], X[:,1], c=y, s=50, cmap='autumn')\n\n# Random point in the 2D plain \nax.plot([-2],[4],'x',color='blue', markeredgewidth=2, markersize=10)\n\n# Plot various 2D planes separating the two 'blobs'\nfor m,b in [(3.5,5),(2,5),(0.9,5)]:\n    plt.plot(x_fit, x_fit*m+b, '-k')\n    \nplt.xlim(min(X[:,0]),max(X[:,0]))\nplt.ylim(min(X[:,1]),max(X[:,1]))\n\n(-0.9549620153430207, 13.094539878082749)\n\n\n\n\n\nWhat’s a better methodology to determine the cutting plane? Something like k-nearest neighbor clustering wherein you find the plane with best separation from the two clusters based on some distance metric. However, k-nearest neighbors is based on non-parametric method – needing to be estimated everytime a new data point is introduced.\nWhat if I want something which is learned and then used as a function every other time a new datum is to be classified. This is where support vector machines (SVM) are useful.\nSupport Vector Machines:\nRather than simply drawing a zero-width line between classes, we can draw round each line a margin of some width, up to the nearest point.\n\nx_fit = np.linspace(min(X[:,0]),max(X[:,0]))\nplt.scatter(X[:,0], X[:,1], c=y, s=50, cmap='autumn')\nplt.plot([-2],[4],'x',color='blue', markeredgewidth=2, markersize=10)\n\nfor m, b, d in [(3.5,5,0.33),(2,5,0.55),(0.9,5,0.8)]:\n    y_fit = x_fit*m + b \n    plt.plot(x_fit, y_fit, '-k')\n    plt.fill_between(x_fit, y_fit-d, y_fit+d, edgecolor='none',\n                    color='#AAAAAA', alpha=0.4)\n    \nplt.xlim(min(X[:,0]),max(X[:,0]))\nplt.ylim(min(X[:,1]),max(X[:,1]))\n\n(-0.9549620153430207, 13.094539878082749)\n\n\n\n\n\nIn support vector machines, the line that maximizes this margin is the one we will choose as the optimal model. Support vector machines are an example of such a maximum margin estimator.\n\nFitting a support vector machine model\nUsing Scikit-learn’s SVM module to train a classifier on the above data. We will use a linear-kernel and set C parameters to a very large value.\n\nfrom sklearn.svm import SVC\nmodel = SVC(kernel='linear',C=1E10)\nmodel.fit(X,y)\n\nSVC(C=10000000000.0, kernel='linear')\n\n\nTo better appreciate the SVM classification logic, we use a convenience function to visualize the decision boundary as made by the SVM module. Code is adopted from Jake’s tutorial.\n\ndef plot_svc_decision_function(model, ax=None, plot_support=True, list_vectors=False):\n    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n    if ax is None:\n        ax = plt.gca()\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n    \n    # create grid to evaluate model\n    x = np.linspace(xlim[0], xlim[1], 30)\n    y = np.linspace(ylim[0], ylim[1], 30)\n    Y, X = np.meshgrid(y, x)\n    xy = np.vstack([X.ravel(), Y.ravel()]).T\n    P = model.decision_function(xy).reshape(X.shape)\n    \n    # plot decision boundary and margins\n    ax.contour(X, Y, P, colors='k',\n               levels=[-1, 0, 1], alpha=0.5,\n               linestyles=['--', '-', '--'])\n    \n    # plot support vectors\n    if plot_support:\n        ax.scatter(model.support_vectors_[:, 0],\n                   model.support_vectors_[:, 1],\n                   s=100, facecolors='none', edgecolors='black',linestyle='--');\n    if list_vectors: \n        print(model.support_vectors_)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n\n\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\nplot_svc_decision_function(model)\n\n\n\n\nThis is the dividing line that maximizes the margin between the two sets of points.\nNotice that a few of the training points just touch the margin: they are indicated by the black circles in this figure.\nThese points are the pivotal elements of this fit, and are known as the support vectors, and give the algorithm its name.\nIn Scikit-Learn, the identity of these points are stored in the support_vectors_ attribute of the classifier.\n\nmodel.support_vectors_\n\narray([[-0.40500616,  6.91150953],\n       [ 2.65952903,  4.72035783],\n       [ 2.07017704,  4.00397825]])\n\n\n\nA key to this classifier’s success is that for the fit, only the position of the support vectors matter; any points further from the margin which are on the correct side do not modify the fit!\n\nTechnically, this is because these points do not contribute to the loss function used to fit the model, so their position and number do not matter so long as they do not cross the margin.\nWe can see this, for example, if we plot the model learned from the first 60 points and first 120 points of this dataset:\n\ndef plot_svm(N=10, ax=None):\n    X, y = make_blobs(n_samples=200, centers=2,\n                      random_state=0, cluster_std=0.60)\n    X = X[:N]\n    y = y[:N]\n    model = SVC(kernel='linear', C=1E10)\n    model.fit(X, y)\n    \n    ax = ax or plt.gca()\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n    ax.set_xlim(-1, 4)\n    ax.set_ylim(-1, 6)\n    plot_svc_decision_function(model, ax)\n    \nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\nfig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\nfor axi, N in zip(ax, [60, 120]):\n    plot_svm(N, axi)\n    axi.set_title('N = {0}'.format(N))\n\n\n\n\nIn spite of increasing the training points, once the margins and the corresponding support vectors are identified the model does not change. This is one of the strengths of this algorithm\n\nfrom ipywidgets import interact, fixed\ninteract(plot_svm, N=[10, 50, 100, 150, 200], ax=fixed(None));"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html#beyond-linear-kernels-kernel-svm",
    "href": "posts/2020-02-19-svm_example.html#beyond-linear-kernels-kernel-svm",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "Beyond linear kernels: Kernel SVM",
    "text": "Beyond linear kernels: Kernel SVM\nKernels are helpful in projecting data into higher dimensional feature space. This can be useful in simplest case to fit non-linear data using linear regression models. Similarly in the case of SVM: Projecting the data into higher dimensions through either polynomial or gaussian kernels we can fit non-linear relationships to a linear classifier\nLet’s look at a data-set which is not linearly separated:\n\nfrom sklearn.datasets import make_circles\n\nX, y = make_circles(200, factor=0.1, noise=0.1)\nclf = SVC(kernel='linear').fit(X,y)\nplt.scatter(X[:,0], X[:,1], c=y, s=50, cmap='autumn')\nplot_svc_decision_function(clf, plot_support=False)\n\n\n\n\nThere is not straight forward way to separate this data however we can project the data into higher dimensions based on its properties in the current dimensional space and get more information about its spread. One way of doing so is computing a radial basis function centered at the middle lump\n\nr = np.exp(-(np.sum((X)**2,axis=1)))\n\nfrom mpl_toolkits import mplot3d\n\ndef plot_3D(elev=30, azim=30, X=X, y=y):\n    ax = plt.subplot(projection='3d')\n    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap='autumn')\n    ax.view_init(elev=elev, azim=azim)\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_zlabel('r')\n\ninteract(plot_3D, elev=[-90, -45, -30, 30, 45, 60, 90], azip=(-180, 180),\n         X=fixed(X), y=fixed(y));\n\n\n\n\nProjecting the data in an additonal dimensions we can see can having a plane at r=0.7 could give us good separation.\nHere we had to choose and carefully tune our projection: if we had not centered our radial basis function in the right location, we would not have seen such clean, linearly separable results.\nIn general, the need to make such a choice is a problem: we would like to somehow automatically find the best basis functions to use.\nOne strategy to this end is to compute a basis function centered at every point in the dataset, and let the SVM algorithm sift through the results. This type of basis function transformation is known as a kernel transformation, as it is based on a similarity relationship (or kernel) between each pair of points.\nA potential problem with this strategy—projecting N points into N dimensions—is that it might become very computationally intensive as N grows large. However, because of a neat little procedure known as the kernel trick, a fit on kernel-transformed data can be done implicitly—that is, without ever building the full N-dimensional representation of the kernel projection! This kernel trick is built into the SVM, and is one of the reasons the method is so powerful.\nIn Scikit-Learn, we can apply kernelized SVM simply by changing our linear kernel to an RBF (radial basis function) kernel, using the kernel model hyperparameter:\n\nclf = SVC(kernel='rbf', C=1E6)\nclf.fit(X, y)\n\nSVC(C=1000000.0)\n\n\n\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\nplot_svc_decision_function(clf)\nplt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n            s=300, lw=1, facecolors='none');"
  },
  {
    "objectID": "posts/2020-02-19-svm_example.html#softer-margins",
    "href": "posts/2020-02-19-svm_example.html#softer-margins",
    "title": "Implement Support Vector Machines in scikit-learn",
    "section": "Softer margins",
    "text": "Softer margins\n\nX, y = make_blobs(n_samples=100, centers=2,\n                  random_state=0, cluster_std=1.2)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn');\n\n\n\n\nTo handle this case, the SVM implementation has a bit of a fudge-factor which “softens” the margin: that is, it allows some of the points to creep into the margin if that allows a better fit. The hardness of the margin is controlled by a tuning parameter, most often known as C.\nFor very large C, the margin is hard, and points cannot lie in it. For smaller C, the margin is softer, and can grow to encompass some points.\nThe plot shown below gives a visual picture of how a changing C parameter affects the final fit, via the softening of the margin:\n\nX, y = make_blobs(n_samples=100, centers=2,\n                  random_state=0, cluster_std=0.8)\n\nfig, ax = plt.subplots(1, 3, figsize=(16, 6))\n\nfor axi, C in zip(ax, [1E10, 10.0, 0.1]):\n    model = SVC(kernel='linear', C=C).fit(X, y)\n    axi.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n    plot_svc_decision_function(model, axi)\n    axi.scatter(model.support_vectors_[:, 0],\n                model.support_vectors_[:, 1],\n                s=300, facecolors='none', edgecolors='black',linestyle='--')\n    axi.set_title('C = {0:.1f}'.format(C), size=14)"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html",
    "href": "posts/2021-03-18-autoencoder.html",
    "title": "Anamoly detection using autoencoders",
    "section": "",
    "text": "An autoencoder is a type of unsupervised learning method. More than that, it is a type of ‘generative’ model which once trained can potentially help generate synthetic data. In essense, it is a non-linear dimensionality reduction technique to learn the internal low-dimensional structure of the data.\nAn autoencoder model contains two components:\n1. An encoder: that takes an image as input, and outputs a low-dimensional embedding (representation) of the image.\n2. A decoder: that takes the low-dimensional embedding, and reconstructs the image.\nIn esence autoencoder can be viewed as a dimensionality reduction tool for embedding the data in low-dimensional latent space which is non-linear.\nRelationship to PCA\nAutoencoder can be seen as a generalisation of principal component analysis to nonlinear manifolds. If we remove the nonlinearity (brought about by the activation functions) then the result of autoencoder will be in (some sense) equivalent to PCA. Now, however, the component vectors encoded by weights will not be orthogonal, like with PCA.\nAnamoly Detection\nBesides being used a generative model, it can be used as a anamoly detection method by considering the loss value between the decoded object and the encoded entity. By setting a threshold on the acceptable loss values we can train the model to flag any instances wherein the model’s loss value exceed that limit and potentially is an anamolous digit.\nSuch an anamoly detection could be used in processes where images, sound, or signal is scanned and flagged for being out of spec. Google I/O in 2021 had a nice workshop on introducing Autoencoder and their utility in anomaly detection for detecting abnormal heart rhythm. Video\nA simple autoencoder based on a CNN architecture will be built to encode and embed MNIST hand-written digit data.\nModel Development\nFor the CNN stride and filter size is chose to ensure final vector in the bottleneck is commensurate with a single vector. To understand more on the how the stride and filter is chosen, or the effect of those parameters on the convolution, there’s a helpful visualization and documentation here: https://github.com/vdumoulin/conv_arithmetic\nWith subsequent epochs the reconstruction of the images becomes better.\nVisualizing the reconstruction of a random validation data digit\nVisualize the distribution of epoch losses for train and validation set from the last epoch. The statistics from this distribution will be used to set the threshold for the anamoly detection in the later section"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#visualize-latent-space",
    "href": "posts/2021-03-18-autoencoder.html#visualize-latent-space",
    "title": "Anamoly detection using autoencoders",
    "section": "Visualize latent space",
    "text": "Visualize latent space\n\nlabel_collection = np.array([])\nlatent_space_collection = np.zeros((0,20))\nfor i, data_batch in enumerate(val_loader):\n    with torch.no_grad():\n        data, label = data_batch \n        reconstruction, latent_x = model(data)\n        label_collection = np.concatenate((label.numpy(), label_collection))\n        latent_space_collection = np.vstack((latent_x.numpy(), latent_space_collection))\n\n\nprint(label_collection.shape, latent_space_collection.shape)\n\n(10000,) (10000, 20)\n\n\n\ntSNE plots\n\nimport openTSNE as openTSNE\nprint('openTSNE', openTSNE.__version__)\n\nopenTSNE 0.6.0\n\n\n\n%%time\n# BH and PCA_init by default\nZ1 = openTSNE.TSNE(n_jobs=-1, negative_gradient_method='bh').fit(latent_space_collection)\n\nCPU times: user 2min 46s, sys: 2min 11s, total: 4min 57s\nWall time: 39 s\n\n\n\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\ncmap = ListedColormap(sns.husl_palette(len(np.unique(label_collection))))\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nim = ax.scatter(Z1[:,0], Z1[:,1], s=10, c=label_collection, cmap=cmap, edgecolor='none')\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('tSNE component 1')\nax.set_ylabel('tSNE component 2')\nax.set_title('t-SNE on Latent Space (MNIST data)')\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.25, 0.01, 0.5], label='digit')\ncbar = fig.colorbar(im, cax=cbar_ax, label='Digit')\n\n/depot/jgreeley/apps/envs/gpu_env1/lib/python3.7/site-packages/pandas/compat/__init__.py:97: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n  warnings.warn(msg)\n\n\n\n\n\nEmbedding 20 dimensions in 2 dimensional tSNE space, the clusters for each digit become quite clear. It is interesting to see that cluster for 1 and 7 are quite close to another, similarly cluster for 5 and 3 which have been traditionally challenging to distinguish in the classifers"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#linear-interpolation-in-the-latent-space",
    "href": "posts/2021-03-18-autoencoder.html#linear-interpolation-in-the-latent-space",
    "title": "Anamoly detection using autoencoders",
    "section": "Linear interpolation in the latent space",
    "text": "Linear interpolation in the latent space\n\nprint(latent_space_collection.shape)\n\n#Select random points for start and ending \nstart_point_index = 4121\nend_point_index = 9832\n\nstart_point_latent_vectors = latent_space_collection[start_point_index]\nend_point_latent_vectors = latent_space_collection[end_point_index]\n\n(10000, 20)\n\n\n\nnum_steps = 10\ntrajectory_points = np.zeros((0,20))\nfor i in range(num_steps):\n    z = start_point_latent_vectors * i/num_steps + end_point_latent_vectors * (num_steps - i) / num_steps \n    trajectory_points = np.vstack((z, trajectory_points))\n    \nprint(trajectory_points.shape)\n\n(10, 20)\n\n\n\ntrajectory_latent_tensor = torch.tensor(trajectory_points)\n\n\nreconstruction_images = model.decoder(trajectory_latent_tensor.float(), trajectory_latent_tensor.shape[0])\nreconstruction_images.shape\n\ntorch.Size([10, 1, 28, 28])\n\n\n\nreconstruction_images = reconstruction_images.detach()\n\n\nfig, ax = plt.subplots(1,num_steps, figsize=(num_steps+10,4))\nax = ax.flatten()\n\nfor i in range(0, reconstruction_images.shape[0]):\n    ax[i].imshow(reconstruction_images[i][0], cmap=cm.binary, interpolation='nearest')\n    ax[i].set_title('Step: {}'.format(i+1))\n    ax[i].set_xticks([])\n    ax[i].set_yticks([]);\n\n\n\n\nVisualizing the image generated from each embedding iterated in a linear fashion from start to finish shows the transition between end points"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#denoising-images",
    "href": "posts/2021-03-18-autoencoder.html#denoising-images",
    "title": "Anamoly detection using autoencoders",
    "section": "Denoising images",
    "text": "Denoising images\nAn autoencoder trained on cleaned image can be used to clear out blurry inputs from outside training set\n\n# Add artificial noise to a random image \nrand_idx = 420\ndigit_image, label = val_dataset[rand_idx]\ndigit_image = digit_image[0]\n\nplt.imshow(digit_image)\nplt.title('Image of {}'.format(label))\nplt.axis('off');\n\n\n\n\nAdd gaussian noise to the image. Code taken from Github\n\nrandom_noise = np.random.randn(digit_image.shape[0], digit_image.shape[1])\ndigit_image_noise = np.clip( digit_image + random_noise * 0.2, 0, 1)\nplt.imshow(digit_image_noise)\nplt.title('Image of {}'.format(label))\nplt.axis('off');\n\n\n\n\n\ndigit_input_tensor = torch.tensor(digit_image_noise[np.newaxis, np.newaxis, ...]).float();\n\n/depot/jgreeley/apps/envs/gpu_env1/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"Entry point for launching an IPython kernel.\n\n\n\ndigit_input_tensor.shape\n\ntorch.Size([1, 1, 28, 28])\n\n\n\npredicted_image, _ = model(digit_input_tensor)\npredicted_image = predicted_image.detach().numpy()\n\n\nplt.imshow(predicted_image[0][0])\nplt.title('Image of {}'.format(label))\nplt.axis('off');\n\n\n\n\nThe results are much more useful in the case of variational autoencoder which is more robust to noise in the input data since the latent is less sparse due to the variational part"
  },
  {
    "objectID": "posts/2021-03-18-autoencoder.html#anomaly-detection",
    "href": "posts/2021-03-18-autoencoder.html#anomaly-detection",
    "title": "Anamoly detection using autoencoders",
    "section": "Anomaly Detection",
    "text": "Anomaly Detection\n\ndef reconstruction_loss(input_image, _model=model, _criterion=criterion, plot=True):\n    model = _model.cpu()\n    input_image_tensor = torch.tensor(input_image)\n    \n    encoded_image, _ = model(input_image_tensor)\n    \n    loss_value = _criterion(encoded_image, input_image_tensor).item()\n    \n    encoded_image = encoded_image.detach().numpy()\n    \n    if plot == True:\n        fig, ax = plt.subplots(1,3,figsize=(10,5))\n        ax[0].imshow(input_image[0][0], cmap=cm.binary, interpolation='nearest')\n        ax[0].set_title('Input Image')\n        \n        ax[1].imshow(encoded_image[0][0], cmap=cm.binary, interpolation='nearest')\n        ax[1].set_title('Reconstructed Input')\n        \n        ax[2].imshow(input_image[0][0] - encoded_image[0][0], cmap=cm.binary, interpolation='nearest')\n        ax[2].set_title('Image Difference')\n        \n        ax[0].set_xticks([])\n        ax[0].set_yticks([])\n        ax[1].set_xticks([])\n        ax[1].set_yticks([])\n        ax[2].set_xticks([])\n        ax[2].set_yticks([])\n        \n    return(loss_value)\n\n\nrandom_entry_from_val_set = val_output_array[num_epochs-4][2].detach().numpy()[0]\nprint(random_entry_from_val_set.shape)\n\n(1, 28, 28)\n\n\n\ninput_image = random_entry_from_val_set[np.newaxis, ...]\nprint(input_image.shape)\n\n(1, 1, 28, 28)\n\n\n\nloss_value = reconstruction_loss(input_image)\ncompare_value = ('Higher' if loss_value > threshold_loss else 'lower')\nanamoly_tag = ('anomaly' if compare_value == 'Higher' else 'not an Anomaly')\nprint('Loss value is {0:6f} which is {1} than set threshold, so this image is {2}'.format(loss_value, compare_value, anamoly_tag))\n\nLoss value is 0.001904 which is lower than set threshold, so this image is not an Anomaly\n\n\n\n\n\n\nExample\n\nplt.imshow(input_image[0][0])\nplt.axis('off');\n\n\n\n\n\n# Rotate by 90: \ntemp_image_rotate = np.rot90(input_image, k=1, axes=(2,3)).copy() # To get rid of negative stride error \n\n\nplt.imshow(temp_image_rotate[0][0])\nplt.axis('off');\n\n\n\n\n\nloss_value = reconstruction_loss(temp_image_rotate)\ncompare_value = ('Higher' if loss_value > threshold_loss else 'lower')\nanamoly_tag = ('anomaly' if compare_value == 'Higher' else 'not an Anomaly')\nprint('Loss value is {0:6f} which is {1} than set threshold, so this image is {2}'.format(loss_value, compare_value, anamoly_tag))\n\nLoss value is 0.028646 which is Higher than set threshold, so this image is anomaly"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html",
    "title": "Implement neural network from scratch for binary classification",
    "section": "",
    "text": "In this notebook I build a simple neural network, having a single hidden layer. Next, I compare this model for its classification accuracy to a boilerplate logistic regression.\nThis notebook was inspired by Andrew Ng’s Deep Learning Specialization tutorial on Coursera"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#dataset",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#dataset",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Dataset",
    "text": "Dataset\nCode to make spirals is adapted from:\nhttp://cs231n.github.io/neural-networks-case-study/\n\nN = 400 # number of points per class\nD = 2 # dimensionality \nK = 2 # number of spokes\n\nX = np.zeros((N*K,D)) # data matrix (each row = single example)\nY = np.zeros(N*K, dtype='int') # class labels\n\nfor j in range(K):\n    ix = range(N*j,N*(j+1))\n    r = np.linspace(0, 1, N) # radius\n    t = np.linspace(j*4.2, (j+1)*4.2, N) + np.random.randn(N)*0.2 # theta\n    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n    Y[ix] = (0 if j % 2 == 0 else 1)\n\nX = copy.deepcopy(X.T)\nY = copy.deepcopy(Y.reshape(-1,1).T)\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\n    \n# lets visualize the data:\nax.scatter(X[0, :], X[1, :], c=Y.ravel(), s=40, cmap=plt.cm.Spectral)\nax.set_xlabel('$X_1$')\nax.set_ylabel('$X_2$')\nax.set_title('Visualize data')\n\nText(0.5, 1.0, 'Visualize data')\n\n\n\n\n\n\nshape_X = X.shape\nshape_Y = Y.shape\n\nprint ('The shape of X is: ' + str(shape_X))\nprint ('The shape of Y is: ' + str(shape_Y))\n\nThe shape of X is: (2, 800)\nThe shape of Y is: (1, 800)"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#simple-logistic-regression",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#simple-logistic-regression",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Simple Logistic Regression",
    "text": "Simple Logistic Regression\nBefore building a full neural network, lets first see how logistic regression performs on this problem. You can use sklearn’s built-in functions to do that. Run the code below to train a logistic regression classifier on the dataset.\n\n# Train the logistic regression classifier\nclf = sklearn.linear_model.LogisticRegression();\nclf.fit(X.T, Y.ravel());\n\nConvenience function to plot a decision boundary for the classification model\n\ndef plot_decision_boundary(func, x_input, y_input):\n    xx_1, xx_2 = np.mgrid[np.min(x_input[:,0]):np.max(x_input[:,0]):.01, np.min(x_input[:,1]):np.max(x_input[:,1]):.01]\n    grid = np.c_[xx_1.ravel(), xx_2.ravel()]\n    y_pred_grid = func(grid).reshape(xx_1.shape)\n    y_pred = func(x_input)\n    \n    fig, ax = plt.subplots(figsize=(10, 10))\n    contour = ax.contourf(xx_1, xx_2, y_pred_grid, alpha=0.7, cmap=\"Spectral\")\n    ax.scatter(x_input[:,0], x_input[:, 1], c=y_pred, s=50, cmap=\"Spectral\", edgecolor=\"white\", linewidth=1)\n    \n    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n            ]\n    ax.set(aspect='equal', \n           xlim=(np.min(x_input[:,0]), np.max(x_input[:,0])), ylim=(np.min(x_input[:,1]),np.max(x_input[:,1])),\n           xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n\n\nplot_decision_boundary(lambda x: clf.predict(x), X.T, Y.T)\nplt.title(\"Logistic Regression\")\n\nText(0.5, 1.0, 'Logistic Regression')\n\n\n\n\n\n\n# Print accuracy\nLR_predictions = clf.predict(X.T)\nprint ('Accuracy of logistic regression: %d ' % float((np.dot(Y, LR_predictions) + np.dot(1-Y, 1-LR_predictions))/float(Y.size)*100) +\n       '% ' + \"(percentage of correctly labelled datapoints)\")\n\nAccuracy of logistic regression: 66 % (percentage of correctly labelled datapoints)\n\n\nInterpretation: The dataset is not linearly separable, so logistic regression doesn’t perform well. Hopefully a neural network will do better."
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#neural-network-model",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#neural-network-model",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Neural Network model",
    "text": "Neural Network model\nLogistic regression did not work well on the dataset. Let’s train a Neural Network with a single hidden layer and see if it does any better.\nHere is basic framework for the model: \nMathematically:\nFor one example \\(x^{(i)}\\):\n\\[\nz^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}\n\\]\n\\[\na^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}\n\\]\n\\[\nz^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}\n\\]\n\\[\n\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}\n\\]\n\\[\ny^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}\n\\]\nGiven the predictions on all the examples, you can also compute the cost \\(J\\) as follows:\n\\[\nJ = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}\n\\]\nThe general methodology to build a Neural Network is to: 1. Define the neural network structure ( # of input units, # of hidden units, etc). 2. Initialize the model’s parameters 3. Loop: - Implement forward propagation - Compute loss - Implement backward propagation to get the gradients - Update parameters (gradient descent)\n\nDefining the neural network structure\nDefine three variables:\n- n_x: the size of the input layer\n- n_h: the size of the hidden layer (set this to 4) \n- n_y: the size of the output layer\n\ndef layer_sizes(X, Y, n_h=4):\n    \"\"\"\n    Arguments:\n    X -- input dataset of shape (input size, number of examples)\n    Y -- labels of shape (output size, number of examples)\n    \n    Returns:\n    n_x -- the size of the input layer\n    n_h -- the size of the hidden layer\n    n_y -- the size of the output layer\n    \"\"\"\n\n    n_x = X.shape[0] # size of input layer\n    n_h = n_h\n    n_y = Y.reshape(-1,1).T.shape[0] # size of output layer\n\n    return (n_x, n_h, n_y)\n\n\n(n_x, n_h, n_y) = layer_sizes(X, Y)\nprint(\"The size of the input layer is: n_x = \" + str(n_x))\nprint(\"The size of the hidden layer is: n_h = \" + str(n_h))\nprint(\"The size of the output layer is: n_y = \" + str(n_y))\n\nThe size of the input layer is: n_x = 2\nThe size of the hidden layer is: n_h = 4\nThe size of the output layer is: n_y = 1\n\n\n\n\nInitialize the model’s parameters\n\nInitialize the weights matrices with random values.\n\nUse: np.random.randn(a,b) * 0.01 to randomly initialize a matrix of shape (a,b).\n\nInitialize the bias vectors as zeros.\n\nUse: np.zeros((a,b)) to initialize a matrix of shape (a,b) with zeros.\n\n\n\ndef initialize_parameters(n_x, n_h, n_y):\n    \"\"\"\n    Argument:\n    n_x -- size of the input layer\n    n_h -- size of the hidden layer\n    n_y -- size of the output layer\n    \n    Returns:\n    params -- python dictionary containing your parameters:\n                    W1 -- weight matrix of shape (n_h, n_x)\n                    b1 -- bias vector of shape (n_h, 1)\n                    W2 -- weight matrix of shape (n_y, n_h)\n                    b2 -- bias vector of shape (n_y, 1)\n    \"\"\"\n    \n    np.random.seed(42) # we set up a seed so that your output matches ours although the initialization is random.\n\n    W1 = np.random.randn(n_h, n_x) * 0.01\n    b1 = np.zeros((n_h,1))\n    \n    W2 = np.random.randn(n_y, n_h) * 0.01\n    b2 = np.zeros((n_y,1))\n    \n    assert (W1.shape == (n_h, n_x))\n    assert (b1.shape == (n_h, 1))\n    assert (W2.shape == (n_y, n_h))\n    assert (b2.shape == (n_y, 1))\n    \n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n    \n    return parameters\n\n\n\nForward-pass\nImplement forward_propagation():\n\nRetrieve each parameter from the dictionary “parameters” (which is the output of initialize_parameters()) by using parameters[\"..\"].\nImplement Forward Propagation. Compute \\(Z^{[1]}, A^{[1]}, Z^{[2]}\\) and \\(A^{[2]}\\) (the vector of all your predictions on all the examples in the training set).\n\n\nValues needed in the backpropagation are stored in “cache”. The cache will be given as an input to the backpropagation function.\n\n\ndef sigmoid(x):\n    z = 1/(1 + np.exp(-x))\n    return z\n\n\ndef forward_propagation(X, parameters):\n    \"\"\"\n    Argument:\n    X -- input data of size (n_x, m)\n    parameters -- python dictionary containing your parameters (output of initialization function)\n    \n    Returns:\n    A2 -- The sigmoid output of the second activation\n    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n    \"\"\"\n    # Retrieve each parameter from the dictionary \"parameters\"\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    \n    ### END CODE HERE ###\n    \n    # Implement Forward Propagation\n    Z1 = np.dot(W1,X) + b1\n    A1 = np.tanh(Z1)\n    Z2 = np.dot(W2,A1) + b2\n    A2 = sigmoid(Z2)\n    \n    assert(A2.shape == (1, X.shape[1]))\n    \n    cache = {\"Z1\": Z1,\n             \"A1\": A1,\n             \"Z2\": Z2,\n             \"A2\": A2}\n    \n    return A2, cache"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#loss-function",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#loss-function",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Loss function",
    "text": "Loss function\nCompute the cost function as follows:\n\\[\nJ = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}\n\\]\n\ndef compute_cost(A2, Y):\n    \"\"\"\n    Computes the cross-entropy cost given in equation (13)\n    \n    Arguments:\n    A2 -- The sigmoid output of the second activation, of shape (1, number of examples)\n    Y -- \"true\" labels vector of shape (1, number of examples)\n    \n    Returns:\n    cost -- cross-entropy cost given equation (13)\n    \"\"\"\n    \n    m = Y.shape[1] # number of example\n\n    # Compute the cross-entropy cost\n    logprobs = np.dot(Y,np.log(A2).T) + np.dot((1-Y),np.log((1-A2)).T)\n    cost = -logprobs/m\n\n    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. E.g., turns [[17]] into 17 \n    assert(isinstance(cost, float))\n    \n    return cost"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#back-propogation",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#back-propogation",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Back-propogation",
    "text": "Back-propogation\nUsing the cache computed during forward propagation, now implement backward propagation.\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T}\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2})\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T\n\\]\n\\[\n\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}\n\\]\n\n\\(*\\) denotes elementwise multiplication.\nGradients for each later:\n\ndW1 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }\\)\ndb1 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }\\)\ndW2 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }\\)\ndb2 = \\(\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }\\)\n\n\n\ndef backward_propagation(parameters, cache, X, Y):\n    \"\"\"\n    Implement the backward propagation using the instructions above.\n    \n    Arguments:\n    parameters -- python dictionary containing our parameters \n    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n    X -- input data of shape (2, number of examples)\n    Y -- \"true\" labels vector of shape (1, number of examples)\n    \n    Returns:\n    grads -- python dictionary containing your gradients with respect to different parameters\n    \"\"\"\n    m = X.shape[1]\n    \n    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n    W1 = parameters['W1']\n    W2 = parameters['W2']\n\n    # Retrieve also A1 and A2 from dictionary \"cache\".\n    A1 = cache['A1']\n    A2 = cache['A2']\n\n    # Backward propagation: calculate dW1, db1, dW2, db2. \n    dZ2 = A2 - Y\n    dW2 = (1/m) * np.dot(dZ2,A1.T)\n    db2 = (1/m) * np.sum(dZ2,axis=1, keepdims=True)\n    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n    dW1 = (1/m) * np.dot(dZ1, X.T)\n    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n\n    grads = {\"dW1\": dW1,\n             \"db1\": db1,\n             \"dW2\": dW2,\n             \"db2\": db2}\n    \n    return grads\n\nGeneral gradient descent formalism: \\[ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }\\]\nwhere: \\(\\alpha\\) is the learning rate and \\(\\theta\\) represents a parameter.\n\ndef update_parameters(parameters, grads, learning_rate = 1.2):\n    \"\"\"\n    Updates parameters using the gradient descent update rule given above\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters \n    grads -- python dictionary containing your gradients \n    \n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    \"\"\"\n    # Retrieve each parameter from the dictionary \"parameters\"\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n\n    # Retrieve each gradient from the dictionary \"grads\"\n    dW1 = grads['dW1']\n    db1 = grads['db1']\n    dW2 = grads['dW2']\n    db2 = grads['db2']\n\n    # Update rule for each parameter\n    W1 = W1 - learning_rate*dW1\n    b1 = b1 - learning_rate*db1\n    W2 = W2 - learning_rate*dW2\n    b2 = b2 - learning_rate*db2\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n    \n    return parameters"
  },
  {
    "objectID": "posts/2021-02-05-nn_classification_from_scratch.html#integrate-previous-parts-nn_model",
    "href": "posts/2021-02-05-nn_classification_from_scratch.html#integrate-previous-parts-nn_model",
    "title": "Implement neural network from scratch for binary classification",
    "section": "Integrate previous parts nn_model()",
    "text": "Integrate previous parts nn_model()\n\ndef nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n    \"\"\"\n    Arguments:\n    X -- dataset of shape (2, number of examples)\n    Y -- labels of shape (1, number of examples)\n    n_h -- size of the hidden layer\n    num_iterations -- Number of iterations in gradient descent loop\n    print_cost -- if True, print the cost every 1000 iterations\n    \n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    \n    np.random.seed(42)\n    n_x, n_h, n_y = layer_sizes(X, Y, n_h=n_h)\n    \n    # Initialize parameters\n    parameters = initialize_parameters(n_x, n_h, n_y)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n         \n        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n        A2, cache = forward_propagation(X, parameters)\n        \n        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n        cost = compute_cost(A2, Y)\n \n        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n        grads = backward_propagation(parameters, cache, X, Y)\n \n        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n        parameters = update_parameters(parameters, grads, learning_rate = 1.2)\n\n        # Print the cost every 1000 iterations\n        if print_cost and i % 1000 == 0:\n            print (\"Cost after iteration %i: %f\" %(i, cost))\n\n    return parameters\n\n\nPredictions\nUse the model to predict: predict().\nUse forward propagation to predict results.\npredictions = \\(y_{prediction} = \\mathbb 1 \\text{{activation > 0.5}} = \\begin{cases}  1 & \\text{if}\\ activation > 0.5 \\\\  0 & \\text{otherwise}  \\end{cases}\\)\n\ndef predict(parameters, X):\n    \"\"\"\n    Using the learned parameters, predicts a class for each example in X\n    \n    Arguments:\n    parameters -- python dictionary containing your parameters \n    X -- input data of size (n_x, m)\n    \n    Returns\n    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n    \"\"\"\n    \n    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n    A2, cache = forward_propagation(X, parameters)\n    threshold = 0.5 \n    predictions = (A2 > threshold)\n    \n    return predictions\n\nIt is time to run the model and see how it performs on a planar dataset. Run the following code to test your model with a single hidden layer of \\(n_h\\) hidden units.\n\n# Build a model with a n_h-dimensional hidden layer\nparameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n\nCost after iteration 0: 0.693141\nCost after iteration 1000: 0.052671\nCost after iteration 2000: 0.040765\nCost after iteration 3000: 0.032499\nCost after iteration 4000: 0.027457\nCost after iteration 5000: 0.023722\nCost after iteration 6000: 0.020082\nCost after iteration 7000: 0.016282\nCost after iteration 8000: 0.013001\nCost after iteration 9000: 0.010872\n\n\n\ndef plot_decision_boundary_NN(func, x_input, y_input, ax=None):\n    xx_1, xx_2 = np.mgrid[np.min(x_input[:,0]):np.max(x_input[:,0]):.01, np.min(x_input[:,1]):np.max(x_input[:,1]):.01]\n    grid = np.c_[xx_1.ravel(), xx_2.ravel()].T\n    y_pred_grid = func(grid).reshape(xx_1.shape)\n    y_pred = func(x_input.T)\n    \n    if ax == None:\n        fig, ax = plt.subplots(1,1, figsize=(10,10))\n        \n    contour = ax.contourf(xx_1, xx_2, y_pred_grid, alpha=0.7, cmap=\"Spectral\")\n    ax.scatter(x_input[:,0], x_input[:, 1], c=y_pred, s=50, cmap=\"Spectral\", edgecolor=\"white\", linewidth=1)\n    \n    lims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n            np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n            ]\n    ax.set(aspect='equal', \n           xlim=(np.min(x_input[:,0]), np.max(x_input[:,0])), ylim=(np.min(x_input[:,1]),np.max(x_input[:,1])),\n           xlabel=\"$X_1$\", ylabel=\"$X_2$\")\n    return ax\n\n\n# Plot the decision boundary\nplot_decision_boundary_NN(lambda x: predict(parameters, x), X.T, Y.T)\nplt.title(\"Decision Boundary for hidden layer size \" + str(4))\n\nText(0.5, 1.0, 'Decision Boundary for hidden layer size 4')\n\n\n\n\n\n\n# Print accuracy\npredictions = predict(parameters, X)\nprint ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')\n\nAccuracy: 99%\n\n\nAccuracy is really high compared to Logistic Regression. The model has spirals! Neural networks are able to learn even highly non-linear decision boundaries, unlike logistic regression.\n\n\nTuning hidden layer size\nRun the following code to observe different behaviors of the model for various hidden layer sizes.\n\n# This may take about 2 minutes to run\nplt.figure(figsize=(16, 32))\nhidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\nfor i, n_h in enumerate(hidden_layer_sizes):\n    ax = plt.subplot(5, 2,i+1)\n    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n    plot_decision_boundary_NN(lambda x: predict(parameters, x), X.T, Y.T, ax)\n    predictions = predict(parameters, X)\n    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n    ax.title.set_text('Hidden Layer of size {} | Accuracy: {}%'.format(n_h, accuracy))\n\n\n\n\n\n\nReference:\n\nhttp://scs.ryerson.ca/~aharley/neural-networks/\nhttp://cs231n.github.io/neural-networks-case-study/"
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html",
    "href": "posts/2019-09-07-pca_tutorial.html",
    "title": "Principal component analysis",
    "section": "",
    "text": "Principal component analysis is one of the oldest tools to be implemented for analyzing feature sets in the data. It is fundamentally a dimensionality reduction technique targeted to reduce noise, feature reduction/extraction and engineering. It can also allow for providing ‘new’ features where are not necessarily correlated ensuring indenpedent treatment on the model."
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#general-idea",
    "href": "posts/2019-09-07-pca_tutorial.html#general-idea",
    "title": "Principal component analysis",
    "section": "General idea:",
    "text": "General idea:\nPCA introduces a new set of variables (called principal components, PCs) by linear combination of the original variables in the data, standardized to zero mean and unit variance (see Figure 12.8 for a toy example in two dimensions). The PCs are chosen such that they are uncorrelated, and they are ordered such that the first component captures the largest possible amount of variation in the data, and subsequent components capture increasingly less. Usually, key features in the data can be seen from only the first two or three PCs.\nExample: If we are trying to understand the effect of weight, age, and height in humans, the weight of the subject is an correlated variable to other two. Height is, in some way, related to weight and that is in a way related to age of the person. Hence understanding effect of one variable on the output without the effect on another is difficult if not impossible. Here, we can use PCA to project the age and weight in a new 2-D space where now the height can be related to THESE two variables independently. Now the drawback is that we do not necessarily know what do these two variables means. For understanding the inherent logic of the variables there are techniques like vari-max rotation used to recapture the projection that MIGHT be used to get the new variables.\nWhen should you use PCA?\n\nDo you want to reduce the number of variables, but aren’t able to identify variables to completely remove from consideration?\nDo you want to ensure your variables are independent of one another?\nAre you comfortable making your independent variables less interpretable?"
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#useful-resources",
    "href": "posts/2019-09-07-pca_tutorial.html#useful-resources",
    "title": "Principal component analysis",
    "section": "Useful Resources:",
    "text": "Useful Resources:\n\nJake VanderPlas’s Python Data Science Handbook Chapter\nTutorial on Principal Component Analysis by Jonathan Shlens (Google Research)\n\nCurrently, PCA, when categorizing it from ML-terminology standpoint, is considered as a dimensionality reduction and a fast-flexible unsupervised learning method. Let’s look at simplified example:\n\nTwo dimensional data-set\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns; sns.set()\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nrng = np.random.RandomState(42)\nx1=rng.randn(2,200) #Normally distributed 200 entries with 2 rows\nfactor=rng.rand(2,2) #factor to multiply the entries \n\n\n#Defining the vectors as column vectors \nX = np.dot(factor, x1).T\nplt.scatter(X[:,0],X[:,1])\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.axis('equal');\n\n\n\n\nIn principal component analysis, this relationship is quantified by finding a list of the principal axes in the data, and using those axes to describe the dataset. Using Scikit-Learn’s PCA estimator, we can compute this as follows:\n\nfrom sklearn.decomposition import PCA \npca=PCA(n_components=2, random_state=42)\npca.fit(X)\n\nPCA(n_components=2, random_state=42)\n\n\n\nprint(pca.components_)\n\n[[ 0.41224135  0.91107468]\n [ 0.91107468 -0.41224135]]\n\n\n\nprint(pca.explained_variance_)\n\n[0.86789943 0.11361735]\n\n\nPCA analysis learns some quantities in the data. To visualize the ‘Principal components’ we can look at the Components which are the directions of the vector and Explained Variance is the square-length magnitude of the vector.\n\ndef draw_vector(v0, v1, ax=None):\n    ax = ax or plt.gca()\n    arrowprops=dict(arrowstyle='->',\n                    linewidth=2.5,\n                    color='k',\n                    shrinkA=0, shrinkB=0)\n    ax.annotate('',v1,v0,arrowprops=arrowprops)\n\nplt.scatter(X[:,0], X[:,1], alpha=0.6)\nfor length, vector in zip(pca.explained_variance_, pca.components_):\n    v = vector * 4. * np.sqrt(length) #vector enhanced by a factor of 5 and the sqrt(lenght)\n    print(v)\n    draw_vector(pca.mean_, pca.mean_+v) #Pre PCA dataset mean\n\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.axis('equal');\n\n[1.53619465 3.3950695 ]\n[ 1.22839009 -0.55581963]\n\n\n\n\n\nThe vectors above represent the principal axes of the data. Length of the vector is how imporatant are they. That is given by how much variance is explained by that axes. The projection of each data point onto the principal axes are the “principal components” of the data. If we plot the original data and the data being transformed such that the principal components are now the unit axes (through translation, rotation, and scaling of the data) we will get something like this\n\nfig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\n# plot data\nax[0].scatter(X[:, 0], X[:, 1], alpha=0.6)\n\nfor length, vector in zip(pca.explained_variance_, pca.components_):\n    v = vector * 3 * np.sqrt(length)\n    draw_vector(pca.mean_, pca.mean_ + v, ax=ax[0])\nax[0].axis('equal');\nax[0].set(xlabel='x', ylabel='y', title='input')\n\n# plot principal components\nX_pca = pca.transform(X)\nax[1].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6)\ndraw_vector([0, 0], [0, 3], ax=ax[1])\ndraw_vector([0, 0], [3, 0], ax=ax[1])\nax[1].axis('equal')\nax[1].set(xlabel='Component 1', ylabel='Component 2',\n          title='principal components',\n          xlim=(-5, 5), ylim=(-3, 3.1));"
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#going-to-higher-dimensions",
    "href": "posts/2019-09-07-pca_tutorial.html#going-to-higher-dimensions",
    "title": "Principal component analysis",
    "section": "Going to higher dimensions",
    "text": "Going to higher dimensions\nThe usefulness of the dimensionality reduction may not be entirely apparent in only two dimensions, but becomes much more clear when looking at high-dimensional data. We can appreciate it more for classifying the feature sets used to predict the handwriten digits\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\ndigits.data.shape\n\n(1797, 64)\n\n\nThe data consists of 8×8 pixel images, meaning that they are 64-dimensional. To gain some intuition into the relationships between these points, we can use PCA to project them to a more manageable number of dimensions, say two\n\npca = PCA(n_components=2)  # project from 64 to 2 dimensions\nprojected = pca.fit_transform(digits.data)\nprint(digits.data.shape)\nprint(projected.shape)\n\n(1797, 64)\n(1797, 2)\n\n\nWe can now plot the dataset on the transformed space along the two components\n\nplt.figure(figsize=(10,10))\nplt.scatter(projected[:, 0], projected[:, 1],\n            c=digits.target, edgecolor='none', alpha=0.5,\n            cmap=plt.cm.get_cmap('Spectral', 10))\nplt.xlabel('component 1')\nplt.ylabel('component 2')\nplt.colorbar();\n\n\n\n\nInitially the data set for each image was a 64 dimensional entry. We now project that 64 dimensional data on a two component principal axes. The PCA routine has found the optimal stretch and rotation in the 64 dimensional space that allows us to see the layout of the digits in two dimensions. This was done in unsupervised manner."
  },
  {
    "objectID": "posts/2019-09-07-pca_tutorial.html#important-featuresconsiderations",
    "href": "posts/2019-09-07-pca_tutorial.html#important-featuresconsiderations",
    "title": "Principal component analysis",
    "section": "Important features/considerations:",
    "text": "Important features/considerations:\n\nLinearity: The underlying idea of PCA is to find another basis for representing the data. This makes PCA is a change of basis problem.\nVariance: To identify which direction to project the data on, signal-to-noise ratio calculated by variance is assumed to model the interesting nature. Hence principal components with larger variance represent the interesting structure.\nOrthogonality: The principal components are orthonormal basis vectors. This allows PCA to provide an intuitive simplification\n\nCovariance matrix is a symmetric matrix that measures the degree of pair-wise linear relationship in the data. - The diagonal entries estimate the variance of the variable - while the off-diagonal entries estimate the covariance between a given pair of variables.\nIdeally, for the case to reduce dimensions and correlations the resulting covariance for the data from change of basis should have off-diagonal elements as 0 and only diagonal elements which are ordered magnitude-wise.\nIn practice computing PCA of dataset following steps: 1. Recast the data as zero mean dataset 2. Compute eigenvectors for the covariance matrix for the dataset – these are the principal components of the data 3. Those eigenvectors would diagonalize the covariance matrix of the original dataset 4. The diagonal entries of the new covariance matrix will give the variance along each principal component\nThe diagonalised matrix from the above transformation is the covariance matrix for the projected data-set. This is made of the eigenvalues of the covariance matrix of original data\n\\[\\begin{align*}\nC_{Y}&=\\frac{YY^{T}}{n} \\\\\n&=\\frac{(PX)(PX)^{T}}{n} \\\\\n&=\\frac{PXP^{T}X^{T}}{n} \\\\\n&=\\frac{P(XX)^{T}P^{T}}{n} \\\\\n&=PC_{X}P^{T} \\\\\n\\end{align*}\\]\nHere P is the eigenvector of Cov(X) matrix\nLet’s use the first example as a basis for explanation:\n\nrng = np.random.RandomState(42)\nx1=rng.randn(2,200) #Normally distributed 200 entries with 2 rows\nfactor=rng.rand(2,2) #factor to multiply the entries \n\nX = np.dot(factor, x1)\nplt.scatter(X[0,:],X[1,:])\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.axis('equal');\n\n\n\n\n\n# Standarize the data \nX_center = np.empty(shape=X.shape)\nX_center[0,:]=X[0,:]-np.mean(X[0,:])\nX_center[1,:]=X[1,:]-np.mean(X[1,:])\n\n\n#Estimate covariance of orginal data\ncov_X = np.dot(X,X.T)/(X_center.shape[1]-1)\nprint(cov_X)\n\n[[0.24184557 0.28376997]\n [0.28376997 0.74491787]]\n\n\n\n# Eigendecomposition of the covariance matrix\neigen_values, eigen_vectors = np.linalg.eig(cov_X) #eigen_values[i] is eigenvalue of eigen_vector[:,i]\nprint(eigen_vectors)\n\n[[-0.91195569 -0.4102887 ]\n [ 0.4102887  -0.91195569]]\n\n\n\nvalues_vectors = [(np.abs(eigen_values[i]), eigen_vectors[:,i]) for i in range(len(eigen_values))]\n\n\n#sort the vectors based on the values\nvalues_vectors = sorted(values_vectors, key=lambda x:x[0], reverse=True)\nprint(values_vectors)\n\n[(0.8725859273634107, array([-0.4102887 , -0.91195569])), (0.11417751236536822, array([-0.91195569,  0.4102887 ]))]\n\n\n\nfig, ax_new = plt.subplots(1, 2, figsize=(16, 6))\n\n# plot data\nax_new[0].scatter(X[0, :], X[1, :], alpha=0.6)\nax_new[0].axis('equal');\nax_new[0].set(xlabel='x', ylabel='y', title='input')\n\n# plot principal components\nX_transform = np.dot(eigen_vectors.T,X)\nax_new[1].scatter(X_transform[0, :], X_transform[1, :], alpha=0.6)\nax_new[1].axis('equal')\nax_new[1].set(xlabel='component 1', ylabel='component 2',\n          title='principal components',\n          xlim=(-5, 5), ylim=(-3, 3.1))\n\n[Text(0.5, 0, 'component 1'),\n Text(0, 0.5, 'component 2'),\n Text(0.5, 1.0, 'principal components'),\n (-5.0, 5.0),\n (-3.0, 3.1)]\n\n\n\n\n\n\npca=PCA(n_components=2, random_state=42)\npca.fit(X.T)\npca_results = [(np.abs(pca.explained_variance_[i]), pca.components_[:,i]) for i in range(len(pca.explained_variance_))]\npca_results = sorted(pca_results, key=lambda x:x[0], reverse=True)\nprint(pca_results)\n\n[(0.867899431633577, array([0.41224135, 0.91107468])), (0.11361735469514019, array([ 0.91107468, -0.41224135]))]\n\n\n\ncov_Y = np.dot(eigen_vectors.T,np.dot(cov_X,eigen_vectors))\n\n\nnp.around(cov_Y,4)\n\narray([[0.1142, 0.    ],\n       [0.    , 0.8726]])"
  },
  {
    "objectID": "posts/2020-10-19-pytorch_transfer_learning_basics.html",
    "href": "posts/2020-10-19-pytorch_transfer_learning_basics.html",
    "title": "Transfer learning walkthrough using Pytorch",
    "section": "",
    "text": "Transfer learning is a technique where a deep-learning model trained on another problem (which usually has lot of data and good accuracy for that task) is slightly modified to be used on a new problem. This is an important concept as building an entirely new model might not be take a long time or there might not be enough data for the training of that particular task. The idea is the weights/parameters of the model at the start of the layers have similar functionality and assist in better performance on the new task. Usually we freeze the weights training of the hidden layers an tweak the output layer slightly to account for the change in the task.\nSo for example, maybe you could have the neural network learn to recognize objects like cats and then use that knowledge or use part of that knowledge to help you do a better job reading x-ray scans. This is called transfer learning. Sometimes you can start with the weights and biases of a published netowrks as a starting point.\nMore details about Transfer Learning can be found on Stanford’s CS231 CNN course here\nIn this example I use a pre-trained convolutional neural network model (ResNet-18) and modify ONLY the last layers of the model to use for our case. This model is trained on millions on images with 1000 image categories.\nThese two major transfer learning scenarios look as follows:\n\nFinetuning the convnet: Instead of random initialization, we initialize the network with a pretrained network, like the one that is trained on imagenet 1000 dataset. Rest of the training looks as usual.\nConvNet as fixed feature extractor: Here, we will freeze the weights for all of the network except that of the final fully connected layer. This last fully connected layer is replaced with a new one with random weights and only this layer is trained.\n\nThis tutorial was adapted from PyTorch’s official documentation (Link)\n\nimport time \nimport os \nimport copy \nimport matplotlib.pyplot as plt\nimport numpy as np \n\nimport torch \nimport torch.nn as nn \nimport torch.optim as optim \nfrom torch.optim import lr_scheduler\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\n%matplotlib inline \n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\ndevice(type='cpu')\n\n\n\n# Define pre-processing steps for the image before being converted to Tensors\n# As defined on the tutorial page \n\nmean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.25, 0.25, 0.25])\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ]),\n}\n\n\ndata_dir = 'data/hymenoptera_data/'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\n\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=0)\n              for x in ['train', 'val']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n\n\nclass_names = image_datasets['train'].classes\nprint(class_names)\n\n['ants', 'bees']\n\n\n\n# From the pytorch tutorial\ndef imshow(inp, title):\n    \"\"\"Imshow for Tensor.\"\"\"\n    fig, ax = plt.subplots(1,1, figsize=(10,10))\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    ax.imshow(inp)\n    plt.title(title)\n    plt.show()\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n\n\n\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step() #Step in the scheduler \n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model for which val_acc is better \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    \n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    \n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n\n\n\nDownload a pretrained model, tweak the model architecture for our use-case, and (re)train on the new dataset\n\n\nDownload the model (ResNet18 in this case)\nChange the output of the final layer – in this case from 1000 output nodes to 2 since we’re looking at only ‘bee’ and ‘ant’\nRe-train the model\n\nOther models available from PyTorch can be viewed (here)\n\n#Load a pre-trained model -- ResNet18 model \nmodel = torchvision.models.resnet18(pretrained=True)\nprint(model)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\nWe’re interested to only change the final layer named fc – so we will look at that layers features, the attributes for each module in the model are stored as keys.\n\nnum_features = model.fc.in_features\n\n# Define a new linear layer as per our need -- 2 classes instead of 1000 as defined in the original \nmodel.fc = nn.Linear(num_features, len(class_names)) #Number of classes in the end \n\n# Send model to device \nmodel.to(device)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n\n\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n#Scheduler to update the learning rate for the SGD \n'''\nAfter every 7 steps in the optimizer the learning rate will be multiplied by 0.1 \n'''\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1) \n\n\nmodel = train_model(model, criterion=criterion, optimizer=optimizer, scheduler=step_lr_scheduler, num_epochs=5)\n\nEpoch 0/4\n----------\ntrain Loss: 1.0695 Acc: 0.5000\nval Loss: 0.6179 Acc: 0.6340\n\nEpoch 1/4\n----------\ntrain Loss: 0.7267 Acc: 0.5820\nval Loss: 0.8217 Acc: 0.5948\n\nEpoch 2/4\n----------\ntrain Loss: 0.6941 Acc: 0.6230\nval Loss: 0.8131 Acc: 0.6667\n\nEpoch 3/4\n----------\ntrain Loss: 0.6948 Acc: 0.5902\nval Loss: 1.6474 Acc: 0.5882\n\nEpoch 4/4\n----------\ntrain Loss: 0.6834 Acc: 0.6270\nval Loss: 0.9145 Acc: 0.6275\n\nTraining complete in 5m 11s\nBest val Acc: 0.666667\n\n\n\n\n\nIn this case ONLY the weights of the final layer are trained. This might reduce the accuracy but would greatly reduce the amount of time taken to fit the model since the number of weights to be optimized is greatly reduced.\n\n#Load a pre-trained model -- ResNet18 model \nmodel = torchvision.models.resnet18(pretrained=True)\n\n\n#Method to freeze the layer parameters -- just get the require grad attribute to FALSE!  \nfor param in model.parameters(): \n    param.requires_grad = False \n\n\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 2) #Number of classes in the end \nmodel.to(device)\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n\n\nThis block is same as before\n\ncriterion = nn.CrossEntropyLoss() \noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n#Scheduler to update the learning rate for the SGD \n'''\nAfter every 7 steps in the optimizer the learning rate will be multiplied by 0.1 \n'''\nstep_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1) \n\nModel training\n\nmodel = train_model(model, criterion=criterion, optimizer=optimizer, scheduler=step_lr_scheduler, num_epochs=5)\n\nEpoch 0/4\n----------\ntrain Loss: 0.6937 Acc: 0.5615\nval Loss: 0.5267 Acc: 0.7974\n\nEpoch 1/4\n----------\ntrain Loss: 0.5915 Acc: 0.7008\nval Loss: 0.4388 Acc: 0.8627\n\nEpoch 2/4\n----------\ntrain Loss: 0.5249 Acc: 0.7623\nval Loss: 0.3686 Acc: 0.9216\n\nEpoch 3/4\n----------\ntrain Loss: 0.5079 Acc: 0.7664\nval Loss: 0.3188 Acc: 0.9477\n\nEpoch 4/4\n----------\ntrain Loss: 0.4556 Acc: 0.8115\nval Loss: 0.3007 Acc: 0.9281\n\nTraining complete in 2m 18s\nBest val Acc: 0.947712\n\n\nUsing fine-tuning and re-training all the weights for the new network take longer and may result in lower acceracy than having the weights fixed. When we keep the weights in earlier layers fixed, we save a lot of time in the model training aand the performance of the model is also better (provided the two tasks are quite similar). Given the network is deep, optimizing the weights for this network from scratch would have been difficult and time consuming. For such a case, transfer learning seems to be a good option."
  },
  {
    "objectID": "posts/2019-10-11-vectorisation_and_tf_example.html",
    "href": "posts/2019-10-11-vectorisation_and_tf_example.html",
    "title": "Vectorisation in python using numpy",
    "section": "",
    "text": "import numpy as np \nimport time \n\na = np.random.randint(10E6,size=(50,1000))\nprint(np.shape(a))\n\nw = np.random.randint(100,size=(50,1))\nprint(np.shape(w))\n\n(50, 1000)\n(50, 1)"
  },
  {
    "objectID": "posts/2019-10-11-vectorisation_and_tf_example.html#general-principle",
    "href": "posts/2019-10-11-vectorisation_and_tf_example.html#general-principle",
    "title": "Vectorisation in python using numpy",
    "section": "General principle",
    "text": "General principle\n(m,n) matrix with (+, -, *, /) with (1,n) or (m,1) lead of copying it to (m,n) before conducting computing."
  },
  {
    "objectID": "posts/IMDB-files/bollywood_imdb_scrapper.html",
    "href": "posts/IMDB-files/bollywood_imdb_scrapper.html",
    "title": "Web-scraping Hindi (Bollywood) movies from IMDb",
    "section": "",
    "text": "from requests import get \nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport time as time \nfrom tqdm import tqdm\n\nfrom IPython.core.display import clear_output\n\n\nnames, year, imdb_rating, metascore, num_votes = [], [], [], [], [] \n\nstart_time = time.time()\nrequests = 0\n\nyears_url = [str(i) for i in range(1950,2006)]\npage_iter = [0, 51, 101, 151, 201]\n\n\nfor year_url in tqdm(years_url):\n    for page_num in tqdm(page_iter):\n        #URL to parse \n        url = 'https://www.imdb.com/search/title/?title_type=feature,&release_date={0},{0}&countries=in&languages=hi&sort=num_votes,desc&start={1}&ref_=adv_prv'.format(int(year_url), int(page_num))\n        response = get(url)\n        \n        #Sleep to carve out load \n        time.sleep(np.random.randint(1,5))\n        \n        #Estimate time elapsed per request\n        requests += 1\n        elapsed_time = time.time() - start_time\n        print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))\n        clear_output(wait = True)\n        \n        html_soup = BeautifulSoup(response.text, 'html.parser')\n        movie_containers = html_soup.find_all('div', class_='lister-item mode-advanced')\n        \n        for i, container in enumerate(movie_containers):\n            container_entry = movie_containers[i] \n            movie_name = container_entry.h3.a.text\n            names.append(movie_name)\n            \n            movie_year = container_entry.h3.find('span',class_='lister-item-year text-muted unbold').text.strip('()')\n            year.append(movie_year)\n            #print(movie_name, movie_year)\n            \n            try:\n                movie_rating = float(container_entry.strong.text)\n                imdb_rating.append(movie_rating)\n            except AttributeError:\n                imdb_rating.append(np.nan)\n            \n            try:\n                movie_votes = float(''.join(container_entry.find('span', attrs = {'name':'nv'}).text.split(',')))\n                num_votes.append(movie_votes)\n            except (AttributeError, ValueError):\n                num_votes.append(np.nan)\n                \n            try:\n                movie_metascore = float(container_entry.find('span', class_='metascore').text.strip())\n                metascore.append(movie_metascore)\n            except AttributeError:\n                metascore.append(np.nan)\n    \n    print('Making dataframe for year {}'.format(year_url))\n    df_movies = pd.DataFrame({'name':names,'year':year,'rating':imdb_rating,'metascore':metascore,'num_votes':num_votes})\n    df_movies.to_csv('./temp_imdb_files/bollywood_data_{}.csv'.format(year_url),sep=',',header=True, index=False)\n    del df_movies\n\n\n100%|██████████| 5/5 [00:30<00:00,  6.14s/it]\n100%|██████████| 56/56 [20:00<00:00, 21.44s/it]\n\n\nMaking dataframe for year 2005\n\n\n\n\n\n\ndf1 = pd.read_csv('./temp_imdb_files/bollywood_data_2005.csv',sep=',')\ndf2 = pd.read_csv('./temp_imdb_files/bollywood_data_2020.csv',sep=',')\n\n\ndf3 = pd.concat((df1, df2)).reset_index(drop=True)\n\n\ndf3.to_csv('./bollywood_movies_data_1950_2020_new.csv',sep=',',header=True, index=False)\n\n\ndf3.year.value_counts()\n\n2004           249\n2001           249\n2005           248\n2000           246\n1991           241\n              ... \nII) (1988        1\nII) (1957        1\nXVII) (2016      1\nIV) (2011        1\nI) (1954         1\nName: year, Length: 181, dtype: int64"
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html",
    "href": "posts/07_28-uspto_rxn.html",
    "title": "Classifying reactions using machine-learning",
    "section": "",
    "text": "Using data-driven methods to classify reactions in different categories."
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html#viewing-it-as-pandas-dataframe",
    "href": "posts/07_28-uspto_rxn.html#viewing-it-as-pandas-dataframe",
    "title": "Classifying reactions using machine-learning",
    "section": "Viewing it as Pandas dataframe",
    "text": "Viewing it as Pandas dataframe\n\ncolumn_names = ['SMILES', 'Patent No', 'Rxn Class']\ndf_rxn = pd.DataFrame(rxn_data_list, columns=column_names)\n\n\ndf_rxn\n\n\n\n\n\n  \n    \n      \n      SMILES\n      Patent No\n      Rxn Class\n    \n  \n  \n    \n      0\n      [CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10...\n      US06887874\n      6.1.5\n    \n    \n      1\n      O.O.[Na+].[CH3:1][c:2]1[cH:7][c:6]([N+:8](=O)[...\n      US07056926\n      7.1.1\n    \n    \n      2\n      [CH3:1][O:2][c:3]1[cH:4][cH:5][c:6](-[c:9]2[cH...\n      US08492378\n      1.8.5\n    \n    \n      3\n      Cl.[CH3:43][CH2:42][S:44](=[O:45])(=[O:46])Cl....\n      US08592454\n      2.2.3\n    \n    \n      4\n      [CH3:25][O:24][c:21]1[cH:22][cH:23][c:17]([O:1...\n      US06716851\n      1.3.7\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      49995\n      [BH4-].[Na+].[CH3:25][O:24][c:19]1[cH:18][c:17...\n      US08324216\n      7.3.1\n    \n    \n      49996\n      [BH4-].[Na+].[N:30]#[C:29][c:26]1[cH:25][cH:24...\n      US07595398\n      7.3.1\n    \n    \n      49997\n      [N:15]#[C:14][CH2:13][c:1]1[cH:2][n:3][n:4]2[c...\n      US08273761\n      7.3.1\n    \n    \n      49998\n      B.Cl.CO.[CH3:12][C:8]([OH:13])([CH2:9][C:10]#[...\n      US08609849\n      7.3.1\n    \n    \n      49999\n      [CH3:2][CH2:1][O:3][C:4](=[O:5])[C:6]1([C:14]#...\n      US07030267\n      7.3.1\n    \n  \n\n50000 rows × 3 columns\n\n\n\n\ndf_rxn.dtypes\n\nSMILES       object\nPatent No    object\nRxn Class    object\ndtype: object\n\n\n\ndf_rxn['Rxn Class'].value_counts()\n\n6.1.5     1000\n3.3.1     1000\n1.3.8     1000\n1.3.6     1000\n3.1.5     1000\n6.2.3     1000\n3.4.1     1000\n6.1.3     1000\n1.7.6     1000\n10.1.2    1000\n9.1.6     1000\n10.1.5    1000\n10.4.2    1000\n7.1.1     1000\n6.3.1     1000\n1.7.7     1000\n7.9.2     1000\n8.1.5     1000\n1.7.4     1000\n7.2.1     1000\n8.1.4     1000\n8.2.1     1000\n7.3.1     1000\n2.1.7     1000\n9.3.1     1000\n6.1.1     1000\n6.3.7     1000\n2.1.2     1000\n1.8.5     1000\n2.2.3     1000\n1.3.7     1000\n1.7.9     1000\n6.2.2     1000\n2.7.2     1000\n2.6.1     1000\n1.6.8     1000\n3.1.1     1000\n1.6.2     1000\n1.2.1     1000\n1.6.4     1000\n1.2.5     1000\n2.3.1     1000\n5.1.1     1000\n10.1.1    1000\n2.1.1     1000\n2.6.3     1000\n6.2.1     1000\n10.2.1    1000\n1.2.4     1000\n3.1.6     1000\nName: Rxn Class, dtype: int64\n\n\n\ndf_rxn.iloc[42069]\n\nSMILES       [H][H].[O:32]=[C:18]1[NH:17][C:16](=[O:33])[C@...\nPatent No                                           US08377927\nRxn Class                                                6.3.1\nName: 42069, dtype: object\n\n\n\ndf_rxn.SMILES[42069]\n\n'[H][H].[O:32]=[C:18]1[NH:17][C:16](=[O:33])[C@@H:15]([c:12]2[cH:11][cH:10][c:9]([O:8]Cc3ccccc3)[cH:14][cH:13]2)[C@@H:19]1[c:20]1[cH:21][n:22]2[c:31]3[c:30]1[cH:29][cH:28][cH:27][c:26]3[CH2:25][CH2:24][CH2:23]2>>[O:32]=[C:18]1[NH:17][C:16](=[O:33])[C@@H:15]([c:12]2[cH:13][cH:14][c:9]([OH:8])[cH:10][cH:11]2)[C@@H:19]1[c:20]1[cH:21][n:22]2[c:31]3[c:30]1[cH:29][cH:28][cH:27][c:26]3[CH2:25][CH2:24][CH2:23]2'\n\n\n\ndisplay_rxn(df_rxn.SMILES[42069])\n\n\n\n\nGenerate Chemical Entries object in Rdkit from the RXN SMILES\n\n%%time \n# Convert Smiles strings to reaction objects - this takes the most time and might be helpful if parallelized \nfrom rdkit.Chem import rdChemReactions # Main reaction analysis class \ndf_rxn['rxn_obj'] = df_rxn['SMILES'].apply(rdChemReactions.ReactionFromSmarts)\n\nCPU times: user 13.9 s, sys: 1.61 s, total: 15.5 s\nWall time: 15.5 s\n\n\n\ndf_rxn['rxn_obj'][42069]\n\n\n\n\n\ntemp_rxn = df_rxn['rxn_obj'][42069]\n\n\ntype(temp_rxn)\n\nrdkit.Chem.rdChemReactions.ChemicalReaction"
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html#convert-the-rxn-objects-to-fps-and-save-pickle",
    "href": "posts/07_28-uspto_rxn.html#convert-the-rxn-objects-to-fps-and-save-pickle",
    "title": "Classifying reactions using machine-learning",
    "section": "Convert the rxn objects to FPs and save pickle",
    "text": "Convert the rxn objects to FPs and save pickle\n\ndf_rxn.sample(2)\n\n\n\n\n\n  \n    \n      \n      SMILES\n      Patent No\n      Rxn Class\n      rxn_obj\n    \n  \n  \n    \n      37512\n      [OH-].[Na+].Cl.[K+].[BH3-]C#N.[CH3:5][CH2:4][N...\n      US06964966\n      1.2.5\n      <rdkit.Chem.rdChemReactions.ChemicalReaction o...\n    \n    \n      934\n      [OH-].[K+].[CH3:14][C@H:5]([CH2:6][c:7]1[cH:8]...\n      05166218\n      1.7.9\n      <rdkit.Chem.rdChemReactions.ChemicalReaction o...\n    \n  \n\n\n\n\n\n%%time\ndf_rxn['FP_Morgan_wo_agents'] = df_rxn['rxn_obj'].apply(diff_fpgen)\n\nCPU times: user 18.5 s, sys: 1.05 s, total: 19.5 s\nWall time: 19.6 s\n\n\nAdding in agents is giving me problem right now - debug it eventually\ndf_rxn[‘Agent_Morgan_FP2’] = df_rxn[‘rxn_obj’].apply(create_agent_feature_FP)"
  },
  {
    "objectID": "posts/07_28-uspto_rxn.html#make-training-and-test-set",
    "href": "posts/07_28-uspto_rxn.html#make-training-and-test-set",
    "title": "Classifying reactions using machine-learning",
    "section": "Make training and test set",
    "text": "Make training and test set\n\n%%time \nX_FPs = np.array( [hashedFPToNPfloat(x) for x in df_rxn['FP_Morgan_wo_agents']] )\n\nCPU times: user 3.38 s, sys: 591 ms, total: 3.97 s\nWall time: 4 s\n\n\n\nY_class = np.array( df_rxn['Rxn Class'] )\n\n\nrtypes = sorted(list(reaction_types))\n\n\nrtype_int = [int(''.join(entry.split('.'))) for entry in rtypes]\n\n\nlen(set(rtype_int))\n\n50\n\n\nNote on multi-class classification:\nhttps://scikit-learn.org/stable/modules/multiclass.html#multiclass-classification\nLabelBinarizer is not needed if you are using an estimator that already supports multiclass data.\nhttps://scikit-learn.org/stable/modules/preprocessing_targets.html#preprocessing-targets\n\nOption 1: OHE\nCreate one hot encoding – does it help to create OHE now? Not sure but doing it here as a first pass.\nY_class_labels = [ rtypes.index(i) for i in Y_class]\nY_class_OHE = np.zeros(shape=(len(Y_class_labels), len(rtypes)), dtype=int) for i, j in enumerate(Y_class_labels): Y_class_OHE[i][j] = 1\nrxn_dict = {i:0 for i in rtypes} for i, j in enumerate(Y_train): rxn_class_id = int(np.argmax(j)) rxn_dict[ rtypes[rxn_class_id] ] += 1\nrxn_dict\n\n\nOption 2: Leave as is\n\nleave_as_is = True \nif leave_as_is == True:\n    Y_target = Y_class\nelse: \n    Y_target = Y_class_OHE \n\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nstratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n\n\nfor train_idx, test_idx in stratSplit.split(X_FPs, Y_target):\n    X_train = X_FPs[train_idx]\n    Y_train = Y_target[train_idx]\n    \n    X_test = X_FPs[test_idx]\n    Y_test = Y_target[test_idx]"
  },
  {
    "objectID": "posts/2021-01-10-pncbirthday.html",
    "href": "posts/2021-01-10-pncbirthday.html",
    "title": "Solving the birthday problem using simple counting",
    "section": "",
    "text": "This problem and discussion herein was adapted from Computational Thinking course offered by MIT. Link to course page\nQuestion from First Course in Probability (Sheldon Ross):\nGiven 20 people, what is the probability that, among the 12 months in the year, there are 4 months containing exactly 2 birthdays and 4 containing exactly 3 birthdays? Link to problem\n\nimport os \nimport time\nimport numpy as np \n\nnp.random.seed(42)\n\n\nProblem setup\nRather than using a formula to estimate the probability we can setup an experiment using for-loops to mimic the trials and then count the actual number of cases where the condition is met.\n\nmonth_number = np.arange(1, 13) # array of months \nnumber_of_people = 20 #Number of people considered\nsample = np.random.choice(month_number, size=number_of_people, replace=True, )\n\nHere sample is the randomized set of 20 birthdays. Each entry is a month. Length of sample is same as number of people in the experiment, 20 in this case.\nHighlight cases which satisfy the constraints: 1. 4 months have exactly 2 birthdays 2. 4 months have exactly 3 birthdays\nFor that first create an array with frequency of birthdays in each month:\n\nfrequency = np.zeros(len(month_number)) #This is zeros frequency array\nfor _entry in sample:\n    _index = _entry - 1\n    frequency[_index] = frequency[_index] + 1\n\n\nsample\n\narray([ 7,  4, 11,  8,  5,  7, 10,  3,  7, 11, 11,  8,  5,  4,  8,  8,  3,\n        6,  5,  2])\n\n\n\nfrequency\n\narray([0., 1., 2., 2., 3., 1., 3., 4., 0., 1., 3., 0.])\n\n\nfrequency array shows how many birthday are there in a month (Jan - Dec).\nOnce we have that, now we have to consider the conditions given in the problem. We can either do this using for/if statement or using numpy.argwhere, where the number of months satisfying the conditions is estimated directly.\n\nlen(np.argwhere(frequency == 2)) \n\n2\n\n\nNow putting it all together and doing multiple trials.\nIn this case, I do 1,500,000 trials and count the ratio of successes to the total trials. While this process takes time, it is better than remembering permutation and combination formulae ;P\nThis is a variant of monte-carlo simulation.\n\n%%time\n# putting it all togther \n_number_of_trials = 1_500_000\n_success = 0 \n  \nfor _ in range(_number_of_trials):\n\n    sample = np.random.choice(month_number, size=number_of_people, replace=True)\n    \n    frequency = np.zeros( len(month_number) )\n    for _entry in sample:\n        if _entry in month_number:\n            _index = _entry - 1\n            frequency[_index] = frequency[_index] + 1\n    \n    if ( len(np.argwhere(frequency == 2)) == 4 ) and ( len(np.argwhere(frequency == 3)) == 4 ): \n        _success = _success + 1\n\nprint('Probability of success = {}'.format(_success / _number_of_trials))\n\nProbability of success = 0.00106\nCPU times: user 3min 8s, sys: 2.08 s, total: 3min 10s\nWall time: 3min 10s\n\n\nThis answer is very close you’d get from using probablity counting and formula!"
  },
  {
    "objectID": "posts/2022-11-20-cheminfo-clustering.html",
    "href": "posts/2022-11-20-cheminfo-clustering.html",
    "title": "Cheminformatics basics - Clustering molecules",
    "section": "",
    "text": "This tutorials is made using references from : * https://github.com/PatWalters/practical_cheminformatics_tutorials * https://doc.datamol.io/stable/tutorials/Clustering.html * https://greglandrum.github.io/rdkit-blog/similarity/tutorial/2020/11/18/sphere-exclusion-clustering.html\nGenerate fingerprints for the molecules - using Morgan FP2\nCalculate distance matrix for the molecules\nClustering the molecules based on the FPs and the distance matrix\nCalculate intra cluster similarity for the molecules"
  },
  {
    "objectID": "posts/2022-11-20-cheminfo-clustering.html#pick-the-most-diverse-molecules-from-the-cluster",
    "href": "posts/2022-11-20-cheminfo-clustering.html#pick-the-most-diverse-molecules-from-the-cluster",
    "title": "Cheminformatics basics - Clustering molecules",
    "section": "Pick the most diverse molecules from the cluster",
    "text": "Pick the most diverse molecules from the cluster\nImplementation of Sphere exclusion algorithm (also called Leader) from Roger Sayles.\n\nfrom rdkit.SimDivFilters import rdSimDivPickers\nlp = rdSimDivPickers.LeaderPicker()\n\n\nthreshold = 0.65 # <- minimum distance between clusters \npicks = lp.LazyBitVectorPick(fps, len(fps), threshold)\nlen(picks)\n\n3291"
  },
  {
    "objectID": "posts/2021-05-23-brfss_eda.html",
    "href": "posts/2021-05-23-brfss_eda.html",
    "title": "Exploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset",
    "section": "",
    "text": "Before beginning with any sort of model building work it is important you get to know the data you’re handling. This includes not just understand the columns and row entries in the dataset but also the simple understanding on what each of the variable in the data means.\nThis step is a vital foundation for any successful analytics, modeling, and prediction task. It is called as the data exploratory analysis.\nThese are few some steps you can keep in mind when starting with an exploration of new dataset being presented: 1. Understand each descriptor in the data, type of data being encoded 2. Cleaning the data – look at null and NaN 3. Visualize variable distributions – use (appropriate) summary statistics * Primary analysis of data spread – histograms * Distribution functions 1. Probability mass functions 2. Cumulative distribution function 3. Kernel density estimates\n\nExplore relationship between variables\n\nScatter plots\nSimple (linear) correlations (Pearson statistics)\nSimple (linear) regression\n\nExplore multivariate relationships\n\nMultiple regression (for continuous variables)\nLogistic regression (for categorical variables)\n\n\nIn this notebook I will cover some of these steps as we explore the Behavioral Risk Factor Surveillance Survey (BRFSS) dataset and try to tease out simple correlations with the variables.\nBRFSS data obtained from: * https://www.kaggle.com/sakinak/behavioral-risk-factor-surveillance-survey-201619\nCode book: This is an extremely important document helping us make sense of the data we’ve imported * https://www.cdc.gov/brfss/annual_data/2019/pdf/codebook19_llcp-v2-508.HTML\n\nimport os\nimport numpy as np \nimport copy \nimport pandas as pd\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 15,\n'axes.titlesize' : 20,\n'axes.labelsize' : 15,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 10,\n'ytick.labelsize' : 10,\n}\n \nplt.rcParams.update(plot_params)\nsns.set_palette(\"colorblind\")\nsns.color_palette('colorblind')\n\n\n\n\n\n# Functions for PMF and CDF, we will come to those later in the notebook \ndef pmf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    return pmf \n\ndef cdf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    cdf = np.zeros(shape=pmf.shape) \n    \n    for i in range(0, pmf.shape[0]):\n        cdf[i] = [pmf[i][0], np.sum(pmf[:i+1], axis=0)[-1]] \n        \n    return cdf \n\n\n# Read archive file -- considering only the 2019 dataset \ndf = pd.read_csv('./archive/2019.csv')\n\n\ndf.columns\n\nIndex(['Unnamed: 0', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR',\n       'DISPCODE', 'SEQNO', '_PSU',\n       ...\n       '_VEGESU1', '_FRTLT1A', '_VEGLT1A', '_FRT16A', '_VEG23A', '_FRUITE1',\n       '_VEGETE1', '_FLSHOT7', '_PNEUMO3', '_AIDTST4'],\n      dtype='object', length=343)\n\n\n\ndf.shape\n\n(418268, 343)\n\n\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418268 entries, 0 to 418267\nColumns: 343 entries, Unnamed: 0 to _AIDTST4\ndtypes: float64(280), int64(63)\nmemory usage: 1.1 GB\n\n\n\ndf.columns[ df.isna().any() ]\n\nIndex(['CTELENM1', 'PVTRESD1', 'COLGHOUS', 'STATERE1', 'CELPHONE', 'LADULT1',\n       'COLGSEX', 'NUMADULT', 'LANDSEX', 'NUMMEN',\n       ...\n       'FRUTDA2_', 'GRENDA1_', 'FRNCHDA_', 'POTADA1_', 'VEGEDA2_', '_FRUTSU1',\n       '_VEGESU1', '_FLSHOT7', '_PNEUMO3', '_AIDTST4'],\n      dtype='object', length=275)\n\n\nThe data is too big to be visualized and described using traditional NaN and summary statistics, rather let’s just checkout key columns and understand their distribution"
  },
  {
    "objectID": "posts/2021-05-23-brfss_eda.html#looking-at-individual-columns",
    "href": "posts/2021-05-23-brfss_eda.html#looking-at-individual-columns",
    "title": "Exploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset",
    "section": "1. Looking at individual columns",
    "text": "1. Looking at individual columns\nSex of the respondent\nData is provided in the column marked as _SEX and the label are: * MALE = 1 * FEMALE = 2\n\ndf['_SEX'].value_counts()\n\n2    228433\n1    189835\nName: _SEX, dtype: int64\n\n\nAnnual Income of the respondent\nINCOME2 Question: Is your annual household income from all sources\nValue of 77 or 99 in the row is either Refused or Not sure. So take them out\n_INCOMG Computed income categories\n\ndf['INCOME2'].value_counts()\n\n8.0     117793\n7.0      54252\n6.0      46572\n99.0     40246\n5.0      34496\n77.0     32654\n4.0      30001\n3.0      23391\n2.0      16122\n1.0      15860\nName: INCOME2, dtype: int64\n\n\n\ndf['_INCOMG'].value_counts()\n\n5    172045\n9     79781\n2     53392\n4     46572\n3     34496\n1     31982\nName: _INCOMG, dtype: int64\n\n\n\n# Replace 77 99 with NaN\ndf['INCOME2'].replace([77, 99], np.nan, inplace=True)\n\n\ndf['INCOME2'].value_counts()\n\n8.0    117793\n7.0     54252\n6.0     46572\n5.0     34496\n4.0     30001\n3.0     23391\n2.0     16122\n1.0     15860\nName: INCOME2, dtype: int64\n\n\n\ndf.shape\n\n(418268, 343)\n\n\nDrop the entries with NaN\n\ndf_income_no_nan = df.dropna(subset=['INCOME2'])\ndf_income_no_nan.shape\n\n(338487, 343)\n\n\n\ndf_income_no_nan['INCOME2'].value_counts()\n\n8.0    117793\n7.0     54252\n6.0     46572\n5.0     34496\n4.0     30001\n3.0     23391\n2.0     16122\n1.0     15860\nName: INCOME2, dtype: int64\n\n\n\npmf_income = pmf(df_income_no_nan['INCOME2'])\n\n\npmf_income\n\narray([[1.        , 0.04685557],\n       [2.        , 0.0476296 ],\n       [3.        , 0.06910457],\n       [4.        , 0.08863265],\n       [5.        , 0.10191233],\n       [6.        , 0.13758874],\n       [7.        , 0.16027794],\n       [8.        , 0.34799859]])\n\n\n\nplt.plot(pmf_income[:,0], pmf_income[:,1], marker='o')\nplt.xlabel('Income Classes')\nplt.ylabel('Frequency (normalized)')\n\nText(0, 0.5, 'Frequency (normalized)')\n\n\n\n\n\n\ncdf_income = cdf(df_income_no_nan['INCOME2'])\n\n\ncdf_income\n\narray([[1.        , 0.04685557],\n       [2.        , 0.09448516],\n       [3.        , 0.16358974],\n       [4.        , 0.25222239],\n       [5.        , 0.35413472],\n       [6.        , 0.49172346],\n       [7.        , 0.65200141],\n       [8.        , 1.        ]])\n\n\n\nplt.plot(cdf_income[:,0], cdf_income[:,1], marker='o')\nplt.xlabel('Income Classes')\nplt.ylabel('Cumulative Frequency (normalized)')\n\nText(0, 0.5, 'Cumulative Frequency (normalized)')\n\n\n\n\n\nLooking at annual income classes as per sex of the respondent\n\ndf_income_no_nan_male = df_income_no_nan.loc[ df_income_no_nan['_SEX'] == 1 ]\n\n\ndf_income_no_nan_female = df_income_no_nan.loc[ df_income_no_nan['_SEX'] == 2 ]\n\n\ncdf_income_male = cdf(df_income_no_nan_male['INCOME2'])\ncdf_income_female = cdf(df_income_no_nan_female['INCOME2'])\n\n\nplt.plot(cdf_income_male[:,0], cdf_income_male[:,1], marker='o', label='Male')\nplt.plot(cdf_income_female[:,0], cdf_income_female[:,1], marker='o', label='Female')\nplt.plot(cdf_income[:,0], cdf_income[:,1], linestyle='--', label='Total')\nplt.xlabel('Income Classes')\nplt.ylabel('Cumulative Frequency (normalized)')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fb1a8eb5520>\n\n\n\n\n\nConsidering the education level of the respondents\nEDUCA What is the highest grade or year of school you completed?\n9 and BLANK == Missing and Refused\n_EDUCAG Computed level of education completed categories\n\ndf['EDUCA'].value_counts().sort_index()\n\n1.0       619\n2.0      9940\n3.0     19506\n4.0    111890\n5.0    116591\n6.0    157887\n9.0      1809\nName: EDUCA, dtype: int64\n\n\n\ndf['EDUCA'].replace([9], np.nan, inplace=True)\n\n\ndf['_EDUCAG'].value_counts()\n\n4    157887\n3    116591\n2    111890\n1     30065\n9      1835\nName: _EDUCAG, dtype: int64\n\n\n\ndf['_EDUCAG'].value_counts(normalize=True).sort_index()\n\n1    0.071880\n2    0.267508\n3    0.278747\n4    0.377478\n9    0.004387\nName: _EDUCAG, dtype: float64\n\n\n\ndf_education_no_na = df.dropna(subset = ['EDUCA'])\n\n\ndf_education_no_na.shape\n\n(416433, 343)\n\n\n\ndf_education_no_na_male = df_education_no_na.loc[ df_education_no_na['_SEX'] == 1 ]\ndf_education_no_na_female = df_education_no_na.loc[ df_education_no_na['_SEX'] == 2 ]\n\n\ncdf_educa_male = cdf(df_education_no_na_male['EDUCA'])\ncdf_educa_female = cdf(df_education_no_na_female['EDUCA'])\n\n\ncdf_educa = cdf(df_education_no_na['EDUCA'])\n\n\ncdf_educa\n\narray([[1.00000000e+00, 1.48643359e-03],\n       [2.00000000e+00, 2.53558195e-02],\n       [3.00000000e+00, 7.21964878e-02],\n       [4.00000000e+00, 3.40883167e-01],\n       [5.00000000e+00, 6.20858577e-01],\n       [6.00000000e+00, 1.00000000e+00]])\n\n\n\nplt.plot(cdf_educa_male[:,0], cdf_educa_male[:,1], marker='o', label='Male')\nplt.plot(cdf_educa_female[:,0], cdf_educa_female[:,1], marker='o', label='Female')\nplt.plot(cdf_educa[:,0], cdf_educa[:,1], linestyle='--', label='Total')\nplt.xlabel('Level of education')\nplt.ylabel('Cumulative Frequency (normalized)')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fb0dcfd2160>\n\n\n\n\n\nHeight and Weight\n\n## Height in meters \ndf.hist('HTM4')\n\narray([[<AxesSubplot:title={'center':'HTM4'}>]], dtype=object)\n\n\n\n\n\n\n## Weight in kilograms:\ndf.hist('WTKG3')\n\narray([[<AxesSubplot:title={'center':'WTKG3'}>]], dtype=object)\n\n\n\n\n\n\ndf['WTKG3'] = df['WTKG3'] / 100\n\n\n## Weight in kilograms:\ndf.hist('WTKG3')\n\narray([[<AxesSubplot:title={'center':'WTKG3'}>]], dtype=object)\n\n\n\n\n\n\nwt_male = df.loc[ df['_SEX'] == 1 ]['WTKG3']\nwt_female = df.loc[ df['_SEX'] == 2 ]['WTKG3']\n\n\nplt.hist(wt_male, alpha=0.6, label='male')\nplt.hist(wt_female, alpha=0.6, label='female')\nplt.xlabel('Weight (kg)')\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7fafcf2eabe0>\n\n\n\n\n\n\n## Age category -- divided in 5 year interval \ndf.hist('_AGEG5YR')\n\narray([[<AxesSubplot:title={'center':'_AGEG5YR'}>]], dtype=object)\n\n\n\n\n\n\nQuick plot for weight vs age-group\n\n## Quick plot for weight as per age \ndf_no_nans = df.dropna( subset=['_AGEG5YR', 'WTKG3'] )\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.scatter( df_no_nans['_AGEG5YR'], df_no_nans['WTKG3'], marker='o', alpha=0.5)\nax.set_xlabel('Age group')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')\n\n\n\n\n\nIt makes much more sense to show these as either violin or box plot:\n\nViolin plot – KDE for that column around the y Each column is a graphical representation of the distribution of weight in one age group. The width of these shapes is proportional to the estimated density, so it’s like two vertical PDFs plotted back to back.  \nBox plot – Each box represents the interquartile range, or IQR, from the 25th to the 75th percentile. The line in the middle of each box is the median. The spines sticking out of the top and bottom show the minimum and maximum values. Looking at the medians, it seems like people in their 40s are the heaviest; younger and older people are lighter. Looking at the sizes of the boxes, it seems like people in their 40s have the most variability in weight, too. These plots also show how skewed the distribution of weight is; that is, the heaviest people are much farther from the median than the lightest people.\n\n\nimport seaborn as sns\nax = sns.boxplot(x = '_AGEG5YR', y = 'WTKG3', whis=10, data = df_no_nans)\nax.set_xlabel('AGE GROUP')\nax.set_ylabel('WEIGHT (Kgs)')\n\nText(0, 0.5, 'WEIGHT (Kgs)')\n\n\n\n\n\n\n\nQuick plot for height vs weight\n\ndf_height_wt = df.dropna( subset=['HTM4', 'WTKG3'] ).sample(50000)\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.scatter( df_height_wt['HTM4'], df_height_wt['WTKG3'], marker='o', alpha=0.5)\nax.set_xlabel('Height (m)')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')\n\n\n\n\n\n\nheight_jitters = df_height_wt['HTM4'] + np.random.normal(0, 2, size=len(df_height_wt))\nweight_jitters = df_height_wt['WTKG3'] + np.random.normal(0, 2, size=len(df_height_wt))\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.scatter( height_jitters, weight_jitters, marker='o', alpha=0.01)\nax.set_xlabel('Height (m)')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')\n\n\n\n\n\nFit a linear regression model\n\nfrom sklearn.linear_model import LinearRegression\nx = height_jitters.values.reshape(-1,1)\ny = weight_jitters.values.reshape(-1,1)\nreg = LinearRegression().fit(x, y)\n\n\nx.min()\n\n90.14298210689765\n\n\n\nprint(reg.coef_, reg.intercept_, reg.score(x,y))\n\n[[0.90102916]] [-71.05446729] 0.2163310658640062\n\n\n\nheight_test = np.linspace(x.min(), x.max()).reshape(-1, 1)\n\n\nfig, ax = plt.subplots(1,1, figsize=(6,6))\nax.plot( height_test, reg.predict(height_test), 'r--', alpha=0.5)\nax.scatter( height_jitters, weight_jitters, marker='o', alpha=0.01)\nax.set_xlabel('Height (m)')\nax.set_ylabel('Weight (kg)')\n\nText(0, 0.5, 'Weight (kg)')"
  },
  {
    "objectID": "posts/2020-12-21-central_limit_theorem.html",
    "href": "posts/2020-12-21-central_limit_theorem.html",
    "title": "Central limit theorem",
    "section": "",
    "text": "The distribution of the sum of independent samples consisting of n points drawn from an arbitrary distribution approach a normal distribution as n increases.\nIf the distribution of the values has a mean and standard deviation, the distribution of sum is approximately given by $ N(n, n^2)$\nSome points to keep in mind: - The values are to be drawn independently - The values have to come from same distribution - The underlying distribution should have finite mean and variance - The rate convergence to the normal distribution depends on the skewness of the parent distribution.\nWe start with some crazy distribution that has got nothing to do with a normal distribution. Sample points from that distribution with some arbitrary sample size, following which we plot the sample mean (or sample sum) on a frequency table – repeat this lot of times (tending to infinity) we end up getting a normal distribution of sample means!\nThe Central Limit Theorem explains the prevalence of normal distributions in the natural world. This limit is central to the ideas of hypothesis testing and helpful for estimating confidence intervals.\n\nKhan Academy video explaining this\n\nBelow a simple python experiment to show this in action.\n\nimport random as rand \nimport numpy as np \nfrom scipy import stats \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n\n# Plot matplotlib plots with white background: \n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nplot_params = {\n'font.size' : 10,\n'axes.titlesize' : 10,\n'axes.labelsize' : 10,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 10,\n'ytick.labelsize' : 10,\n}\n \nplt.rcParams.update(plot_params)\n\nsns.color_palette('colorblind')\n\n\n\n\n\nfrom numpy.random import default_rng\nrng = default_rng(42)\n\n\n\nFor this case let’s assume we have a dice which is unfair and does not ever land on 3 and 5, and lands more on 2 and 6. We can build this skewed probability into the dice using the weights.\n\ndice = np.arange(1,7) # Dice numbers possible \nprobabilities = [0.2, 0.3, 0.0, 0.2, 0.0, 0.3] #Weighted probabilites for the numbers \n\nDefine a function to draw samples from the dice and calculate the mean.\n\n# Draw sample size = n, take the mean and plot the frequencies \ndef sample_draw_mean(_trials=1000, _sample_size=1):\n    sample_mean_trials = []\n    # Sample a number from the distribution equal to trials\n    for i in range(_trials):\n        sample = rng.choice(dice, size=_sample_size, p=probabilities, replace=True)\n        sample_mean_trials.append(np.mean(sample))\n    return sample_mean_trials\n\nDrawing sample_size=1 from the distribution multiple times, i.e. equal to num_of_trials variable\n\nnum_of_trials = 1000\nsample_size = 1\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\nFor sample size of 1, the frequency of numbers rolled by the unfair dice relates to the probability we have set above. However we can start to define samples from that distribution wherein, instead of single number we draw (for example 4).\n\n\n\nnum_of_trials = 1000\nsample_size = 4\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\n\nnum_of_trials = 1000\nsample_size = 20\nsns.histplot(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size), bins=len(dice), stat='density', kde=True);\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\n\n\n\n\nAs we keep plotting the frequency distribution for the sample mean it starts to approach the normal distribution!\n\ndef normal_distribution(x, mean=0, sigma=1):\n    out = (1/np.sqrt(2 * np.pi * sigma ** 2)) * np.exp(-1/2 * ((x - mean)/sigma)**2)\n    return(out)\n\n\nnum_of_trials = 1000\nsample_size = 20\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nsample_means = np.sort(sample_draw_mean(_trials=num_of_trials, _sample_size=sample_size))\n# Plot histogram density\nsns.histplot(sample_means, bins=len(dice), stat='density', kde=False, ax=ax)\n# Plot normal distribution\nax.plot(sample_means, normal_distribution(sample_means, np.mean(sample_means), np.std(sample_means)), color='black', linestyle='--', label='Normal Distribution')\n# Plot sample mean\nax.axvline(np.mean(sample_means), color='red', linestyle='--', linewidth=2.0, label='Sample Mean')\nax.set_xlabel('Dice number')\nplt.title('Visualize sample mean distribution for {} sample drawn {} times'.format(sample_size, num_of_trials), fontsize=15);\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n# Define an exponential distribution\nbeta = 5.0 \nnum_of_trials = 1000\nsample_size_list = [1, 10, 100, 500]\n\n\ndef generate_mean_samples(_beta, _iter, _sample_size):\n    samples_mean = []\n    for i in range(_iter):\n        sample_numbers = np.random.exponential(_beta, _sample_size)\n        samples_mean.append(np.mean(sample_numbers))\n    return(samples_mean)\n\n\nsample_plot_list = []\nfor n in sample_size_list:\n    sample_plot_list.append((n, generate_mean_samples(beta, num_of_trials, n)))\n\n\nfig, ax = plt.subplots(2,2, figsize=(10,10))\nax = ax.flatten()\nfor i, entry in enumerate(sample_plot_list): \n    sns.histplot(entry[1], stat='density', alpha=0.6, kde=False, ax=ax[i])\n    ax[i].set_title('Sample size: {}'.format(entry[0]))\n    sample_mean = np.mean(entry[1])\n    sample_std = np.std(entry[1])\n    normal_x = np.sort(entry[1])\n    # Plot normal distribution \n    ax[i].plot(normal_x, normal_distribution(normal_x,sample_mean,sample_std), linewidth=4.0, color='black', linestyle='--', label='Normal Distribution')\n    \n    # Sample mean\n    ax[i].axvline(sample_mean, color='red', linestyle='--', linewidth=4.0, label='Sample Mean')\n    ax[i].set_xlabel('Sample Mean')\nplt.suptitle(r'Visualize sample mean distribution for Exponential distribution $\\beta$={}, Sampled {} times'.format(beta, num_of_trials));\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n#plt.tight_layout()\n\n<matplotlib.legend.Legend at 0x133a00070>\n\n\n\n\n\n\n\n\nEstimate coin toss probability\nA coin is flipped 30 times, you get 22 heads. Find if the coin is fair or not. That is, if the probability of getting heads-tails is 50%.\nThis can be solved by estimating the probability of getting heads / tails provided the above condition is met.\nSince we can model the coin toss process (a priori model) using Bernoulli’s distribution, we will estimate the probability of 22 heads considering a fair coin. This will be our Null Hypothesis.\nNull hypothesis: The null hypothesis is a model of the system based on the assumption that the apparent effect was actually due to chance.\nAssuming a bernoulli distribution:\n\\[X_{i} \\sim B(p)\\]\n\\[ P(N_H=22) = \\binom nx p^{22}(1-p)^{30-22} \\]\nBy central limit theorem: \\[ \\sum_{i=1}^{30}{X_{i}} \\sim N(30p, 30(1-p)) \\]\nFrom maximum likelihood estimate, more detailts on MLE can be found here.:\n\\[ \\hat{p} = 0.73 \\]\nEstimate 95% confidence interval: * Assuming a normal distribution: \\[ \\mu \\pm 1.96 \\sigma \\]\n\\[ 30\\hat{p} \\pm 1.96 \\sqrt{ 30 * (1-\\hat{p}) } \\]\n\\[ 22 \\pm 1.96 \\sqrt{( 30 * 0.26 )} = (16.4, 27.58) \\]\n\nrng = np.random.default_rng(42)\n\nDefine a numpy.random.choice function to simulate coin tosses. This can repeated to 30 times.\n\nsampling_30 = rng.choice([0,1], replace=True, size=30) # we can randint(2) here as well. \n\nnp.where is used to find the entries with heads, that way for each 30 coin tosses we can estimate how many heads are there. In this case we are treating heads as 1 and tails as 0\n\nlen(np.where(sampling_30 == 1)[0]) # or just sum the list since all we have is 1 / 0 \n\n15\n\n\n\nsum(sampling_30)\n\n15\n\n\nSetup the problem to perform multiple trails of 30 coin tosses, when done with the trials we will keep an account of how many of those trials had 22 heads.\n\nheads_condition = 22\nnum_heads_list = []\nconstraint_satisy = 0\nnum_trials = 5000\n\n\nfor _ in range(num_trials):\n    sampling_30 = rng.choice([0,1], replace=True, size=30, p=[0.50,0.50]) # A-priori fair coin toss model \n    number_of_heads = len(np.where(sampling_30 == 1)[0])\n    num_heads_list.append(number_of_heads)\n    \n    if number_of_heads == heads_condition:\n        constraint_satisy = constraint_satisy + 1  \n        \nnum_heads_list = np.array(num_heads_list)\n\n\nlen(num_heads_list)\n\n5000\n\n\nDefining a normal distribution function from scipy or we could also use the function defined previously.\n\nfrom scipy.stats import norm\nx = np.linspace(min(num_heads_list), max(num_heads_list))\nstd_norm_coin = norm(np.mean(num_heads_list), np.std(num_heads_list))\n\n\nquantiles_95_confidence = np.quantile(num_heads_list, [0.025, 0.975])\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,5))\n\n# Plot histogram density\nsns.histplot(num_heads_list, stat='density', kde=False, ax=ax)\n\n# Plot normal distribution\nax.plot(x, std_norm_coin.pdf(x), color='black', linestyle='--', label='Normal Distribution')\n\n# Plot sample mean\nax.axvline(np.mean(num_heads_list), color='red', linestyle='--', linewidth=2.0, label='Sample Mean')\nax.axvline(heads_condition, color='blue', linestyle='-', linewidth=2.0, label='Experiment condition')\n\n\n# Plot confidence interval \nax.axvspan(quantiles_95_confidence[0], quantiles_95_confidence[1], alpha=0.15, color='yellow',label='95% confidence interval')\n\nax.set_xlabel('Number of heads in 30 coin tosses')\nplt.title('Visualize distribution of number of heads for 30 coin tosses sampled {} times'.format(num_trials), fontsize=15);\nplt.legend(loc=\"upper left\")\nplt.tight_layout()\n\n\n\n\np-value estimate\n\np_value = constraint_satisy / num_trials\nprint(p_value)\n\n0.0042\n\n\nSince p-value is less than 0.05, this means the coin is not fair\nFor most problems, we only care about the order of magnitude: if the p-value is smaller that 1/100, the effect is likely to be real; if it is greater than 1/10, probably not. If you think there is a difference between a 4.8% (significant!) and 5.2% (not significant!), you are taking it too seriously."
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html",
    "href": "posts/2021-06-13-pandas_resources.html",
    "title": "Pandas cookbook",
    "section": "",
    "text": "Selected Pandas code snippets and recipes that I revisit now and again. The snippets are adopted from different python scripts written over time, ignore the variable names.\nThis post was inspired by the wonderful work of Chris Albon and his snippets of code blocks."
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#reading-and-writing",
    "href": "posts/2021-06-13-pandas_resources.html#reading-and-writing",
    "title": "Pandas cookbook",
    "section": "Reading and Writing",
    "text": "Reading and Writing\nBasic reading a blank csv file\n# If you have no column names but know the number of columns\npd.read_csv(file_name, header=None, names=['col1','col2'])\nSaving a file to not have ‘Unamed’ column\ndf1.to_csv(os.path.join(output_dir, 'file_name_to_save_as.csv'), sep=',',columns=df1.columns, index=False, header=False) # header = None for no column names\nQuickly generate pandas dataframe from n lists\nsmiles = [\"C\", \"CCC\"]\nlabels = [1.5, 2.3]\ndf = pd.DataFrame( list( zip(smiles, labels) ), columns=[\"smiles\", \"task\"] )\nInformation about the dataframe\npandas_dataframe.info()\nSummary statistics (mean, quartile ranges)\npandas_dataframe.describe().round(2)\nReplace\ndf = df.replace( [list_of_value_to_replace], value_to_replace_with)\n# Eg: df.replace( [98-99], np.nan)\nReplace characters in the columns\n# List of characters to remove\nchars_to_remove = ['+','$',',']\n\n# List of column names to clean\ncols_to_clean = ['Installs','Price']\n\n# Loop for each column in cols_to_clean\nfor col in cols_to_clean:\n    # Loop for each char in chars_to_remove\n    for char in chars_to_remove:\n        # Replace the character with an empty string\n        apps[col] = apps[col].apply(lambda x: x.replace(char, ''))\n    # Convert col to float data type\n    apps[col] = apps[col].astype(float)\nConvert spaces titles in the row to one word separated by ‘-’\nreduced_df['product_title'] = reduced_df['product_title'].apply( lambda x: x.lower().replace(' ', '-') )\nDefine a new column with temp entries\npandas_dataframe['columns_name'] = 42 \nCreate columns in a loop\npandas_dataframe.columns = ['feature_' + str(i) for i in range(n_columns)]\nDropping miscellaneous columns and NaN entries\ncolumns_to_drop = ['CookTimeInMins', 'Servings', 'Course', 'Diet', 'Instructions', 'TranslatedInstructions', 'URL']\nfood_df = food_df.drop(columns = columns_to_drop).dropna()"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#post-process",
    "href": "posts/2021-06-13-pandas_resources.html#post-process",
    "title": "Pandas cookbook",
    "section": "Post process",
    "text": "Post process\nHighlight cells based on a condition\ndf = pd.DataFrame({\n    \"col1\":[-5,-2,1,4],\n    \"col2\":[2,3,-1,4]\n})\n\ndef highlight_number(row):\n    return[\n    \"background-color: red; color:white\"\n    if cell <= 0\n    else \"background-color: green; color:white\"\n    for cell in row\n    ]\n\ndf.style.apply(highlight_number)"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#quick-plotting",
    "href": "posts/2021-06-13-pandas_resources.html#quick-plotting",
    "title": "Pandas cookbook",
    "section": "Quick plotting",
    "text": "Quick plotting\nSimple pearson correlation plot\n# Generate Pearson Correlation Matrix for HOUSING \ncorr_matrix=housing.corr()\n\n# Edit the visuals and precision \ncorr_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n\n# Look at Pearson values for one attribute \ncorr_matrix['median_house_value'].sort_values(ascending=True)\nPlot multiple scatter plots\nfrom pandas.plotting import scatter_matrix\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_axes = scatter_matrix(housing[attributes], figsize=(12, 8));"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#handling-missing-values",
    "href": "posts/2021-06-13-pandas_resources.html#handling-missing-values",
    "title": "Pandas cookbook",
    "section": "Handling missing values",
    "text": "Handling missing values\nOption A: Dropping values in the columns with NaN\nhousing.dropna(subset=[\"total_bedrooms\"])\nOption B: Drop that column entirely\nhousing.drop(\"total_bedrooms\", axis=1)\nOption C: Fill missing value with some central tendency\nattribute_median = housing[\"total_bedrooms\"].median()\nhousing[\"total_bedrooms\"].fillna( attribute_median, inplace=True ) \nChecking the NULL enties in the dataset\nsample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nGet number of NULL entries in the dataframe columns\nnull_columns=food_df.columns[food_df.isnull().any()]\nfood_df[null_columns].isnull().sum()\nPrint full rows having NULL entries in the df\nis_NaN = food_df.isnull()\nrow_has_NaN = is_NaN.any(axis=1)\nrows_with_NaN = food_df[row_has_NaN]\nDropping NULL only from a particular column\ndf_income_drop_na = df.dropna(subset=['INCOME2'])"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#join-two-datasets",
    "href": "posts/2021-06-13-pandas_resources.html#join-two-datasets",
    "title": "Pandas cookbook",
    "section": "Join two datasets",
    "text": "Join two datasets\n1. Inner join\nOnly returns rows with matching values in both df.\nA_B = A.merge(B, on = <common column name>, suffixes = tuples to append the name of columns with similar names) \nRemember that .merge() only returns rows where the values match in both tables.\n2. Merging more than one table\ndf1.merge(df2, on='col_A') \\\n    .merge(df3, on='col_B') \\\n    .merge(df4, on='col_C')\n3. Merge across multiple columns tags\ndf1.merge( df2, on = ['col_A', 'col_B'])"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#searching",
    "href": "posts/2021-06-13-pandas_resources.html#searching",
    "title": "Pandas cookbook",
    "section": "Searching",
    "text": "Searching\nFind columns names based on a string\ndf_raw_data.columns[df_raw_data.columns.str.contains('STRING_SUBSET')]\nFind rows in column Model based on a string\nSelect all row entries that start with Mac\ndf[df['model'].str.match('Mac')]\nSelect all row entries that contain ac in it\ndf[df['model'].str.contains('ac')]\nFilter entries in the column based on the threshold * Data has indian-inspired international cuisines which are not what we are interested in\ncuisin_counts = food_df['Cuisine'].value_counts()\ncuisin_counts_more_than_50 = cuisin_counts.iloc[np.where(cuisin_counts > 50)]\nfood_df_top_cuisine = food_df.loc[ food_df['Cuisine'].isin(list(cuisin_counts_more_than_50.index))  ] \n#Dropping entries in `food_df` which have non-ind\nClean up entries with partial matches\ndf.loc[df['Store Name'].str.contains('Wal', case=False), 'Store_Group_1'] = 'Walmarts'\nsouth_indian_tag = ['Chettinad', 'Andhra', 'Karnataka', 'Tamil Nadu', 'Kerala Recipes', 'South Indian Recipes']\nfood_df_top_cuisine.loc[food_df_top_cuisine['Cuisine'].isin(south_indian_tag), 'Combined_cuisine'] = 'South Indian'\nWith or statements\nString_filter_option = ['cond_1', 'cond_2']\npandas_dataframe[ Pandas_dataframe[ 'columns' ].str.contains('|'.join(string_filter_option)) ] \nFilter rows in the pandas df with another list\nmonth_list = ['May','Jun','Jul','Aug','Sep']\ndf_pH.loc[df_pH['Month'].isin(month_list)]\nFilter out values using names: Making a separate list of those that DO NOT satisfy the constraint\nno_bands = halftime_musicians[ ~halftime_musicians.musician.str.contains('Marching') ]"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#statistics-distributions",
    "href": "posts/2021-06-13-pandas_resources.html#statistics-distributions",
    "title": "Pandas cookbook",
    "section": "Statistics & Distributions",
    "text": "Statistics & Distributions\nHistogram\ndf.hist('WTKG3')\nCDF and PDF\n# Functions for PMF and CDF, we will come to those later in the notebook \ndef pmf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n\n    return pmf \n\ndef cdf(pandas_series):\n    values, counts = np.unique(pandas_series, return_counts = True)\n    pmf = np.c_[ values, counts / sum(counts) ]\n    cdf = np.zeros(shape=pmf.shape) \n    \n    for i in range(0, pmf.shape[0]):\n        cdf[i] = [pmf[i][0], np.sum(pmf[:i+1], axis=0)[-1]] \n        \n    return cdf\nConfidence interval\nA bootstrap analysis of the reduction of deaths due to handwashing\nboot_mean_diff = []\nfor i in range(3000):\n    boot_before = before_proportion.sample(frac=1, replace=True)\n    boot_after = after_proportion.sample(frac=1, replace=True)\n    boot_mean_diff.append( boot_after.mean() - boot_before.mean() )\nCalculating a 95% confidence interval from boot_mean_diff\nconfidence_interval = pd.Series(boot_mean_diff).quantile([0.025,0.975])"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#convert-variables",
    "href": "posts/2021-06-13-pandas_resources.html#convert-variables",
    "title": "Pandas cookbook",
    "section": "Convert variables",
    "text": "Convert variables\nConvert continuous variable to discrete\npd.cut \nExample 1:\nhousing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf], #bins around 2-5 income bracket\n                               labels=[1, 2, 3, 4, 5])\nUse cut when you need to segment and sort data values into bins. This function is also useful for going from a continuous variable to a categorical variable. For example, cut could convert ages to groups of age ranges. Supports binning into an equal number of bins, or a pre-specified array of bins.\nExample 2:\npd.cut(iris_df['sepal_length'], bins=3, right=True, labels=['low','med','high'], retbins=True)\nFine tune the labeling\ndef convert_to_cat(panda_series):\n    first_quarter = panda_series.describe()['25%']\n    third_quarter = panda_series.describe()['75%']\n    print(first_quarter, third_quarter)\n    \n    cat_list = ['temp'] * len(panda_series) \n\n    for i, entry in enumerate(panda_series):\n        if entry <= first_quarter: \n            cat_list[i] = 'SMALL'\n        elif first_quarter < entry <= third_quarter:\n            cat_list[i] = 'MED'\n        else:\n            cat_list[i] = 'LARGE'\n    \n    return cat_list\nCateogorical variables to one-hot\n# Pandas get dummies is one option \npd.get_dummies(iris_df['sepal_width_cat'], prefix='sepal_width')\nOne-hot discrete variable with more granularity\ndef OHE_discreet(point, pandas_series, intervals):\n    '''\n    define range for one-hot, for every entry find the closest value in the one-hot\n    '''\n\n    z = np.linspace(min(pandas_series), max(pandas_series), intervals)\n    ohe = np.zeros(len(z))\n    ohe[np.argmin(abs(z - point)**2)] = 1\n    return ohe\n\niris_df['sepal_width_OHE'] = iris_df['sepal_width'].apply(OHE_discreet, args=(iris_df['sepal_width'], 11))"
  },
  {
    "objectID": "posts/2021-06-13-pandas_resources.html#grouping-data-by-entries-in-a-row",
    "href": "posts/2021-06-13-pandas_resources.html#grouping-data-by-entries-in-a-row",
    "title": "Pandas cookbook",
    "section": "Grouping data by entries in a row:",
    "text": "Grouping data by entries in a row:\nExample 1\nlicenses_zip_ward.groupby('alderman').agg({'income':'median'})\nEstimate the statistic of ‘income’ after grouping the dataframe by row entries in column ‘alderman’\nExample 2\ncounted_df = licenses_owners.groupby('title').agg({'account':'count'})\nI want to know the number of account each unique title entry has in the df. Here the column account was counted and the total entries were reported when the data frame was first grouped by entries in the title column.\nExample 3\nGroupby multiple columns and show the counts\n# Create a column that will store the month\ndata['month'] = data['date'].dt.month\n\n# Create a column that will store the year\ndata['year'] = data['date'].dt.year\n\n# Group by the month and year and count the pull requests\ncounts = data.groupby(['month','year'])['pid'].count()\nExample 4\nGroup and pivot table. Find the number of pull_request for the repo every year for the two authors:\n# The developers we are interested in\nauthors = ['xeno-by', 'soc']\n\n# Get all the developers' pull requests\nby_author = pulls.loc[ pulls['user'].isin(authors) ]\nby_author['year'] = by_author['date'].dt.year \n\n# Count the number of pull requests submitted each year\ncounts = by_author.groupby(['user', 'year']).agg({'pid': 'count'}).reset_index()\n\n# Convert the table to a wide format\ncounts_wide = counts.pivot_table(index='year', columns='user', values='pid', fill_value=0)\n\n# Plot the results\ncounts_wide"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html",
    "href": "posts/2021-02-03-tsnevsumap.html",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "",
    "text": "Recreating the dataset explored in the recent publication looking at the effect of random initializations and sub-methods in well-known dimensionality reduction techniques: Initialization is critical for preserving global data structure in both t-SNE and UMAP"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html#key-takeaways",
    "href": "posts/2021-02-03-tsnevsumap.html#key-takeaways",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "Key takeaways:",
    "text": "Key takeaways:\n\nUsing either t-SNE or UMAP over another is difficult to justify. There is no evidence per se that UMAP algorithm have any advantage over t-SNE in terms of preserving global structure.\nThese algorithms should be used cautiously and with informative initialization by default\nIn all embeddings, distances between clusters of points can be completely meaningless. It is often impossible to represent complex topologies in 2 dimensions, and embeddings should be approached with the utmost care when attempting to interpret their layout.\nThe only cerrtainty is the closeness of the points and their similarity\nThese methods don’t work that great if the intrinsic dimensionality of the data is higher than 2D\nHigh dimensional data sets typically have lower intrinsic dimensionality $ d << D $ however \\(d\\) may still be larger than 2 and preserving these distances faithfully might not always be possible.\nWhen using both UMAP or t-SNE, one must take care not to overinterpret the embedding structure or distances.\n\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\n\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nimport openTSNE, umap\nprint('openTSNE', openTSNE.__version__)\nprint('umap', umap.__version__)\n\nopenTSNE 0.6.0\numap 0.5.1\n\n\n\nfrom openTSNE import TSNE\nfrom umap import UMAP"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html#looking-at-2d-circle",
    "href": "posts/2021-02-03-tsnevsumap.html#looking-at-2d-circle",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "1. Looking at 2D circle",
    "text": "1. Looking at 2D circle\n\n#Generate circle\n\nn = 7000\nnp.random.seed(42)\nX = np.random.randn(n, 3) / 1000\nX[:,0] += np.cos(np.arange(n)*2*np.pi/n)\nX[:,1] += np.sin(np.arange(n)*2*np.pi/n)\n\nplt.plot(X[:,0], X[:,1]);\nplt.axis('equal');\n\n\n\n\n\n%%time\n\n# BH is faster for this sample size\nZ1 = TSNE(n_jobs=-1, initialization='random', random_state=42, negative_gradient_method='bh').fit(X)\nZ2 = TSNE(n_jobs=-1, negative_gradient_method='bh').fit(X)\n\nCPU times: user 48.3 s, sys: 760 ms, total: 49.1 s\nWall time: 40.8 s\n\n\n\n%%time\n\nZ3 = UMAP(init='random', random_state=42).fit_transform(X)\nZ4 = UMAP().fit_transform(X)\n\nCPU times: user 58.4 s, sys: 2.59 s, total: 1min\nWall time: 33.4 s\n\n\n\n%%time\nfrom sklearn import decomposition\npca_2D = decomposition.PCA(n_components=2)\npca_2D.fit(X)\nZ5 = pca_2D.transform(X)\n\nCPU times: user 6.17 ms, sys: 5.36 ms, total: 11.5 ms\nWall time: 5.72 ms\n\n\n\nfrom matplotlib.colors import ListedColormap\ncmap = ListedColormap(sns.husl_palette(n))\n\ntitles = ['Data', 't-SNE, random init', 't-SNE, PCA init', \n          'UMAP, random init', 'UMAP, LE init', 'PCA']\n\nplt.figure(figsize=(10,2))\n\nfor i,Z in enumerate([X,Z1,Z2,Z3,Z4,Z5],1):\n    plt.subplot(1,6,i)\n    plt.gca().set_aspect('equal', adjustable='datalim')\n    plt.scatter(Z[:,0], Z[:,1], s=1, c=np.arange(n), cmap=cmap, \n                edgecolor='none', rasterized=True)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(titles[i-1], fontsize=8)\n    \n#sns.despine(left=True, bottom=True)"
  },
  {
    "objectID": "posts/2021-02-03-tsnevsumap.html#looking-at-hand-written-digit-data",
    "href": "posts/2021-02-03-tsnevsumap.html#looking-at-hand-written-digit-data",
    "title": "t-SNE and UMAP - Effect of initialization on the dimensionality reduction",
    "section": "2. Looking at hand-written digit data",
    "text": "2. Looking at hand-written digit data\n\nfrom sklearn.datasets import load_digits\ndigits = load_digits()\n\n\ndigits.keys()\n\ndict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n\n\n\nX = digits.data\nY = digits.target\n\n\n%%time\n\n# BH is faster for this sample size\nZ1 = TSNE(n_jobs=-1, initialization='random', random_state=42, negative_gradient_method='bh').fit(X)\nZ2 = TSNE(n_jobs=-1, negative_gradient_method='bh').fit(X)\n\nCPU times: user 14.8 s, sys: 331 ms, total: 15.2 s\nWall time: 13.3 s\n\n\n\n%%time\n\nZ3 = UMAP(init='random', random_state=42).fit_transform(X)\nZ4 = UMAP().fit_transform(X)\n\nCPU times: user 17.7 s, sys: 311 ms, total: 18 s\nWall time: 12.5 s\n\n\n\n%%time\n\npca_2D = decomposition.PCA(n_components=2)\npca_2D.fit(X)\nZ5 = pca_2D.transform(X)\n\nCPU times: user 17.8 ms, sys: 16.7 ms, total: 34.5 ms\nWall time: 10.2 ms\n\n\n\nfrom matplotlib.colors import ListedColormap\ncmap = ListedColormap(sns.husl_palette(len(np.unique(Y))))\n\ntitles = ['Data', 't-SNE, random init', 't-SNE, PCA init', \n          'UMAP, random init', 'UMAP, LE init', 'PCA']\n\nfig, ax = plt.subplots(3,2, figsize=(15,15))\nax = ax.flatten()\n\nfor i,Z in enumerate([X,Z1,Z2,Z3,Z4,Z5],0):\n    im = ax[i].scatter(Z[:,0], Z[:,1], s=10, c=Y, cmap=cmap, edgecolor='none')\n    ax[i].set_xticks([])\n    ax[i].set_yticks([])\n    ax[i].set_title(titles[i], fontsize=15)\n    \nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.25, 0.01, 0.5], label='digit')\ncbar = fig.colorbar(im, cax=cbar_ax,label='Digit')"
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html",
    "href": "posts/2022-08-31-cheminfo_smirks.html",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "",
    "text": "The code and discussion in this notebook is inspired and borrowed from: * Efficient Bits\nThe Reaction SMARTS or SMIRKS way to query chemical reactions\nSMIRKS as per the Daylight definition are used to describe a transform (or reaction) to modify molecules. They are rules to make new molecules but also be used a ‘Reaction SMARTS’ to search for reactions smiles which match that transformation.\nRDKit treats these slightly differently - it has Reaction SMARTS which are used for substructure matching alone."
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html#set-up-the-reactants-and-reaction-definitions",
    "href": "posts/2022-08-31-cheminfo_smirks.html#set-up-the-reactants-and-reaction-definitions",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "Set up the reactants and reaction definitions",
    "text": "Set up the reactants and reaction definitions\n\nfrom rdkit.Chem import rdmolfiles as rdfiles\n\nlib_alcohols = rdfiles.SmilesMolSupplier('./molecule_enumerations/alcohol.smi') #Read input file with all reactants\nlib_alkynes = rdfiles.SmilesMolSupplier('./molecule_enumerations/alkynes.smi')\nreaction_library = pd.read_csv('./molecule_enumerations/rxn_definitions.txt', sep='\\t', index_col = 'ReactionName')\nreaction_library\n\n\n\n\n\n  \n    \n      \n      ReactionSMARTS\n    \n    \n      ReactionName\n      \n    \n  \n  \n    \n      Primary alc ox\n      [CH2:1][OD1] >> [C:1]=[OD1]\n    \n    \n      Amide coupling\n      [C:1](=[O:2])O.[N:3] >> [C:1](=[O:2])[N:3]\n    \n    \n      Diels-Alder\n      '[C:1]=[C:2]-[C:3]=[C:4].[C:5]=[C:6] >> [C:5]-...\n    \n    \n      4-Click\n      [N:1]=[N+1:2]=[N-1:3].[CH:4]#[C:5]>>[N:1]-1-[C..."
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html#single-molecule-reaction",
    "href": "posts/2022-08-31-cheminfo_smirks.html#single-molecule-reaction",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "Single molecule reaction",
    "text": "Single molecule reaction\n\ndef unimolecular(molecule, reaction_smirk):\n  rxn = AllChem.ReactionFromSmarts(reaction_smirk)\n  product = rxn.RunReactants([molecule,])\n  \n  final_smiles_list = []\n  try: \n    for i in range(len(product)):\n      final_smiles = Chem.MolToSmiles(product[i][0])\n      final_smiles_list.append(final_smiles)\n  except:\n    pass\n  return final_smiles_list\n\n\nDraw.MolsToGridImage(lib_alcohols)\n\n\n\n\n\nreaction_library.ReactionSMARTS['Primary alc ox']\n\n'[CH2:1][OD1] >> [C:1]=[OD1]'\n\n\n\nunimolecular(lib_alcohols[0], reaction_library.ReactionSMARTS['Primary alc ox'])\n\n['CC=O']\n\n\n\nproducts = []\nfor alcohol_mol in lib_alcohols:\n  prod = unimolecular(alcohol_mol, reaction_library.ReactionSMARTS['Primary alc ox'])\n  for mol in prod:\n    product = Chem.MolFromSmiles(mol)\n    products.append(product)\nalign_bundle_coords(products)\nDraw.MolsToGridImage(products)"
  },
  {
    "objectID": "posts/2022-08-31-cheminfo_smirks.html#reacting-two-compounds",
    "href": "posts/2022-08-31-cheminfo_smirks.html#reacting-two-compounds",
    "title": "Cheminformatics basics - Why the SMIRKS?",
    "section": "Reacting two compounds",
    "text": "Reacting two compounds\n\ndef bimolecular_rxn(mol1, mol2, reaction_smirk):\n  rxn = AllChem.ReactionFromSmarts(reaction_smirk)\n  product = rxn.RunReactants([mol1, mol2])\n  \n  final_smiles_list = []\n  try: \n    for i in range(len(product)):\n      final_smiles = Chem.MolToSmiles(product[i][0])\n      final_smiles_list.append(final_smiles)\n  except:\n    pass\n  return final_smiles_list\n\n\nreaction_smirks = reaction_library.ReactionSMARTS[\"4-Click\"] #Define the reaction type from the reaction library\nreaction_smirks\n\n'[N:1]=[N+1:2]=[N-1:3].[CH:4]#[C:5]>>[N:1]-1-[CH:4]=[C:5]-[N-0:3]=[N+0:2]-1'\n\n\n\nproduct_bimolecular = [] #List of enumerated molecules\nCore = Chem.MolFromSmiles('O[C@@H]1[C@@H](O)[C@H](OCC2=CC=CC=C2)[C@H](C[C@H]1N=[N+]=[N-])C([O-])=O') #Define the molecular core\nCore\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor i in lib_alkynes: #Read the .smi-file of reagents to be used for enumeration\n    resulting_smiles = bimolecular_rxn(Core, i, reaction_smirks)\n    \n    for i in resulting_smiles:\n        prod1 = Chem.MolFromSmiles(i)\n        product_bimolecular.append(prod1)\nalign_bundle_coords(product_bimolecular)\nDraw.MolsToGridImage(product_bimolecular)"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html",
    "href": "posts/2020-08-01-sp_500.html",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "",
    "text": "To extract stock information we will use yfinance module which is a convenient way to download data from Yahoo Finance. The official API for Yahoo Finance was decommissioned some time back. More details about this module can be found here.\n\nfrom requests import get \nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport time as time \nfrom tqdm import tqdm\nimport yfinance as yf\n\nfrom IPython.core.display import clear_output\n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nsns.color_palette(\"husl\")\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 30,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html#generate-list-of-sp-500-companies",
    "href": "posts/2020-08-01-sp_500.html#generate-list-of-sp-500-companies",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "1. Generate list of S&P 500 companies",
    "text": "1. Generate list of S&P 500 companies\n\nParse wikipedia to generate a list\n\nwiki_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\nresponse = get(wiki_url)\nhtml_soup = BeautifulSoup(response.text, 'html.parser')\ntab = html_soup.find(\"table\",{\"class\":\"wikitable sortable\"})\n\n\ncolumn_headings = [entry.text.strip() for entry in tab.findAll('th')]\nprint(column_headings)\n\n['Symbol', 'Security', 'SEC filings', 'GICS Sector', 'GICS Sub-Industry', 'Headquarters Location', 'Date first added', 'CIK', 'Founded']\n\n\n\nSP_500_dict = {keys:[] for keys in column_headings}\n\n\nfor i, name in enumerate(SP_500_dict.keys()):\n    print(i, name)\n\n0 Symbol\n1 Security\n2 SEC filings\n3 GICS Sector\n4 GICS Sub-Industry\n5 Headquarters Location\n6 Date first added\n7 CIK\n8 Founded\n\n\n\n\nPopulate each row entry as per company data\n\nfor row_entry in tab.findAll('tr')[1:]:\n    row_elements = row_entry.findAll('td')\n    for key, _elements in zip(SP_500_dict.keys(), row_elements):\n        SP_500_dict[key].append(_elements.text.strip())\n\n\nSP_500_df = pd.DataFrame(SP_500_dict, columns=SP_500_dict.keys())\n\n\nSP_500_df\n\n\n\n\n\n  \n    \n      \n      Symbol\n      Security\n      SEC filings\n      GICS Sector\n      GICS Sub-Industry\n      Headquarters Location\n      Date first added\n      CIK\n      Founded\n    \n  \n  \n    \n      0\n      MMM\n      3M Company\n      reports\n      Industrials\n      Industrial Conglomerates\n      St. Paul, Minnesota\n      1976-08-09\n      0000066740\n      1902\n    \n    \n      1\n      ABT\n      Abbott Laboratories\n      reports\n      Health Care\n      Health Care Equipment\n      North Chicago, Illinois\n      1964-03-31\n      0000001800\n      1888\n    \n    \n      2\n      ABBV\n      AbbVie Inc.\n      reports\n      Health Care\n      Pharmaceuticals\n      North Chicago, Illinois\n      2012-12-31\n      0001551152\n      2013 (1888)\n    \n    \n      3\n      ABMD\n      Abiomed\n      reports\n      Health Care\n      Health Care Equipment\n      Danvers, Massachusetts\n      2018-05-31\n      0000815094\n      1981\n    \n    \n      4\n      ACN\n      Accenture\n      reports\n      Information Technology\n      IT Consulting & Other Services\n      Dublin, Ireland\n      2011-07-06\n      0001467373\n      1989\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      500\n      YUM\n      Yum! Brands Inc\n      reports\n      Consumer Discretionary\n      Restaurants\n      Louisville, Kentucky\n      1997-10-06\n      0001041061\n      1997\n    \n    \n      501\n      ZBRA\n      Zebra Technologies\n      reports\n      Information Technology\n      Electronic Equipment & Instruments\n      Lincolnshire, Illinois\n      2019-12-23\n      0000877212\n      1969\n    \n    \n      502\n      ZBH\n      Zimmer Biomet\n      reports\n      Health Care\n      Health Care Equipment\n      Warsaw, Indiana\n      2001-08-07\n      0001136869\n      1927\n    \n    \n      503\n      ZION\n      Zions Bancorp\n      reports\n      Financials\n      Regional Banks\n      Salt Lake City, Utah\n      2001-06-22\n      0000109380\n      1873\n    \n    \n      504\n      ZTS\n      Zoetis\n      reports\n      Health Care\n      Pharmaceuticals\n      Parsippany, New Jersey\n      2013-06-21\n      0001555280\n      1952\n    \n  \n\n505 rows × 9 columns\n\n\n\n\nSP_500_df['GICS Sector'].value_counts()\n\nInformation Technology    75\nIndustrials               74\nFinancials                65\nConsumer Discretionary    63\nHealth Care               62\nConsumer Staples          32\nReal Estate               29\nMaterials                 28\nUtilities                 28\nCommunication Services    26\nEnergy                    23\nName: GICS Sector, dtype: int64\n\n\n\n\nVisualize distribution of the companies as per sectors\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nSP_500_df['GICS Sector'].value_counts().plot.pie(y='GICS Sector', autopct='%1.1f%%', fontsize=20, ax = ax, colormap='tab20')\nplt.axis('off')\n\n(-1.25, 1.25, -1.25, 1.25)\n\n\n\n\n\n\nSP_500_df.loc[ SP_500_df['GICS Sector'] == 'Energy']\n\n\n\n\n\n  \n    \n      \n      Symbol\n      Security\n      SEC filings\n      GICS Sector\n      GICS Sub-Industry\n      Headquarters Location\n      Date first added\n      CIK\n      Founded\n    \n  \n  \n    \n      44\n      APA\n      APA Corporation\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Houston, Texas\n      1997-07-28\n      0000006769\n      1954\n    \n    \n      59\n      BKR\n      Baker Hughes Co\n      reports\n      Energy\n      Oil & Gas Equipment & Services\n      Houston, Texas\n      2017-07-07\n      0001701605\n      2017\n    \n    \n      80\n      COG\n      Cabot Oil & Gas\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Houston, Texas\n      2008-06-23\n      0000858470\n      1989\n    \n    \n      101\n      CVX\n      Chevron Corp.\n      reports\n      Energy\n      Integrated Oil & Gas\n      San Ramon, California\n      1957-03-04\n      0000093410\n      1879\n    \n    \n      121\n      COP\n      ConocoPhillips\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Houston, Texas\n      1957-03-04\n      0001163165\n      2002\n    \n    \n      140\n      DVN\n      Devon Energy\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Oklahoma City, Oklahoma\n      2000-08-30\n      0001090012\n      1971\n    \n    \n      142\n      FANG\n      Diamondback Energy\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Midland, Texas\n      2018-12-03\n      0001539838\n      2007\n    \n    \n      169\n      EOG\n      EOG Resources\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Houston, Texas\n      2000-11-02\n      0000821189\n      1999\n    \n    \n      183\n      XOM\n      Exxon Mobil Corp.\n      reports\n      Energy\n      Integrated Oil & Gas\n      Irving, Texas\n      1957-03-04\n      0000034088\n      1999\n    \n    \n      219\n      HAL\n      Halliburton Co.\n      reports\n      Energy\n      Oil & Gas Equipment & Services\n      Houston, Texas\n      1957-03-04\n      0000045012\n      1919\n    \n    \n      227\n      HES\n      Hess Corporation\n      reports\n      Energy\n      Integrated Oil & Gas\n      New York, New York\n      1984-05-31\n      0000004447\n      1919\n    \n    \n      230\n      HFC\n      HollyFrontier Corp\n      reports\n      Energy\n      Oil & Gas Refining & Marketing\n      Dallas, Texas\n      2018-06-18\n      0000048039\n      1947\n    \n    \n      274\n      KMI\n      Kinder Morgan\n      reports\n      Energy\n      Oil & Gas Storage & Transportation\n      Houston, Texas\n      2012-05-25\n      0001506307\n      1997\n    \n    \n      298\n      MRO\n      Marathon Oil Corp.\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Houston, Texas\n      1991-05-01\n      0000101778\n      1887\n    \n    \n      299\n      MPC\n      Marathon Petroleum\n      reports\n      Energy\n      Oil & Gas Refining & Marketing\n      Findlay, Ohio\n      2011-07-01\n      0001510295\n      2009 (1887)\n    \n    \n      345\n      NOV\n      NOV Inc.\n      reports\n      Energy\n      Oil & Gas Equipment & Services\n      Houston, Texas\n      2005-03-14\n      0001021860\n      1841\n    \n    \n      352\n      OXY\n      Occidental Petroleum\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Houston, Texas\n      1982-12-31\n      0000797468\n      1920\n    \n    \n      355\n      OKE\n      Oneok\n      reports\n      Energy\n      Oil & Gas Storage & Transportation\n      Tulsa, Oklahoma\n      2010-03-15\n      0001039684\n      1906\n    \n    \n      372\n      PSX\n      Phillips 66\n      reports\n      Energy\n      Oil & Gas Refining & Marketing\n      Houston, Texas\n      2012-05-01\n      0001534701\n      2012 (1917)\n    \n    \n      374\n      PXD\n      Pioneer Natural Resources\n      reports\n      Energy\n      Oil & Gas Exploration & Production\n      Irving, Texas\n      2008-09-24\n      0001038357\n      1997\n    \n    \n      411\n      SLB\n      Schlumberger Ltd.\n      reports\n      Energy\n      Oil & Gas Equipment & Services\n      Curaçao, Kingdom of the Netherlands\n      1965-03-31\n      0000087347\n      1926\n    \n    \n      466\n      VLO\n      Valero Energy\n      reports\n      Energy\n      Oil & Gas Refining & Marketing\n      San Antonio, Texas\n      \n      0001035002\n      1980\n    \n    \n      494\n      WMB\n      Williams Companies\n      reports\n      Energy\n      Oil & Gas Storage & Transportation\n      Tulsa, Oklahoma\n      1975-03-31\n      0000107263\n      1908\n    \n  \n\n\n\n\nWe can parse these tables and search companies based on the sector\n\nSP_500_df.loc[ SP_500_df['GICS Sector'] == 'Information Technology']\n\n\n\n\n\n  \n    \n      \n      Symbol\n      Security\n      SEC filings\n      GICS Sector\n      GICS Sub-Industry\n      Headquarters Location\n      Date first added\n      CIK\n      Founded\n    \n  \n  \n    \n      4\n      ACN\n      Accenture\n      reports\n      Information Technology\n      IT Consulting & Other Services\n      Dublin, Ireland\n      2011-07-06\n      0001467373\n      1989\n    \n    \n      6\n      ADBE\n      Adobe Inc.\n      reports\n      Information Technology\n      Application Software\n      San Jose, California\n      1997-05-05\n      0000796343\n      1982\n    \n    \n      7\n      AMD\n      Advanced Micro Devices\n      reports\n      Information Technology\n      Semiconductors\n      Santa Clara, California\n      2017-03-20\n      0000002488\n      1969\n    \n    \n      13\n      AKAM\n      Akamai Technologies\n      reports\n      Information Technology\n      Internet Services & Infrastructure\n      Cambridge, Massachusetts\n      2007-07-12\n      0001086222\n      1998\n    \n    \n      38\n      APH\n      Amphenol Corp\n      reports\n      Information Technology\n      Electronic Components\n      Wallingford, Connecticut\n      2008-09-30\n      0000820313\n      1932\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      475\n      V\n      Visa Inc.\n      reports\n      Information Technology\n      Data Processing & Outsourced Services\n      San Francisco, California\n      2009-12-21\n      0001403161\n      1958\n    \n    \n      489\n      WDC\n      Western Digital\n      reports\n      Information Technology\n      Technology Hardware, Storage & Peripherals\n      San Jose, California\n      2009-07-01\n      0000106040\n      1970\n    \n    \n      490\n      WU\n      Western Union Co\n      reports\n      Information Technology\n      Data Processing & Outsourced Services\n      Englewood, Colorado\n      2006-09-29\n      0001365135\n      1851\n    \n    \n      498\n      XLNX\n      Xilinx\n      reports\n      Information Technology\n      Semiconductors\n      San Jose, California\n      1999-11-08\n      0000743988\n      1984\n    \n    \n      501\n      ZBRA\n      Zebra Technologies\n      reports\n      Information Technology\n      Electronic Equipment & Instruments\n      Lincolnshire, Illinois\n      2019-12-23\n      0000877212\n      1969\n    \n  \n\n75 rows × 9 columns"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html#get-total-number-of-shares",
    "href": "posts/2020-08-01-sp_500.html#get-total-number-of-shares",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "Get total number of Shares",
    "text": "Get total number of Shares\nWe will use yfinance to extact Tickr information for each SP500 company and use pandas datareader\nyf_tickr = yf.Ticker('ADBE')\nyf_tickr.info['sharesOutstanding'] #info has good summary info for the stock \n\nimport yfinance as yf\n\n\nSTART_DATE = \"2020-01-01\"\nEND_DATE = \"2020-07-26\"\n\n\nyf_tickr = yf.Ticker('TSLA')\n\n\n_shares_outstanding = yf_tickr.info['sharesOutstanding']\n_previous_close = yf_tickr.info['previousClose']\nprint('Outstanding shares: {}'.format(_shares_outstanding))\nprint('Market Cap: {} Million USD'.format((_shares_outstanding * _previous_close)/10**6))\n\nOutstanding shares: 959854016\nMarket Cap: 676447.51923584 Million USD\n\n\n\ndf_tckr = yf_tickr.history(start=START_DATE, end=END_DATE, interval=\"1wk\", actions=False)\ndf_tckr['Market_Cap'] = df_tckr['Open'] * _shares_outstanding\ndf_tckr['YTD'] = (df_tckr['Open'] - df_tckr['Open'][0]) * 100 / df_tckr['Open'][0]\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,8))\ndf_tckr.plot(use_index=True, y=\"YTD\",ax=ax, linewidth=4, grid=False, label='TSLA')\nax.set_xlabel('Date')\nax.set_ylabel('% YTD change (Weekly basis)')\n\nText(0, 0.5, '% YTD change (Weekly basis)')\n\n\n\n\n\n\nExtend this to plotting for multiple companies\n\nimport time as time \ndef plot_market_cap(tickr_list, START_DATE, END_DATE):\n    \n    total_data = {}\n    for tickr in tickr_list:\n        total_data[tickr] = {}\n        print('Looking at: {}'.format(tickr))\n        yf_tickr = yf.Ticker(tickr)\n        #try:\n        #    _shares_outstanding = yf_tickr.info['sharesOutstanding']\n        #except(IndexError):\n        #    print('Shares outstanding not found')\n        #    _shares_outstanding = None\n        \n        df_tckr = yf_tickr.history(start=START_DATE, end=END_DATE, actions=False)\n        df_tckr['YTD'] = (df_tckr['Open'] - df_tckr['Open'][0]) * 100 / df_tckr['Open'][0]\n            \n        total_data[tickr]['hist'] = df_tckr\n        #total_data[tickr]['shares'] = _shares_outstanding\n        time.sleep(np.random.randint(10))\n        \n    return total_data\n\n\ntickr_list = ['AAPL', 'TSLA','FB','DAL','XOM']\ndata = plot_market_cap(tickr_list, START_DATE, END_DATE)\n\nLooking at: AAPL\nLooking at: TSLA\nLooking at: FB\nLooking at: DAL\nLooking at: XOM\n\n\n\ncompany_name = [SP_500_df[SP_500_df['Symbol'].str.contains(i)]['Security'].values[0] for i in tickr_list]\n\n\ncompany_name\n\n['Apple Inc.',\n 'Tesla, Inc.',\n 'Facebook, Inc.',\n 'Delta Air Lines Inc.',\n 'Exxon Mobil Corp.']\n\n\n\nprint(len(data['AAPL']['hist']['YTD']))\n\n142\n\n\n\nytd_stat = pd.DataFrame()\nfor tickr in tickr_list: \n    ytd_stat[tickr] = data[tickr]['hist']['YTD'].values\nytd_stat['Date'] = data['AAPL']['hist'].index\n\n\nytd_stat\n\n\n\n\n\n  \n    \n      \n      AAPL\n      TSLA\n      FB\n      DAL\n      XOM\n      Date\n    \n  \n  \n    \n      0\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      2020-01-02\n    \n    \n      1\n      0.307187\n      3.769137\n      0.222494\n      -2.426609\n      1.566061\n      2020-01-03\n    \n    \n      2\n      -0.827016\n      3.762073\n      -0.024185\n      -3.292044\n      0.113891\n      2020-01-06\n    \n    \n      3\n      1.215244\n      8.692576\n      2.935916\n      -1.730873\n      0.370157\n      2020-01-07\n    \n    \n      4\n      0.310568\n      11.590101\n      3.022975\n      -2.002382\n      -0.185078\n      2020-01-08\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      137\n      30.850611\n      257.835096\n      16.111244\n      -53.866312\n      -36.389268\n      2020-07-20\n    \n    \n      138\n      34.589490\n      286.320361\n      19.090690\n      -54.720640\n      -36.477584\n      2020-07-21\n    \n    \n      139\n      31.223803\n      276.678424\n      16.207978\n      -55.181977\n      -35.005460\n      2020-07-22\n    \n    \n      140\n      31.637726\n      295.512370\n      15.903267\n      -55.574967\n      -36.109559\n      2020-07-23\n    \n    \n      141\n      23.481414\n      233.571249\n      11.337365\n      -54.754814\n      -35.402933\n      2020-07-24\n    \n  \n\n142 rows × 6 columns"
  },
  {
    "objectID": "posts/2020-08-01-sp_500.html#final-plot-for-returns",
    "href": "posts/2020-08-01-sp_500.html#final-plot-for-returns",
    "title": "S&P 500 analysis using beautifulsoup and pandas",
    "section": "Final plot for returns",
    "text": "Final plot for returns\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\nfor i, tickr in enumerate(tickr_list):\n    ax.plot(ytd_stat['Date'], ytd_stat[tickr], linewidth=5.0, label=company_name[i])\nax.set_ylabel('YTD %Return 2020')\nax.set_xlabel('Date')\nax.legend()\n\n<matplotlib.legend.Legend at 0x7f9c0a4365e0>"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html",
    "href": "posts/2021-04-28-material_prop_walkthrough.html",
    "title": "Mateiral informatics sample project",
    "section": "",
    "text": "A random forest regression model is built to predict the heat capacity (\\(C_p\\)) of solid inorganic materials at different temperatures. The dataset is collected from the NIST JANAF Thermochemical Table\nThis project is adapted from recent publication looking at best practices for setting up mateial informatics task. * A. Y. T. Wang et al., “Machine Learning for Materials Scientists: An Introductory Guide toward Best Practices,” Chem. Mater., vol. 32, no. 12, pp. 4954–4965, 2020."
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#featurization",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#featurization",
    "title": "Mateiral informatics sample project",
    "section": "Featurization",
    "text": "Featurization\nComposition-based feature vector (CBFV) is used to describe each mateiral entry (eg: Cr2O3) with set of elemental and composition based numbers.\n\n# Import the package and the generate_features function\nfrom cbfv.composition import generate_features\n\n\nrename_columns = {'Cp':'target'}\ntrain_points['Type'] = 'Train'\nval_points['Type'] = 'Val'\ntest_points['Type'] = 'Test'\ntotal_data = pd.concat([train_points, val_points, test_points], ignore_index=True);\n\ntotal_data = total_data.rename(columns=rename_columns)\n\n/Users/pghaneka/miniconda3/envs/torch_38/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/Users/pghaneka/miniconda3/envs/torch_38/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/Users/pghaneka/miniconda3/envs/torch_38/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  after removing the cwd from sys.path.\n\n\n\ntotal_data.sample(5)\n\n\n\n\n\n  \n    \n      \n      formula\n      T\n      target\n      Type\n    \n  \n  \n    \n      3833\n      I1K1\n      1400.0\n      74.601\n      Val\n    \n    \n      4215\n      Cr2O3\n      298.0\n      120.366\n      Test\n    \n    \n      1290\n      I2Mo1\n      1000.0\n      91.458\n      Train\n    \n    \n      1578\n      I2Zr1\n      700.0\n      97.445\n      Train\n    \n    \n      2379\n      Na2O5Si2\n      1700.0\n      292.880\n      Train\n    \n  \n\n\n\n\n\ntrain_df = total_data.loc[ total_data['Type'] == 'Train' ].drop(columns=['Type']).reset_index(drop=True)\nval_df = total_data.loc[ total_data['Type'] == 'Val' ].drop(columns=['Type']).reset_index(drop=True)\ntest_df = total_data.loc[ total_data['Type'] == 'Test' ].drop(columns=['Type']).reset_index(drop=True)\n\n\nSub-sampling\nOnly some points from the original training data train_df are used to ensure the analysis is tractable\n\ntrain_df.shape\n\n(3131, 3)\n\n\n\ntrain_df = train_df.sample(n=1000, random_state=42)\ntrain_df.shape\n\n(1000, 3)\n\n\n\n# Generate features \nX_unscaled_train, y_train, formulae_entry_train, skipped_entry = generate_features(train_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\nX_unscaled_val, y_val, formulae_entry_val, skipped_entry = generate_features(val_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\nX_unscaled_test, y_test, formulae_entry_test, skipped_entry = generate_features(test_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n\nProcessing Input Data: 100%|██████████| 1000/1000 [00:00<00:00, 26074.09it/s]\nAssigning Features...:   0%|          | 0/1000 [00:00<?, ?it/s]\n\n\n    Featurizing Compositions...\n\n\nAssigning Features...: 100%|██████████| 1000/1000 [00:00<00:00, 13526.13it/s]\n\n\n    Creating Pandas Objects...\n\n\n\nProcessing Input Data: 100%|██████████| 944/944 [00:00<00:00, 28169.72it/s]\nAssigning Features...:   0%|          | 0/944 [00:00<?, ?it/s]\n\n\n    Featurizing Compositions...\n\n\nAssigning Features...: 100%|██████████| 944/944 [00:00<00:00, 14855.23it/s]\n\n\n    Creating Pandas Objects...\n\n\nProcessing Input Data: 100%|██████████| 489/489 [00:00<00:00, 25491.43it/s]\nAssigning Features...: 100%|██████████| 489/489 [00:00<00:00, 12626.83it/s]\n\n\n    Featurizing Compositions...\n    Creating Pandas Objects...\n\n\n\nX_unscaled_train.head(5)\n\n\n\n\n\n  \n    \n      \n      sum_Atomic_Number\n      sum_Atomic_Weight\n      sum_Period\n      sum_group\n      sum_families\n      sum_Metal\n      sum_Nonmetal\n      sum_Metalliod\n      sum_Mendeleev_Number\n      sum_l_quantum_number\n      ...\n      range_Melting_point_(K)\n      range_Boiling_Point_(K)\n      range_Density_(g/mL)\n      range_specific_heat_(J/g_K)_\n      range_heat_of_fusion_(kJ/mol)_\n      range_heat_of_vaporization_(kJ/mol)_\n      range_thermal_conductivity_(W/(m_K))_\n      range_heat_atomization(kJ/mol)\n      range_Cohesive_energy\n      T\n    \n  \n  \n    \n      0\n      64.0\n      139.938350\n      10.5\n      50.0\n      23.25\n      1.0\n      2.75\n      0.0\n      289.25\n      4.75\n      ...\n      2009873.29\n      5.748006e+06\n      26.002708\n      0.112225\n      252.450947\n      88384.346755\n      4759.155119\n      41820.25\n      4.410000\n      1100.0\n    \n    \n      1\n      58.0\n      119.979000\n      10.0\n      40.0\n      18.00\n      1.0\n      2.00\n      0.0\n      231.00\n      4.00\n      ...\n      505663.21\n      1.328602e+06\n      8.381025\n      0.018225\n      36.496702\n      28866.010000\n      1597.241190\n      4830.25\n      0.511225\n      1100.0\n    \n    \n      2\n      27.0\n      58.691000\n      6.0\n      17.0\n      10.00\n      1.0\n      0.00\n      1.0\n      115.00\n      3.00\n      ...\n      43890.25\n      1.277526e+05\n      1.210000\n      0.062500\n      301.890625\n      1179.922500\n      6.502500\n      2652.25\n      0.230400\n      3400.0\n    \n    \n      3\n      36.0\n      72.144000\n      7.0\n      18.0\n      9.00\n      1.0\n      1.00\n      0.0\n      95.00\n      1.00\n      ...\n      131841.61\n      2.700361e+05\n      0.067600\n      0.001600\n      11.636627\n      5148.062500\n      9973.118090\n      2550.25\n      0.255025\n      2900.0\n    \n    \n      4\n      80.0\n      162.954986\n      19.0\n      120.0\n      56.00\n      0.0\n      8.00\n      0.0\n      659.00\n      8.00\n      ...\n      16129.00\n      5.659641e+04\n      0.826963\n      0.018225\n      0.021993\n      21.791158\n      0.010922\n      6241.00\n      0.555025\n      1300.0\n    \n  \n\n5 rows × 177 columns\n\n\n\n\nformulae_entry_train.head(5)\n\n0    Mo1O2.750\n1        Fe1S2\n2        B1Ti1\n3        Ca1S1\n4         N5P3\nName: formula, dtype: object\n\n\n\nX_unscaled_train.shape\n\n(1000, 177)"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#feature-scaling",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#feature-scaling",
    "title": "Mateiral informatics sample project",
    "section": "Feature scaling",
    "text": "Feature scaling\n\nX_unscaled_train.columns\n\nIndex(['sum_Atomic_Number', 'sum_Atomic_Weight', 'sum_Period', 'sum_group',\n       'sum_families', 'sum_Metal', 'sum_Nonmetal', 'sum_Metalliod',\n       'sum_Mendeleev_Number', 'sum_l_quantum_number',\n       ...\n       'range_Melting_point_(K)', 'range_Boiling_Point_(K)',\n       'range_Density_(g/mL)', 'range_specific_heat_(J/g_K)_',\n       'range_heat_of_fusion_(kJ/mol)_',\n       'range_heat_of_vaporization_(kJ/mol)_',\n       'range_thermal_conductivity_(W/(m_K))_',\n       'range_heat_atomization(kJ/mol)', 'range_Cohesive_energy', 'T'],\n      dtype='object', length=177)\n\n\n\nX_unscaled_train.describe().round(2)\n\n\n\n\n\n  \n    \n      \n      sum_Atomic_Number\n      sum_Atomic_Weight\n      sum_Period\n      sum_group\n      sum_families\n      sum_Metal\n      sum_Nonmetal\n      sum_Metalliod\n      sum_Mendeleev_Number\n      sum_l_quantum_number\n      ...\n      range_Melting_point_(K)\n      range_Boiling_Point_(K)\n      range_Density_(g/mL)\n      range_specific_heat_(J/g_K)_\n      range_heat_of_fusion_(kJ/mol)_\n      range_heat_of_vaporization_(kJ/mol)_\n      range_thermal_conductivity_(W/(m_K))_\n      range_heat_atomization(kJ/mol)\n      range_Cohesive_energy\n      T\n    \n  \n  \n    \n      count\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      ...\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n    \n    \n      mean\n      66.57\n      147.21\n      11.28\n      46.27\n      23.19\n      1.28\n      2.64\n      0.08\n      292.01\n      3.73\n      ...\n      579042.62\n      1803422.99\n      8.45\n      3.34\n      181.31\n      28201.58\n      3305.55\n      14959.38\n      1.70\n      1195.38\n    \n    \n      std\n      48.94\n      116.53\n      6.33\n      36.29\n      16.68\n      0.76\n      2.32\n      0.31\n      210.15\n      2.59\n      ...\n      750702.41\n      2017584.79\n      17.52\n      10.61\n      413.13\n      36421.94\n      4474.33\n      22191.74\n      2.45\n      760.90\n    \n    \n      min\n      4.00\n      7.95\n      2.00\n      1.00\n      1.00\n      0.00\n      0.00\n      0.00\n      3.00\n      0.00\n      ...\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n    \n    \n      25%\n      31.00\n      65.12\n      6.00\n      18.00\n      10.00\n      1.00\n      1.00\n      0.00\n      126.00\n      2.00\n      ...\n      20619.03\n      199191.78\n      0.23\n      0.01\n      1.88\n      1451.91\n      119.61\n      729.00\n      0.09\n      600.00\n    \n    \n      50%\n      55.00\n      118.00\n      10.00\n      36.00\n      20.00\n      1.00\n      2.00\n      0.00\n      247.00\n      3.00\n      ...\n      222030.88\n      1169819.78\n      1.25\n      0.05\n      20.92\n      18260.29\n      1607.65\n      5312.67\n      0.63\n      1054.00\n    \n    \n      75%\n      86.00\n      182.15\n      15.00\n      72.00\n      36.00\n      2.00\n      4.00\n      0.00\n      442.00\n      5.00\n      ...\n      882096.64\n      3010225.00\n      9.33\n      0.12\n      171.31\n      40317.25\n      4968.28\n      18080.67\n      2.08\n      1600.00\n    \n    \n      max\n      278.00\n      685.60\n      41.00\n      256.00\n      113.00\n      4.00\n      15.00\n      2.00\n      1418.00\n      19.00\n      ...\n      3291321.64\n      8535162.25\n      93.11\n      44.12\n      2391.45\n      168342.03\n      40198.47\n      95733.56\n      10.59\n      4600.00\n    \n  \n\n8 rows × 177 columns\n\n\n\n\nX_unscaled_train['range_heat_of_vaporization_(kJ/mol)_'].hist();\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler, normalize\n\n\nstdscaler = StandardScaler()\nX_train = stdscaler.fit_transform(X_unscaled_train)\nX_val = stdscaler.transform(X_unscaled_val)\nX_test = stdscaler.transform(X_unscaled_test)\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns).describe().round(2)\n\n\n\n\n\n  \n    \n      \n      sum_Atomic_Number\n      sum_Atomic_Weight\n      sum_Period\n      sum_group\n      sum_families\n      sum_Metal\n      sum_Nonmetal\n      sum_Metalliod\n      sum_Mendeleev_Number\n      sum_l_quantum_number\n      ...\n      range_Melting_point_(K)\n      range_Boiling_Point_(K)\n      range_Density_(g/mL)\n      range_specific_heat_(J/g_K)_\n      range_heat_of_fusion_(kJ/mol)_\n      range_heat_of_vaporization_(kJ/mol)_\n      range_thermal_conductivity_(W/(m_K))_\n      range_heat_atomization(kJ/mol)\n      range_Cohesive_energy\n      T\n    \n  \n  \n    \n      count\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      ...\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n    \n    \n      mean\n      -0.00\n      -0.00\n      -0.00\n      0.00\n      -0.00\n      -0.00\n      -0.00\n      -0.00\n      -0.00\n      -0.00\n      ...\n      0.00\n      0.00\n      -0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      -0.00\n    \n    \n      std\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      ...\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n      1.00\n    \n    \n      min\n      -1.28\n      -1.20\n      -1.47\n      -1.25\n      -1.33\n      -1.68\n      -1.14\n      -0.27\n      -1.38\n      -1.44\n      ...\n      -0.77\n      -0.89\n      -0.48\n      -0.31\n      -0.44\n      -0.77\n      -0.74\n      -0.67\n      -0.69\n      -1.57\n    \n    \n      25%\n      -0.73\n      -0.70\n      -0.83\n      -0.78\n      -0.79\n      -0.36\n      -0.71\n      -0.27\n      -0.79\n      -0.67\n      ...\n      -0.74\n      -0.80\n      -0.47\n      -0.31\n      -0.43\n      -0.73\n      -0.71\n      -0.64\n      -0.66\n      -0.78\n    \n    \n      50%\n      -0.24\n      -0.25\n      -0.20\n      -0.28\n      -0.19\n      -0.36\n      -0.27\n      -0.27\n      -0.21\n      -0.28\n      ...\n      -0.48\n      -0.31\n      -0.41\n      -0.31\n      -0.39\n      -0.27\n      -0.38\n      -0.43\n      -0.43\n      -0.19\n    \n    \n      75%\n      0.40\n      0.30\n      0.59\n      0.71\n      0.77\n      0.96\n      0.59\n      -0.27\n      0.71\n      0.49\n      ...\n      0.40\n      0.60\n      0.05\n      -0.30\n      -0.02\n      0.33\n      0.37\n      0.14\n      0.15\n      0.53\n    \n    \n      max\n      4.32\n      4.62\n      4.69\n      5.78\n      5.39\n      3.59\n      5.34\n      6.18\n      5.36\n      5.89\n      ...\n      3.61\n      3.34\n      4.83\n      3.84\n      5.35\n      3.85\n      8.25\n      3.64\n      3.62\n      4.48\n    \n  \n\n8 rows × 177 columns\n\n\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns)['range_heat_of_vaporization_(kJ/mol)_'].hist()\n\n<AxesSubplot:>\n\n\n\n\n\n\nX_train = normalize(X_train)\nX_val = normalize(X_val)\nX_test = normalize(X_test)\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns).describe().round(2)\n\n\n\n\n\n  \n    \n      \n      sum_Atomic_Number\n      sum_Atomic_Weight\n      sum_Period\n      sum_group\n      sum_families\n      sum_Metal\n      sum_Nonmetal\n      sum_Metalliod\n      sum_Mendeleev_Number\n      sum_l_quantum_number\n      ...\n      range_Melting_point_(K)\n      range_Boiling_Point_(K)\n      range_Density_(g/mL)\n      range_specific_heat_(J/g_K)_\n      range_heat_of_fusion_(kJ/mol)_\n      range_heat_of_vaporization_(kJ/mol)_\n      range_thermal_conductivity_(W/(m_K))_\n      range_heat_atomization(kJ/mol)\n      range_Cohesive_energy\n      T\n    \n  \n  \n    \n      count\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      ...\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n      1000.00\n    \n    \n      mean\n      -0.01\n      -0.01\n      -0.00\n      -0.00\n      -0.00\n      0.00\n      -0.00\n      -0.01\n      -0.00\n      0.00\n      ...\n      0.00\n      0.01\n      -0.00\n      -0.01\n      -0.00\n      0.01\n      0.00\n      -0.00\n      -0.00\n      0.00\n    \n    \n      std\n      0.07\n      0.07\n      0.07\n      0.07\n      0.07\n      0.08\n      0.07\n      0.07\n      0.07\n      0.08\n      ...\n      0.08\n      0.08\n      0.07\n      0.07\n      0.07\n      0.08\n      0.09\n      0.08\n      0.08\n      0.09\n    \n    \n      min\n      -0.12\n      -0.11\n      -0.13\n      -0.11\n      -0.11\n      -0.12\n      -0.11\n      -0.04\n      -0.12\n      -0.13\n      ...\n      -0.08\n      -0.10\n      -0.06\n      -0.05\n      -0.05\n      -0.08\n      -0.12\n      -0.09\n      -0.09\n      -0.19\n    \n    \n      25%\n      -0.06\n      -0.06\n      -0.06\n      -0.06\n      -0.06\n      -0.04\n      -0.06\n      -0.03\n      -0.06\n      -0.05\n      ...\n      -0.05\n      -0.05\n      -0.03\n      -0.03\n      -0.04\n      -0.05\n      -0.05\n      -0.05\n      -0.05\n      -0.06\n    \n    \n      50%\n      -0.02\n      -0.03\n      -0.02\n      -0.02\n      -0.02\n      -0.03\n      -0.02\n      -0.02\n      -0.02\n      -0.02\n      ...\n      -0.03\n      -0.03\n      -0.03\n      -0.02\n      -0.03\n      -0.02\n      -0.03\n      -0.04\n      -0.04\n      -0.02\n    \n    \n      75%\n      0.03\n      0.02\n      0.06\n      0.06\n      0.06\n      0.06\n      0.05\n      -0.02\n      0.07\n      0.05\n      ...\n      0.04\n      0.04\n      0.01\n      -0.02\n      -0.00\n      0.02\n      0.03\n      0.02\n      0.01\n      0.05\n    \n    \n      max\n      0.25\n      0.26\n      0.19\n      0.20\n      0.19\n      0.25\n      0.20\n      0.40\n      0.19\n      0.24\n      ...\n      0.22\n      0.23\n      0.29\n      0.32\n      0.43\n      0.26\n      0.58\n      0.26\n      0.24\n      0.38\n    \n  \n\n8 rows × 177 columns\n\n\n\n\npd.DataFrame(X_train, columns=X_unscaled_train.columns)['range_heat_of_vaporization_(kJ/mol)_'].hist()\n\n<AxesSubplot:>"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#model-fitting-1",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#model-fitting-1",
    "title": "Mateiral informatics sample project",
    "section": "Model fitting",
    "text": "Model fitting\n\nfrom time import time \n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n\n\nmodel = RandomForestRegressor(random_state=42)\n\n\n%%time\nmodel.fit(X_train, y_train)\n\nCPU times: user 5.51 s, sys: 31.7 ms, total: 5.54 s\nWall time: 5.57 s\n\n\nRandomForestRegressor(random_state=42)\n\n\n\ndef display_performance(y_true, y_pred):\n    r2 = r2_score(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    \n    print('R2: {0:0.2f}\\n'\n          'MAE: {1:0.2f}\\n'\n          'RMSE: {2:0.2f}'.format(r2, mae, rmse))\n    return(r2, mae, rmse)\n\n\ny_pred = model.predict(X_val)\ndisplay_performance(y_val,y_pred);\n\nR2: 0.81\nMAE: 14.03\nRMSE: 20.48\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_val, y_pred, alpha=0.6, label='Random Forest')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_val, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x7fb9372fb610>"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#feature-importance",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#feature-importance",
    "title": "Mateiral informatics sample project",
    "section": "Feature Importance",
    "text": "Feature Importance\n\nfeature_name = [i for i in X_unscaled_train.columns]\n\n\nlen(feature_name)\n\n177\n\n\n\nX_train.shape\n\n(1000, 177)\n\n\n\nlen(model.estimators_)\n\n100\n\n\n\nmean_feature_importance = model.feature_importances_\nstd_feature_importance = np.std([ tree.feature_importances_ for tree in model.estimators_ ], axis=0)\n\n\nfeat_imp_df = pd.DataFrame({'name':feature_name, 'mean_imp':mean_feature_importance, 'std_dev':std_feature_importance})\n\n\nfeat_imp_df_top = feat_imp_df.sort_values('mean_imp', ascending=False)[:20]\n\n\nfeat_imp_df_top[:5]\n\n\n\n\n\n  \n    \n      \n      name\n      mean_imp\n      std_dev\n    \n  \n  \n    \n      24\n      sum_valence_s\n      0.383415\n      0.273328\n    \n    \n      12\n      sum_Covalent_Radius\n      0.205463\n      0.220244\n    \n    \n      17\n      sum_MB_electonegativity\n      0.098704\n      0.212963\n    \n    \n      31\n      sum_Number_of_unfilled_f_valence_electrons\n      0.076559\n      0.028590\n    \n    \n      176\n      T\n      0.049666\n      0.008509\n    \n  \n\n\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(30,3))\nax.bar(feat_imp_df_top['name'], feat_imp_df_top['mean_imp'], yerr=feat_imp_df_top['std_dev'])\nax.tick_params(axis='x', rotation=90)\nax.set_title('Feature Importance');\n\n\n\n\n\ntop_feature_list = feat_imp_df.loc[ feat_imp_df['mean_imp'] > 0.001 ]['name']\n\n\nlen(top_feature_list)\n\n40\n\n\n\nX_train_df = pd.DataFrame(X_train, columns=feature_name)\nX_val_df = pd.DataFrame(X_val, columns=feature_name)\n\nX_train_short = X_train_df[list(top_feature_list)]\nX_val_short = X_val_df[list(top_feature_list)]\n\n\nprint(X_train_short.shape, X_train.shape)\n\n(1000, 40) (1000, 177)\n\n\n\nRefit a new model on small feature set\n\nmodel_small = RandomForestRegressor(random_state=42)\n\n\n%%time\nmodel_small.fit(X_train_short, y_train)\n\nCPU times: user 1.41 s, sys: 13.9 ms, total: 1.43 s\nWall time: 1.44 s\n\n\nRandomForestRegressor(random_state=42)\n\n\n\ny_pred = model_small.predict(X_val_short)\ndisplay_performance(y_val, y_pred);\n\nR2: 0.81\nMAE: 13.87\nRMSE: 20.40\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(5,5))\nax.scatter(y_val, y_pred, alpha=0.6, label='Random Forest')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n# Linear fit\nreg = np.polyfit(y_val, y_pred, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='Linear Fit')\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='Parity Line')\nax.set_aspect('equal')\n        \nax.set_xlabel('True value')\nax.set_ylabel('Model predicted')\nax.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x7fb934fa1310>"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#cross-validation",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#cross-validation",
    "title": "Mateiral informatics sample project",
    "section": "Cross-validation",
    "text": "Cross-validation\nCombine train and validation set to generate one train - test set for cross-validation\n\n# Train stack \nX_y_train = np.c_[X_train_short, y_train]\nX_y_train.shape\n\n(1000, 41)\n\n\n\nnp.unique(X_y_train[:,-1] - y_train)\n\narray([0.])\n\n\n\n# Validation stack\nX_y_val = np.c_[X_val_short, y_val]\n\n\nX_Y_TRAIN = np.vstack((X_y_train, X_y_val))\n\n\nX_TRAIN = X_Y_TRAIN[:,0:-1].copy()\nY_TRAIN = X_Y_TRAIN[:,-1].copy()\n\nprint(X_TRAIN.shape, Y_TRAIN.shape)\n\n(1944, 40) (1944,)\n\n\n\nfrom sklearn.model_selection import cross_validate\n\ndef display_score(scores, metric):\n    score_key = 'test_{}'.format(metric)\n    print(metric)\n    print('Mean: {}'.format(scores[score_key].mean()))\n    print('Std dev: {}'.format(scores[score_key].std()))\n\n\n%%time\n_scoring = ['neg_root_mean_squared_error', 'neg_mean_absolute_error']\nforest_scores = cross_validate(model, X_TRAIN, Y_TRAIN, \n                              scoring = _scoring, cv=5)\n\nCPU times: user 11.1 s, sys: 66 ms, total: 11.1 s\nWall time: 11.2 s\n\n\n\ndisplay_score(forest_scores, _scoring[0])\n\nneg_root_mean_squared_error\nMean: -15.22268277329878\nStd dev: 3.677396464443359\n\n\n\ndisplay_score(forest_scores, _scoring[1])\n\nneg_mean_absolute_error\nMean: -9.559763633911203\nStd dev: 2.786793874037375"
  },
  {
    "objectID": "posts/2021-04-28-material_prop_walkthrough.html#hyperparameter-optimization",
    "href": "posts/2021-04-28-material_prop_walkthrough.html#hyperparameter-optimization",
    "title": "Mateiral informatics sample project",
    "section": "Hyperparameter Optimization",
    "text": "Hyperparameter Optimization\n\nimport joblib\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\nrandom_forest_base_model = RandomForestRegressor(random_state=42)\n\nparam_grid = {\n    'bootstrap':[True],\n    'min_samples_leaf':[5,10,100,200,500],\n    'min_samples_split':[5,10,100,200,500],\n    'n_estimators':[100,200,400,500],\n    'max_features':['auto','sqrt','log2'],\n    'max_depth':[5,10,15,20]\n}\n\n\nCV_rf = RandomizedSearchCV(estimator=random_forest_base_model, \n                           n_iter=50, \n                           param_distributions=param_grid, \n                           scoring='neg_root_mean_squared_error',\n                           cv = 5, verbose = 1, n_jobs=-1, refit=True)\n\n\n%%time\nwith joblib.parallel_backend('multiprocessing'):\n    CV_rf.fit(X_TRAIN, Y_TRAIN)\n\nFitting 5 folds for each of 50 candidates, totalling 250 fits\nCPU times: user 646 ms, sys: 183 ms, total: 829 ms\nWall time: 1min 5s\n\n\n\nprint(CV_rf.best_params_, CV_rf.best_score_)\n\n{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': True} -19.161578679126375\n\n\n\npd.DataFrame(CV_rf.cv_results_).sort_values('rank_test_score')[:5]\n\n\n\n\n\n  \n    \n      \n      mean_fit_time\n      std_fit_time\n      mean_score_time\n      std_score_time\n      param_n_estimators\n      param_min_samples_split\n      param_min_samples_leaf\n      param_max_features\n      param_max_depth\n      param_bootstrap\n      params\n      split0_test_score\n      split1_test_score\n      split2_test_score\n      split3_test_score\n      split4_test_score\n      mean_test_score\n      std_test_score\n      rank_test_score\n    \n  \n  \n    \n      4\n      2.390702\n      0.061919\n      0.014793\n      0.000683\n      100\n      10\n      10\n      auto\n      20\n      True\n      {'n_estimators': 100, 'min_samples_split': 10,...\n      -19.636059\n      -20.949326\n      -16.321387\n      -18.878979\n      -20.022143\n      -19.161579\n      1.568968\n      1\n    \n    \n      20\n      1.299131\n      0.010285\n      0.033008\n      0.003166\n      200\n      10\n      10\n      sqrt\n      10\n      True\n      {'n_estimators': 200, 'min_samples_split': 10,...\n      -21.980440\n      -23.012936\n      -18.847124\n      -19.781677\n      -17.760789\n      -20.276593\n      1.949783\n      2\n    \n    \n      22\n      10.616245\n      0.066480\n      0.084979\n      0.025942\n      500\n      5\n      10\n      auto\n      5\n      True\n      {'n_estimators': 500, 'min_samples_split': 5, ...\n      -21.048335\n      -23.039862\n      -18.059296\n      -18.935399\n      -20.566808\n      -20.329940\n      1.733000\n      3\n    \n    \n      40\n      3.364752\n      0.126191\n      0.089052\n      0.004354\n      500\n      10\n      10\n      sqrt\n      15\n      True\n      {'n_estimators': 500, 'min_samples_split': 10,...\n      -22.245647\n      -23.261791\n      -18.796893\n      -20.179776\n      -17.747398\n      -20.446301\n      2.061082\n      4\n    \n    \n      2\n      0.448634\n      0.006245\n      0.015180\n      0.001035\n      100\n      5\n      10\n      log2\n      20\n      True\n      {'n_estimators': 100, 'min_samples_split': 5, ...\n      -22.658766\n      -23.491199\n      -19.473837\n      -20.457559\n      -17.931118\n      -20.802496\n      2.039804\n      5\n    \n  \n\n\n\n\n\nbest_model = CV_rf.best_estimator_\n\n\nbest_model\n\nRandomForestRegressor(max_depth=20, min_samples_leaf=10, min_samples_split=10,\n                      random_state=42)"
  },
  {
    "objectID": "posts/2019-08-02-end2endml_housing.html",
    "href": "posts/2019-08-02-end2endml_housing.html",
    "title": "End-to-end Machine Learning Project",
    "section": "",
    "text": "This project is adapted from Aurelien Geron’s ML book (Github link) . The aim to predict median house values in Californian districts, given a number of features from these districts.\nMain steps we will go through: 1. Formulate the problem 2. Get the data 3. Discover and visualize data / Data exploration to gain insight 4. Prep data for ML algorithm testing 5. Select model and train it 6. Fine-tuning the model\n\nStep 1: Formulate the problem\nPrediction of district’s median housing price given all other metrics. A supervised learning task is where we are given ‘labelled’ data for training purpose. Regression model to predict a continuous variable i.e. district median housing price. Given multiple features, this is a multi-class regression type problem. Univariate regression since a single output is estimated.\n\n\nStep 2: Get the data\n\nimport os \nimport pandas as pd\nimport numpy as np \n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nsns.color_palette(\"husl\")\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 30,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'lines.linewidth' : 3,\n'lines.markersize' : 10,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n#Load the dataset \nhousing = pd.read_csv('./data/housing.csv')\n\n\nhousing.sample(7)\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n      ocean_proximity\n    \n  \n  \n    \n      10769\n      -117.89\n      33.66\n      33.0\n      3595.0\n      785.0\n      1621.0\n      732.0\n      4.1372\n      265200.0\n      <1H OCEAN\n    \n    \n      4165\n      -118.20\n      34.11\n      36.0\n      1441.0\n      534.0\n      1809.0\n      500.0\n      2.1793\n      185700.0\n      <1H OCEAN\n    \n    \n      3685\n      -118.37\n      34.21\n      36.0\n      2080.0\n      455.0\n      1939.0\n      484.0\n      4.2875\n      176600.0\n      <1H OCEAN\n    \n    \n      8040\n      -118.15\n      33.84\n      37.0\n      1508.0\n      252.0\n      635.0\n      241.0\n      3.7500\n      221300.0\n      <1H OCEAN\n    \n    \n      11836\n      -120.98\n      39.08\n      20.0\n      4570.0\n      906.0\n      2125.0\n      815.0\n      3.0403\n      148000.0\n      INLAND\n    \n    \n      1525\n      -122.07\n      37.89\n      28.0\n      3410.0\n      746.0\n      1428.0\n      670.0\n      4.3864\n      266800.0\n      NEAR BAY\n    \n    \n      18180\n      -122.03\n      37.37\n      9.0\n      2966.0\n      770.0\n      1430.0\n      740.0\n      3.0047\n      256000.0\n      <1H OCEAN\n    \n  \n\n\n\n\nEach row presents one district. Each of these districts has 10 attributes (features).\n\nhousing.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 20640 entries, 0 to 20639\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           20640 non-null  float64\n 1   latitude            20640 non-null  float64\n 2   housing_median_age  20640 non-null  float64\n 3   total_rooms         20640 non-null  float64\n 4   total_bedrooms      20433 non-null  float64\n 5   population          20640 non-null  float64\n 6   households          20640 non-null  float64\n 7   median_income       20640 non-null  float64\n 8   median_house_value  20640 non-null  float64\n 9   ocean_proximity     20640 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.6+ MB\n\n\nOne thing to notice in this dataset is the number of total_bedroom entries is different from other entries. This suggests there are some missing entries or null in the dataset.\n\n#To show the null elements (if any in the total_bedroom entries)\nhousing[housing.total_bedrooms.isnull()]\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n      ocean_proximity\n    \n  \n  \n    \n      290\n      -122.16\n      37.77\n      47.0\n      1256.0\n      NaN\n      570.0\n      218.0\n      4.3750\n      161900.0\n      NEAR BAY\n    \n    \n      341\n      -122.17\n      37.75\n      38.0\n      992.0\n      NaN\n      732.0\n      259.0\n      1.6196\n      85100.0\n      NEAR BAY\n    \n    \n      538\n      -122.28\n      37.78\n      29.0\n      5154.0\n      NaN\n      3741.0\n      1273.0\n      2.5762\n      173400.0\n      NEAR BAY\n    \n    \n      563\n      -122.24\n      37.75\n      45.0\n      891.0\n      NaN\n      384.0\n      146.0\n      4.9489\n      247100.0\n      NEAR BAY\n    \n    \n      696\n      -122.10\n      37.69\n      41.0\n      746.0\n      NaN\n      387.0\n      161.0\n      3.9063\n      178400.0\n      NEAR BAY\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      20267\n      -119.19\n      34.20\n      18.0\n      3620.0\n      NaN\n      3171.0\n      779.0\n      3.3409\n      220500.0\n      NEAR OCEAN\n    \n    \n      20268\n      -119.18\n      34.19\n      19.0\n      2393.0\n      NaN\n      1938.0\n      762.0\n      1.6953\n      167400.0\n      NEAR OCEAN\n    \n    \n      20372\n      -118.88\n      34.17\n      15.0\n      4260.0\n      NaN\n      1701.0\n      669.0\n      5.1033\n      410700.0\n      <1H OCEAN\n    \n    \n      20460\n      -118.75\n      34.29\n      17.0\n      5512.0\n      NaN\n      2734.0\n      814.0\n      6.6073\n      258100.0\n      <1H OCEAN\n    \n    \n      20484\n      -118.72\n      34.28\n      17.0\n      3051.0\n      NaN\n      1705.0\n      495.0\n      5.7376\n      218600.0\n      <1H OCEAN\n    \n  \n\n207 rows × 10 columns\n\n\n\nFor categorical entries (here, ocean_proximity entries) we can find out the entries and their number using the value_counts(). We can do this for any entry we wish but makes more sense for categorical entries.\n\nhousing[\"ocean_proximity\"].value_counts()\n\n<1H OCEAN     9136\nINLAND        6551\nNEAR OCEAN    2658\nNEAR BAY      2290\nISLAND           5\nName: ocean_proximity, dtype: int64\n\n\n\nhousing.describe().round(2)\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n    \n  \n  \n    \n      count\n      20640.00\n      20640.00\n      20640.00\n      20640.00\n      20433.00\n      20640.00\n      20640.00\n      20640.00\n      20640.00\n    \n    \n      mean\n      -119.57\n      35.63\n      28.64\n      2635.76\n      537.87\n      1425.48\n      499.54\n      3.87\n      206855.82\n    \n    \n      std\n      2.00\n      2.14\n      12.59\n      2181.62\n      421.39\n      1132.46\n      382.33\n      1.90\n      115395.62\n    \n    \n      min\n      -124.35\n      32.54\n      1.00\n      2.00\n      1.00\n      3.00\n      1.00\n      0.50\n      14999.00\n    \n    \n      25%\n      -121.80\n      33.93\n      18.00\n      1447.75\n      296.00\n      787.00\n      280.00\n      2.56\n      119600.00\n    \n    \n      50%\n      -118.49\n      34.26\n      29.00\n      2127.00\n      435.00\n      1166.00\n      409.00\n      3.53\n      179700.00\n    \n    \n      75%\n      -118.01\n      37.71\n      37.00\n      3148.00\n      647.00\n      1725.00\n      605.00\n      4.74\n      264725.00\n    \n    \n      max\n      -114.31\n      41.95\n      52.00\n      39320.00\n      6445.00\n      35682.00\n      6082.00\n      15.00\n      500001.00\n    \n  \n\n\n\n\nDescribe is powerful subroutine since that allows us to check the stat summary of numerical attributes\nThe 25%-50%-75% entries for each column show corresponding percentiles. It indicates the value below which a given percentage of observations in a group of observations fall. For example, 25% of observation have median income below 2.56, 50% observations have median income below 3.53, and 75% observations have median income below 4.74. 25% –> 1st Quartile, 50% –> Median, 75% –> 3rd Quartile\n\nhousing.hist(bins=50,figsize=(20,20));\n\n\n\n\nFew observations from the Histogram plots, again remember each row is an entry for an ENTIRE district:\n\nNOTICE: From the dataset’s source disclaimer: The housing_median_value, housing_median_age, median_income_value are capped at an arbitrary value.\n\n\nFrom latitute and longitude plots there seems to be lots of district in four particular locations (34,37 – latitude) and (-120,-118 – longitude). We cannot comment on the exact location but only one on these pairs giving most data.\nWe see a tighter distribution for total_rooms, total_bedrooms, and population but spread for house_value and an intresting spike at its end.\nSmall spike at the end of median_income plot suggests presence of small group of affluent families but interestingly that spike does not correlate with the spike in the house_value (More high-end property entries than more “rich” people in a district)\n\nFinally, the dataset is tail-heavy that is they extend further to the right from the median which might make modeling using some ML algorithm a bit chanellenging. Few entries should be scaled such that the distribution is more normal.\n\n\nCreate a test-set\nThis ensures that this is the data on which training, testing occurs and we do not try overfitting to account for all the variance in the data. Typical 20% of data-points are randomly chosen.\n\ndef split_train_test(data,test_ratio):\n    shuffled_indices=np.random.permutation(len(data))\n    test_set_size=int(len(data)*test_ratio)\n    test_indices=shuffled_indices[:test_set_size]\n    train_indices=shuffled_indices[test_set_size:]\n    return(data.iloc[train_indices],data.iloc[test_indices])\n\n\n#To ensure we get similar results at each run -- if not initiated every successive will give more random \n#shuffled indices risking the possibility of the algo seeing the entire dataset! \n\nnp.random.seed(42)\n\n#Random seed set to 42 for no particular reason \n#but just cause its the answer to the Ultimate Question of Life, The Universe, and Everything\n\ntrain_set, test_set = split_train_test(housing, 0.2)\nprint(len(train_set), \"train +\", len(test_set), \"test\")\n\n16512 train + 4128 test\n\n\nBetter way is to have an instance identifier (like id) for each entry to distingusih each entry and see if its sampled or not.\n\nfrom zlib import crc32\n\ndef test_set_check(identifier, test_ratio):\n    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n\ndef split_train_test_by_id(data, test_ratio, id_column):\n    ids = data[id_column]\n    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n    return data.loc[~in_test_set], data.loc[in_test_set]\n\nThe dataset currently doesnt have inherent id. We could use the row index as id. Or we could use an ad-hoc unique identifier as an interim id.\n\n#HOUSING DATA WITH ID as ROW INDEX\nhousing_with_id = housing.reset_index()   # adds an `index` column\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\n\n#HOUSING DATA WITH ID AS COMBO OF LAT AND LONG. \nhousing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\ntrain_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")\n\n#SCIKIT-LEARN IMPLEMENTATION\n#from sklearn.model_selection import train_test_split\n#train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n\n\ntest_set.head()\n\n\n\n\n\n  \n    \n      \n      index\n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      median_house_value\n      ocean_proximity\n      id\n    \n  \n  \n    \n      59\n      59\n      -122.29\n      37.82\n      2.0\n      158.0\n      43.0\n      94.0\n      57.0\n      2.5625\n      60000.0\n      NEAR BAY\n      -122252.18\n    \n    \n      60\n      60\n      -122.29\n      37.83\n      52.0\n      1121.0\n      211.0\n      554.0\n      187.0\n      3.3929\n      75700.0\n      NEAR BAY\n      -122252.17\n    \n    \n      61\n      61\n      -122.29\n      37.82\n      49.0\n      135.0\n      29.0\n      86.0\n      23.0\n      6.1183\n      75000.0\n      NEAR BAY\n      -122252.18\n    \n    \n      62\n      62\n      -122.29\n      37.81\n      50.0\n      760.0\n      190.0\n      377.0\n      122.0\n      0.9011\n      86100.0\n      NEAR BAY\n      -122252.19\n    \n    \n      67\n      67\n      -122.29\n      37.80\n      52.0\n      1027.0\n      244.0\n      492.0\n      147.0\n      2.6094\n      81300.0\n      NEAR BAY\n      -122252.20\n    \n  \n\n\n\n\nHowever the sampling we have considered here or the one used in Scikit-learn is random sampling by default. This is fine for large dataset however for smaller dataset it is utmost important that the sampled data is representative of the main population data or else we will introduce sampling bias.\nThis is an important bias that could be introduced without prior knowledge and could be overlooked at multiple occassion leading to wrong conclusions. To ensure the sampled dataset is representative of the population set we use stratified sampling (pseudo-random sampling). To make the stratified sampling tractable we first divide the main data into multiple ‘stratas’ based on an variable which we feel is an feature that should be replicated in our test set. The sample is divided into strata and right number of instances are chosen from each strata. We must not have too many stratas and the each strate must have appropriate number of instances.\nFor the case of property pricing in the district, median_income variable is chosen as the variable whose distribution in the main population and the randomly chosen test sample is same. This attribute is an important attribute to predict the final median housing price. So we can think of converting the continuous variable of median_variable into categorical variable – that is stratas.\n\nStratified sampling using median income\n\nhousing[\"median_income\"].hist()\n\n<AxesSubplot:>\n\n\n\n\n\nFrom the median_income histogram it is seen that most of the entries are clustered in the range of 2-5 (arbitrary units). We can then use this information to make stratas around these instances. Cut routine in the pandas is used for this purpose. This function is also useful for going from a continuous variable to a categorical variable. For example, cut could convert ages to groups of age ranges.\n\nhousing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf], #bins around 2-5 income bracket\n                               labels=[1, 2, 3, 4, 5])\nhousing[\"income_cat\"].value_counts()\n\n3    7236\n2    6581\n4    3639\n5    2362\n1     822\nName: income_cat, dtype: int64\n\n\n\nhousing[\"income_cat\"].hist()\n\n<AxesSubplot:>\n\n\n\n\n\nNow with the population categorised into various median income groups we can use stratified sampling routine (as implemented in scikit-learn) to make our test-set. As an additional proof let’s compare this to a randomly sampled test_case. We will redo the random sampling we did prviously but with the new population with categorised median_income.\n\n#Stratified sampling from scikit-learn \nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]\n\n#Using random sampling\nrand_train_set, rand_test_set = train_test_split(housing, test_size=0.2, random_state=42)\n\nLet’s check the distribution of the income_cat variable in the strat_test, random_test, and the main sample.\n\nhousing[\"income_cat\"].value_counts()/len(housing[\"income_cat\"])\n\n3    0.350581\n2    0.318847\n4    0.176308\n5    0.114438\n1    0.039826\nName: income_cat, dtype: float64\n\n\n\nrand_test_set[\"income_cat\"].value_counts()/len(rand_test_set[\"income_cat\"])\n\n3    0.358527\n2    0.324370\n4    0.167393\n5    0.109496\n1    0.040213\nName: income_cat, dtype: float64\n\n\n\nstrat_test_set[\"income_cat\"].value_counts()/len(strat_test_set[\"income_cat\"])\n\n3    0.350533\n2    0.318798\n4    0.176357\n5    0.114583\n1    0.039729\nName: income_cat, dtype: float64\n\n\n\ndef income_cat_proportions(data):\n    return data[\"income_cat\"].value_counts() / len(data)\n\ncompare_props = pd.DataFrame({\n    \"Overall\": income_cat_proportions(housing),\n    \"Stratified\": income_cat_proportions(strat_test_set),\n    \"Random\": income_cat_proportions(rand_test_set),\n}).sort_index()\ncompare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\ncompare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100\n\n\ncompare_props\n\n\n\n\n\n  \n    \n      \n      Overall\n      Stratified\n      Random\n      Rand. %error\n      Strat. %error\n    \n  \n  \n    \n      1\n      0.039826\n      0.039729\n      0.040213\n      0.973236\n      -0.243309\n    \n    \n      2\n      0.318847\n      0.318798\n      0.324370\n      1.732260\n      -0.015195\n    \n    \n      3\n      0.350581\n      0.350533\n      0.358527\n      2.266446\n      -0.013820\n    \n    \n      4\n      0.176308\n      0.176357\n      0.167393\n      -5.056334\n      0.027480\n    \n    \n      5\n      0.114438\n      0.114583\n      0.109496\n      -4.318374\n      0.127011\n    \n  \n\n\n\n\nNow, we can remove the income_cat column\n\nfor set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)\n\n\n\n\nPreliminary visualization of the data\nLet’s now dive a bit deeper into the data visualization and analysis. Before we do so, copy the strat_train_set as that would be the data-set we would be playing around and make sure the main data-set is not touched.\n\nhousing=strat_train_set.copy()\nhousing.info()\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 16512 entries, 17606 to 15775\nData columns (total 10 columns):\n #   Column              Non-Null Count  Dtype  \n---  ------              --------------  -----  \n 0   longitude           16512 non-null  float64\n 1   latitude            16512 non-null  float64\n 2   housing_median_age  16512 non-null  float64\n 3   total_rooms         16512 non-null  float64\n 4   total_bedrooms      16354 non-null  float64\n 5   population          16512 non-null  float64\n 6   households          16512 non-null  float64\n 7   median_income       16512 non-null  float64\n 8   median_house_value  16512 non-null  float64\n 9   ocean_proximity     16512 non-null  object \ndtypes: float64(9), object(1)\nmemory usage: 1.4+ MB\n\n\n\nGeographical visualization\nLet’s now plot the data entries in the housing data as per the latitude and longitude.\n\nhousing.plot(kind='scatter',x='longitude',y='latitude');\n\n*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n\n\n<AxesSubplot:xlabel='longitude', ylabel='latitude'>\n\n\n\n\n\nThis look’s like California however, we cannot infer anything more out of this. Let’s play around a little bit more…\n\nPlaying with the alpha value in the plotting routine allows us to see the frequency of THAT datapoint in the plot\n\n\nhousing.plot(kind='scatter',x='longitude',y='latitude',alpha=0.1);\n\n*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n\n\n<AxesSubplot:xlabel='longitude', ylabel='latitude'>\n\n\n\n\n\nFrom here, we can see the high density of listings in the Bay area and LA also around Sacramento and Fresco.\n\nhousing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n    s=housing[\"population\"]/100, label=\"population\", figsize=(8,5),\n    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()\n\n<matplotlib.legend.Legend at 0x7f82c1692f70>\n\n\n\n\n\nThis is more interesting! We have now plotted the data with more information. Each data-point has two additional set of info apart of frequency of occurence. First being the color of the point is the median_house_value entry (option c). The radius of the data-point is the population of that district (option s). It can be seen that the housing prices are very much related to the location. The ones closer to the bay area are more expensive but need not be densely populated.\n\n\nLooking for simple correlations\nIn addition to looking at the plot of housing price, we can check for simpler correaltions. Pearson’s correlation matrix is something which is in-built in pandas and can be directly used. It checks for correlation between every pair of feature provided in the data-set. It estimates the covariance of the two features and estimates whether the correlation is inverse, direct, or none.\n\ncorr_matrix=housing.corr()\ncorr_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n\n\n                    longitude        latitude        housing_median_age        total_rooms        total_bedrooms        population        households        median_income        median_house_value    \n                \n                        longitude\n                        1.00\n                        -0.92\n                        -0.11\n                        0.05\n                        0.08\n                        0.11\n                        0.06\n                        -0.02\n                        -0.05\n            \n            \n                        latitude\n                        -0.92\n                        1.00\n                        0.01\n                        -0.04\n                        -0.07\n                        -0.12\n                        -0.08\n                        -0.08\n                        -0.14\n            \n            \n                        housing_median_age\n                        -0.11\n                        0.01\n                        1.00\n                        -0.36\n                        -0.33\n                        -0.30\n                        -0.31\n                        -0.11\n                        0.11\n            \n            \n                        total_rooms\n                        0.05\n                        -0.04\n                        -0.36\n                        1.00\n                        0.93\n                        0.86\n                        0.92\n                        0.20\n                        0.14\n            \n            \n                        total_bedrooms\n                        0.08\n                        -0.07\n                        -0.33\n                        0.93\n                        1.00\n                        0.88\n                        0.98\n                        -0.01\n                        0.05\n            \n            \n                        population\n                        0.11\n                        -0.12\n                        -0.30\n                        0.86\n                        0.88\n                        1.00\n                        0.90\n                        0.00\n                        -0.03\n            \n            \n                        households\n                        0.06\n                        -0.08\n                        -0.31\n                        0.92\n                        0.98\n                        0.90\n                        1.00\n                        0.01\n                        0.06\n            \n            \n                        median_income\n                        -0.02\n                        -0.08\n                        -0.11\n                        0.20\n                        -0.01\n                        0.00\n                        0.01\n                        1.00\n                        0.69\n            \n            \n                        median_house_value\n                        -0.05\n                        -0.14\n                        0.11\n                        0.14\n                        0.05\n                        -0.03\n                        0.06\n                        0.69\n                        1.00\n            \n    \n\n\n\ncorr_matrix['median_house_value'].sort_values(ascending=True)\n\nlatitude             -0.142724\nlongitude            -0.047432\npopulation           -0.026920\ntotal_bedrooms        0.047689\nhouseholds            0.064506\nhousing_median_age    0.114110\ntotal_rooms           0.135097\nmedian_income         0.687160\nmedian_house_value    1.000000\nName: median_house_value, dtype: float64\n\n\nThe correlation matrix suggests the amount of correlation between a pair of variables. When close to 1 it means a strong +ve correlation whereas, -1 means an inverse correlation. Looking at the correlation between median_house_values and other variables, we can see that there’s some correlation with median_income (0.68 – so +ve), and with the latitude (-0.14 – so an inverse relation).\nAnother to check this relation is to plot scatter plots for each pair of variables in the dataset. Below we plot this for few potential/interesting variables\n\n# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\nfrom pandas.plotting import scatter_matrix\n\nattributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n              \"housing_median_age\"]\nscatter_axes = scatter_matrix(housing[attributes], figsize=(12, 8));\n#y labels\n[plt.setp(item.yaxis.get_label(), 'size', 10) for item in scatter_axes.ravel()];\n#x labels\n[plt.setp(item.xaxis.get_label(), 'size', 10) for item in scatter_axes.ravel()];\n\n\n\n\nThe diagonal entries show the histogram for each variable. We saw this previously for some variables. The most promising variable from this analysis seems to be the median_income.\n\nhousing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n             alpha=0.1);\n\n*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n\n\n\n\n\nPlotting it shows the stronger correlation with the target variable i.e. median_house_value however we can see horizontal lines (especially at USD 500k, 450k 350k) these could be due to some stratifying done in the dataset implicitly. It would be better to remove those to ensure our model does not spuriously fit for those since they are some of the quirks in the data.\n\n\n\nExperimenting with attributes\nBefore we began proposing models for the data. We can play around with the variables and try different combinations of them to see if we get better trends. Let’s look at a few. First, the total_room and/or total_bedroom variable could be changed to average_bedroom_per_house to better for bedrooms rather than looking for total bedroom in that district we would be looking at avg_bedroom per district and similarly we would do it for rooms.\n\n#Average bedroom per house-holds in the district \nhousing['avg_bedroom']=housing['total_bedrooms']/housing['households']\n\n#Average room per house-holds in the district \nhousing['avg_room']=housing['total_rooms']/housing['households']\n\n#Average bedrooms per rooms in a given district\nhousing['bedroom_per_room']=housing['total_bedrooms']/housing['total_rooms']\n\n#Average population per household in a given district\nhousing['population_per_household']=housing['population']/housing['households']\n\n#Average room per population in a given district\nhousing['room_per_popoulation']=housing['total_rooms']/housing['population']\n\n#Average room per population in a given district\nhousing['room_per_popoulation']=housing['total_rooms']/housing['population']\n\n\n#Making the correlation matrix again \ncorr_matrix=housing.corr()\ncorr_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n\n\n                    longitude        latitude        housing_median_age        total_rooms        total_bedrooms        population        households        median_income        median_house_value        avg_bedroom        avg_room        bedroom_per_room        population_per_household        room_per_popoulation    \n                \n                        longitude\n                        1.00\n                        -0.92\n                        -0.11\n                        0.05\n                        0.08\n                        0.11\n                        0.06\n                        -0.02\n                        -0.05\n                        0.01\n                        -0.03\n                        0.10\n                        -0.00\n                        -0.07\n            \n            \n                        latitude\n                        -0.92\n                        1.00\n                        0.01\n                        -0.04\n                        -0.07\n                        -0.12\n                        -0.08\n                        -0.08\n                        -0.14\n                        0.07\n                        0.11\n                        -0.12\n                        0.01\n                        0.14\n            \n            \n                        housing_median_age\n                        -0.11\n                        0.01\n                        1.00\n                        -0.36\n                        -0.33\n                        -0.30\n                        -0.31\n                        -0.11\n                        0.11\n                        -0.08\n                        -0.15\n                        0.14\n                        0.02\n                        -0.10\n            \n            \n                        total_rooms\n                        0.05\n                        -0.04\n                        -0.36\n                        1.00\n                        0.93\n                        0.86\n                        0.92\n                        0.20\n                        0.14\n                        0.03\n                        0.13\n                        -0.19\n                        -0.02\n                        0.12\n            \n            \n                        total_bedrooms\n                        0.08\n                        -0.07\n                        -0.33\n                        0.93\n                        1.00\n                        0.88\n                        0.98\n                        -0.01\n                        0.05\n                        0.04\n                        0.00\n                        0.09\n                        -0.03\n                        0.05\n            \n            \n                        population\n                        0.11\n                        -0.12\n                        -0.30\n                        0.86\n                        0.88\n                        1.00\n                        0.90\n                        0.00\n                        -0.03\n                        -0.07\n                        -0.07\n                        0.04\n                        0.08\n                        -0.14\n            \n            \n                        households\n                        0.06\n                        -0.08\n                        -0.31\n                        0.92\n                        0.98\n                        0.90\n                        1.00\n                        0.01\n                        0.06\n                        -0.06\n                        -0.08\n                        0.07\n                        -0.03\n                        -0.04\n            \n            \n                        median_income\n                        -0.02\n                        -0.08\n                        -0.11\n                        0.20\n                        -0.01\n                        0.00\n                        0.01\n                        1.00\n                        0.69\n                        -0.06\n                        0.31\n                        -0.62\n                        0.02\n                        0.23\n            \n            \n                        median_house_value\n                        -0.05\n                        -0.14\n                        0.11\n                        0.14\n                        0.05\n                        -0.03\n                        0.06\n                        0.69\n                        1.00\n                        -0.04\n                        0.15\n                        -0.26\n                        -0.02\n                        0.20\n            \n            \n                        avg_bedroom\n                        0.01\n                        0.07\n                        -0.08\n                        0.03\n                        0.04\n                        -0.07\n                        -0.06\n                        -0.06\n                        -0.04\n                        1.00\n                        0.86\n                        0.05\n                        -0.01\n                        0.84\n            \n            \n                        avg_room\n                        -0.03\n                        0.11\n                        -0.15\n                        0.13\n                        0.00\n                        -0.07\n                        -0.08\n                        0.31\n                        0.15\n                        0.86\n                        1.00\n                        -0.40\n                        -0.01\n                        0.90\n            \n            \n                        bedroom_per_room\n                        0.10\n                        -0.12\n                        0.14\n                        -0.19\n                        0.09\n                        0.04\n                        0.07\n                        -0.62\n                        -0.26\n                        0.05\n                        -0.40\n                        1.00\n                        0.00\n                        -0.26\n            \n            \n                        population_per_household\n                        -0.00\n                        0.01\n                        0.02\n                        -0.02\n                        -0.03\n                        0.08\n                        -0.03\n                        0.02\n                        -0.02\n                        -0.01\n                        -0.01\n                        0.00\n                        1.00\n                        -0.05\n            \n            \n                        room_per_popoulation\n                        -0.07\n                        0.14\n                        -0.10\n                        0.12\n                        0.05\n                        -0.14\n                        -0.04\n                        0.23\n                        0.20\n                        0.84\n                        0.90\n                        -0.26\n                        -0.05\n                        1.00\n            \n    \n\n\n\ncorr_matrix['median_house_value'].sort_values(ascending=True)\n\nbedroom_per_room           -0.259984\nlatitude                   -0.142724\nlongitude                  -0.047432\navg_bedroom                -0.043343\npopulation                 -0.026920\npopulation_per_household   -0.021985\ntotal_bedrooms              0.047689\nhouseholds                  0.064506\nhousing_median_age          0.114110\ntotal_rooms                 0.135097\navg_room                    0.146285\nroom_per_popoulation        0.199429\nmedian_income               0.687160\nmedian_house_value          1.000000\nName: median_house_value, dtype: float64\n\n\nThis is interesting! We see that bedroom_per_room is another potential descriptor with negative corelation moreover we get room_per_population and avg_room to be decent new descriptors for the median_house_value. Not bad for a simple math manipulation to better represent the data. This is a crucial step and where domain knowledge and intuition would come handy.\n\n\nData cleaning and prepping\n\nSeparate the predictors and the target values\nWrite functions to conduct various data transformations ensuring consistency and ease\nMake sure the data is devoid of any NaN values since that would raise warning and errors. We have three strategies we can implement here:\n\nGet rid of those points (districts) entirely\nGet rid of whole attribute\nSet missing values to either zero or one of the averages (mean, median, or mode)\n\n\nIn our case, total bedrooms had some missing values.\n# Option a:\nhousing.dropna(subset=[\"total_bedrooms\"])\n# Option b:\nhousing.drop(\"total_bedrooms\", axis=1)\n# Option c:\nmedian = housing[\"total_bedrooms\"].median()\nhousing[\"total_bedrooms\"].fillna(median, inplace=True) # option 3\nBefore we do any of this let’s first separate the predictor and target_values\n\nhousing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\nhousing_labels = strat_train_set[\"median_house_value\"].copy()\n\n\n#Checking the NULL enties in the dataset\nsample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\nsample_incomplete_rows\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      ocean_proximity\n    \n  \n  \n    \n      4629\n      -118.30\n      34.07\n      18.0\n      3759.0\n      NaN\n      3296.0\n      1462.0\n      2.2708\n      <1H OCEAN\n    \n    \n      6068\n      -117.86\n      34.01\n      16.0\n      4632.0\n      NaN\n      3038.0\n      727.0\n      5.1762\n      <1H OCEAN\n    \n    \n      17923\n      -121.97\n      37.35\n      30.0\n      1955.0\n      NaN\n      999.0\n      386.0\n      4.6328\n      <1H OCEAN\n    \n    \n      13656\n      -117.30\n      34.05\n      6.0\n      2155.0\n      NaN\n      1039.0\n      391.0\n      1.6675\n      INLAND\n    \n    \n      19252\n      -122.79\n      38.48\n      7.0\n      6837.0\n      NaN\n      3468.0\n      1405.0\n      3.1662\n      <1H OCEAN\n    \n  \n\n\n\n\n\nsample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      ocean_proximity\n    \n  \n  \n  \n\n\n\n\n\nsample_incomplete_rows.drop(\"total_bedrooms\", axis=1)   #option 2\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      population\n      households\n      median_income\n      ocean_proximity\n    \n  \n  \n    \n      4629\n      -118.30\n      34.07\n      18.0\n      3759.0\n      3296.0\n      1462.0\n      2.2708\n      <1H OCEAN\n    \n    \n      6068\n      -117.86\n      34.01\n      16.0\n      4632.0\n      3038.0\n      727.0\n      5.1762\n      <1H OCEAN\n    \n    \n      17923\n      -121.97\n      37.35\n      30.0\n      1955.0\n      999.0\n      386.0\n      4.6328\n      <1H OCEAN\n    \n    \n      13656\n      -117.30\n      34.05\n      6.0\n      2155.0\n      1039.0\n      391.0\n      1.6675\n      INLAND\n    \n    \n      19252\n      -122.79\n      38.48\n      7.0\n      6837.0\n      3468.0\n      1405.0\n      3.1662\n      <1H OCEAN\n    \n  \n\n\n\n\n\nmedian = housing[\"total_bedrooms\"].median()\nsample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3\nsample_incomplete_rows\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      ocean_proximity\n    \n  \n  \n    \n      4629\n      -118.30\n      34.07\n      18.0\n      3759.0\n      433.0\n      3296.0\n      1462.0\n      2.2708\n      <1H OCEAN\n    \n    \n      6068\n      -117.86\n      34.01\n      16.0\n      4632.0\n      433.0\n      3038.0\n      727.0\n      5.1762\n      <1H OCEAN\n    \n    \n      17923\n      -121.97\n      37.35\n      30.0\n      1955.0\n      433.0\n      999.0\n      386.0\n      4.6328\n      <1H OCEAN\n    \n    \n      13656\n      -117.30\n      34.05\n      6.0\n      2155.0\n      433.0\n      1039.0\n      391.0\n      1.6675\n      INLAND\n    \n    \n      19252\n      -122.79\n      38.48\n      7.0\n      6837.0\n      433.0\n      3468.0\n      1405.0\n      3.1662\n      <1H OCEAN\n    \n  \n\n\n\n\n\nScikit-learn imputer class\nThis is a handy class to take of missing values. First, we create an instance of that class with specifying what is to be replaced and what strategy is used. Before doing so, we need to make srue the entire data-set has ONLY numerical entries and Imputer will evaluate the given average for all the dataset and store it in the statistics_ instance\nWhat the imputer will do is, 1. Evaluate an specified type of average. 2. For a given numerical data-set look for NaN or Null entires in a given attribute and replace it with the computed avearge for that attribute\n\ntry:\n    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\nexcept ImportError:\n    from sklearn.preprocessing import Imputer as SimpleImputer\n\nimputer = SimpleImputer(strategy=\"median\") #We define the strategy here \nhousing_num = housing.drop('ocean_proximity', axis=1)\n# alternatively: housing_num = housing.select_dtypes(include=[np.number])\n\n\nimputer.fit(housing_num)\n\nSimpleImputer(strategy='median')\n\n\n\nimputer.statistics_\n\narray([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n        408.    ,    3.5409])\n\n\n\nhousing_num.median().values\n\narray([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n        408.    ,    3.5409])\n\n\nWe can now use this as a training variables set for our model\n\nX = imputer.transform(housing_num)\n\nWe convert the Pandas dataframe entries to a numpy array which is transformed with appropriately replacing the missing entries with median.\n\nprint(type(X), type(housing_num))\n\n<class 'numpy.ndarray'> <class 'pandas.core.frame.DataFrame'>\n\n\n\nprint(np.shape(X), housing_num.shape)\n'''\nIf we need the data-frame back\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing.index)\n'''\n\n(16512, 8) (16512, 8)\n\n\n'\\nIf we need the data-frame back\\nhousing_tr = pd.DataFrame(X, columns=housing_num.columns,\\n                          index=housing.index)\\n'\n\n\n\n\n\nHandling Text and Categorical Attribute\nNow let’s preprocess the categorical input feature, ocean_proximity:\n\nhousing_cat = housing[['ocean_proximity']]\ntype(housing_cat)\n\npandas.core.frame.DataFrame\n\n\nConverting the categorical entries to integers\n\ntry:\n    from sklearn.preprocessing import OrdinalEncoder\nexcept ImportError:\n    from future_encoders import OrdinalEncoder # Scikit-Learn < 0.20\n    \nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\nhousing_cat_encoded[:10]\n\narray([[0.],\n       [0.],\n       [4.],\n       [1.],\n       [0.],\n       [1.],\n       [0.],\n       [1.],\n       [0.],\n       [0.]])\n\n\n\nhousing[\"ocean_proximity\"].value_counts()\n\n<1H OCEAN     7276\nINLAND        5263\nNEAR OCEAN    2124\nNEAR BAY      1847\nISLAND           2\nName: ocean_proximity, dtype: int64\n\n\nNow, housing_cat_encoded has converted the categorical entries to purely numerical values for each category\n\nordinal_encoder.categories_\n\n[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n       dtype=object)]\n\n\nNow, this is helpful with the string categories getting converted to numerical categories. However, there is still an small issue. The categorical numbering may introduce some bias in the final model. ML algorithms will assume that two nearby values are more similar than two distant values.\nIn the above case, ‘<1H OCEAN’ and ‘INLAND’have category values as 0 and 1 however’<1H OCEAN’ is more closer to ‘NEAR OCEAN’ with category value 4.\nTo fix this issue, one solution is to create one binary attribute per category. This is called One-hot encoding as ONLY one of the attribute in the vector is 1 (hot) and others are 0 (cold).\nScikit-learn provides a OneHotEncoder encoder to convert integer categorical values to one-hot vectors.\n\ntry:\n    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n    from sklearn.preprocessing import OneHotEncoder\nexcept ImportError:\n    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20\n\ncat_encoder = OneHotEncoder()\n#1-Hot encoded vector for the housing training data-set \nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\ntype(housing_cat_1hot)\n\nscipy.sparse.csr.csr_matrix\n\n\nA sparse array is declared in this case which has the position of the non-zero value and not necessarily the entire numpy matrix. This is helpful in the cases where there are too many categories and also many datapoints. For examples, if we have 4 categories and 1000 datapoints the final one-hot matrix would be 1000x4 size. Most of that would be full of 0s, with only one 1 per row for a particular category.\nThe housing_cat_1hot can be converted to numpy array by using the housing_cat_1hot.toarray()\nAlternatively, you can set sparse=False when creating the OneHotEncoder\n\ncat_encoder.categories_\n\n[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n       dtype=object)]\n\n\nLet’s create a custom transformer to add extra attributes:\n\nhousing.columns\n\nIndex(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n       'total_bedrooms', 'population', 'households', 'median_income',\n       'ocean_proximity'],\n      dtype='object')\n\n\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n# get the right column indices: safer than hard-coding indices\nrooms_ix, bedrooms_ix, population_ix, household_ix = [\n    list(housing.columns).index(col) for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n\n#Here we convert the housing.columns to list and \n#then find the index for the entry which matches the string in the loop \n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    def fit(self, X, y=None):\n        return self  # nothing else to do\n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n        population_per_household = X[:, population_ix] / X[:, household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household,\n                         bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n\nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=True)\nhousing_extra_attribs = attr_adder.transform(housing.values)\n\nFrom the above class, there’s only one hyperparameter in the class. add_bedrooms_per_room is the only option and is set True by default. Let’s check the new feature space by converting it to a Pandas Dataframe\n\nhousing_extra_attribs = pd.DataFrame(\n    housing_extra_attribs,\n    columns=list(housing.columns)+[\"bedrooms_per_room\",\"rooms_per_household\", \"population_per_household\"],\n    index=housing.index)\nhousing_extra_attribs.head()\n\n\n\n\n\n  \n    \n      \n      longitude\n      latitude\n      housing_median_age\n      total_rooms\n      total_bedrooms\n      population\n      households\n      median_income\n      ocean_proximity\n      bedrooms_per_room\n      rooms_per_household\n      population_per_household\n    \n  \n  \n    \n      17606\n      -121.89\n      37.29\n      38.0\n      1568.0\n      351.0\n      710.0\n      339.0\n      2.7042\n      <1H OCEAN\n      4.625369\n      2.094395\n      0.223852\n    \n    \n      18632\n      -121.93\n      37.05\n      14.0\n      679.0\n      108.0\n      306.0\n      113.0\n      6.4214\n      <1H OCEAN\n      6.00885\n      2.707965\n      0.159057\n    \n    \n      14650\n      -117.2\n      32.77\n      31.0\n      1952.0\n      471.0\n      936.0\n      462.0\n      2.8621\n      NEAR OCEAN\n      4.225108\n      2.025974\n      0.241291\n    \n    \n      3230\n      -119.61\n      36.31\n      25.0\n      1847.0\n      371.0\n      1460.0\n      353.0\n      1.8839\n      INLAND\n      5.232295\n      4.135977\n      0.200866\n    \n    \n      3555\n      -118.59\n      34.23\n      17.0\n      6592.0\n      1525.0\n      4459.0\n      1463.0\n      3.0347\n      <1H OCEAN\n      4.50581\n      3.047847\n      0.231341\n    \n  \n\n\n\n\n\n\nFeature scaling\nFeaature scaling is an important transformation needed to be applied to the data. With some exceptions, ML algorithms dont perform well when the input numerical entries have very different scales. Eg: One variable has range 0-1 but other variable has range 1-1000. This is the case in our data-base where the total number of rooms range from 6 to 39,320 while the objective variable i.e. median income only ranges from 0-15. Two common ways of scaling:\n\nMin-max scaling (also called Normalization) Values are shifted such that they are normalized. They are rescaled in the range of 0-1. We do this by subtracting the min value and dividing by the range in the data \\[\\begin{equation}\nx_{i} = \\frac{X_{i}-min}{max-min}\n\\end{equation}\\]\nStandardization This is when the mean of the dataset is subtracted from each entry so that the data has mean as 0 and then divided by the standard deviation so that the resulting distribution has a unit variance. Unlike min-max scaling, standardization does not bound to a particular range like 0-1. However, standardisation is much less affected by outliers. If a particular values is extremely high or low that could affect the other inputs in the case of min-max scaling. However that effect is reduced in the case of standardization given it does not directly account for the range in the scaling but the mean and variance. \\[\\begin{equation}\nx_{i} = \\frac{X_{i}-\\mu}{\\sigma}\n\\end{equation}\\]\n\n\nNOTE: It is important that these scaling operations are performed on the training data only and not on the full dataset\n\n\n\nTransformation pipelines\nPipeline class in scikit-learn can help with sequences of transformations. Now let’s build a pipeline for preprocessing the numerical attributes (note that we could use CombinedAttributesAdder() instead of FunctionTransformer(...) if we preferred):\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")), #Fill in missing values using the median of each entry \n        ('attribs_adder', CombinedAttributesAdder(add_bedrooms_per_room=True)), #Add additional columns entrys\n        ('std_scaler', StandardScaler()), #Feature scaling -- using standardisation here \n    ])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)\n\n\nhousing_num_tr\n\narray([[-1.15604281,  0.77194962,  0.74333089, ..., -0.31205452,\n        -0.08649871,  0.15531753],\n       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.21768338,\n        -0.03353391, -0.83628902],\n       [ 1.18684903, -1.34218285,  0.18664186, ..., -0.46531516,\n        -0.09240499,  0.4222004 ],\n       ...,\n       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.3469342 ,\n        -0.03055414, -0.52177644],\n       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.02499488,\n         0.06150916, -0.30340741],\n       [-1.43579109,  0.99645926,  1.85670895, ..., -0.22852947,\n        -0.09586294,  0.10180567]])\n\n\nThis Pipeline constructor takes a list of name/estimator pairs defining a sequence of steps. All but the last step/estimator must be the trasnformers (like feature scaling).\n\ntry:\n    from sklearn.compose import ColumnTransformer\nexcept ImportError:\n    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20\n\nNow let’s join all these components into a big pipeline that will preprocess both the numerical and the categorical features (again, we could use CombinedAttributesAdder() instead of FunctionTransformer(...) if we preferred):\n\nnum_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfull_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, num_attribs),\n        (\"cat\", OneHotEncoder(), cat_attribs),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing)\n\n\nhousing_prepared\n\narray([[-1.15604281,  0.77194962,  0.74333089, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.17602483,  0.6596948 , -1.1653172 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 1.18684903, -1.34218285,  0.18664186, ...,  0.        ,\n         0.        ,  1.        ],\n       ...,\n       [ 1.58648943, -0.72478134, -1.56295222, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.78221312, -0.85106801,  0.18664186, ...,  0.        ,\n         0.        ,  0.        ],\n       [-1.43579109,  0.99645926,  1.85670895, ...,  0.        ,\n         1.        ,  0.        ]])\n\n\n\nhousing_prepared.shape\n\n(16512, 16)\n\n\n\n\nStep 3: Select and train a model\nFinally.\n\nTraining and evaluation on the training set\nGiven the prioir transformations, the features are scaled, categories are converted to one-hot vectors, and the missing variables are taken account of. Let’s train a Linear Regression model first\n\nfrom sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression() \nlin_reg.fit(housing_prepared, housing_labels)\n\nLinearRegression()\n\n\n\n#Test some data out on the model \ntrial_input = housing.iloc[:5] #First 5 entries \ntrial_label = housing_labels.iloc[:5] #First 5 labels corresponding to the entries \nprep_trial_input = full_pipeline.transform(trial_input) #Transforming the entries to suit the trained input \nprint('Predictions:',lin_reg.predict(prep_trial_input))\n\nPredictions: [210644.60459286 317768.80697211 210956.43331178  59218.98886849\n 189747.55849879]\n\n\n\nprint('Labels:',list(trial_label))\n\nLabels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n\n\n\nfrom sklearn.metrics import mean_squared_error\n\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse\n\n68628.19819848923\n\n\n\nhousing_labels.describe()\n\ncount     16512.000000\nmean     206990.920724\nstd      115703.014830\nmin       14999.000000\n25%      119800.000000\n50%      179500.000000\n75%      263900.000000\nmax      500001.000000\nName: median_house_value, dtype: float64\n\n\nAs seen the RMSE is 68628 which is better than nothing but still it is quite high when the range of the median_house_values range from 15000 to 500000\n\nfrom sklearn.metrics import mean_absolute_error\n\nlin_mae = mean_absolute_error(housing_labels, housing_predictions)\nlin_mae\n\n49439.89599001897\n\n\nHere the model is underfitting the data since the RMSE is so high. > When this happens either the features do not provide enough information to make good predictions or the model is not powerful enough.\nLet’s try using a more complex model, DecisionTreeRegressor which is capable of finding non-linear relationships in the data\n\n\nDecision Tree Regressor\n\nfrom sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(housing_prepared, housing_labels)\n\nDecisionTreeRegressor(random_state=42)\n\n\n\nhousing_predictions = tree_reg.predict(housing_prepared)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse\n\n0.0\n\n\nLOL!\nThis model is badly overfitting the data! Let’s proof this hypothesis using cross-validation schemes. We dont want to touch the test set, JUST WORK WITH THE TRAINING SET. Only touch the test set when the model we are using is good enough. We will use the part of the training set for training and other part for model validation.\n\n\nFine-tune the model\nCross-validation\nCross-validation is a method of getting reliable estimate of model performance using only the training data 10-fold cross-validation — breaking training data in 10 equal parts creating 10 miniature test/train splits. Out of the 10 folds, train data on 9 and test on 10th. Do this 10 times each time holding out different fold.\n\nScikit-learn cross-validation feature expects a utility function (greater the better) rather than a cost function (lower the better), so to score the functions we use opposite of MSE, which is why we again compute -scores before calculating the square root\n\n\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n                         scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)\n\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())\n\ndisplay_scores(tree_rmse_scores)\n\nScores: [70194.33680785 66855.16363941 72432.58244769 70758.73896782\n 71115.88230639 75585.14172901 70262.86139133 70273.6325285\n 75366.87952553 71231.65726027]\nMean: 71407.68766037929\nStandard deviation: 2439.4345041191004\n\n\nCross-validation not only allows us to get an estimate of the performance of the model but also the measure of how precise this estimate is (i.e. standard deviation). The Decision tree has high std-dev. This information could not be obtained with just one validation set. However, caveat is that cross-validation comes at the cost of training the model several times, so it is not always possible.\nLet’s compute the same score for LinearRegresson model.\n\nlin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n                             scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)\n\nScores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n 71552.91566558 67665.10082067]\nMean: 69052.46136345083\nStandard deviation: 2731.674001798342\n\n\nHere it can be seen that DecisionTree model performs much worse than the LinearRegression model.\n\n\nRandom Forrest Regressor\nRandom forrest works by employing many decision trees on random subsets of the features, then averaging out their predictions. Building a model on top of many other models is called Ensemble Learning and it is often great way to push ML algorithms even further.\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\nforest_reg.fit(housing_prepared, housing_labels)\n\nRandomForestRegressor(n_estimators=10, random_state=42)\n\n\n\nNote: we specify n_estimators=10 to avoid a warning about the fact that the default value is going to change to 100 in Scikit-Learn 0.22.\n\n\nhousing_predictions = forest_reg.predict(housing_prepared)\nforest_mse = mean_squared_error(housing_labels, housing_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse\n\n21933.31414779769\n\n\n\nfrom sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)\ndisplay_scores(forest_rmse_scores)\n\nScores: [51646.44545909 48940.60114882 53050.86323649 54408.98730149\n 50922.14870785 56482.50703987 51864.52025526 49760.85037653\n 55434.21627933 53326.10093303]\nMean: 52583.72407377466\nStandard deviation: 2298.353351147122\n\n\nRandom forest regressor looks better than DecisionTree and LinearRegression. The RMSE is still quite high for production quality code and could be due to overfitting. We can try other algorithms before spending time on a particular algorithm tweaking the hyperparameters. The goal is to shortlist 2-3 methods that are promising then fine-tune the model. Before we move ahead we can take a look at one more ML algorithm which is commonly employed for such supervised learning cases: Support Vector Regression\n\nfrom sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\")\nsvm_reg.fit(housing_prepared, housing_labels)\nhousing_predictions = svm_reg.predict(housing_prepared)\nsvm_mse = mean_squared_error(housing_labels, housing_predictions)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse\n\n111094.6308539982\n\n\n\n\n\nStep 4: Fine-tune the model\nOnce we settle for an algorithm we can fine-tune them efficiently using some of the in-built scikit-learn routines.\n\nGrid Search\nGridSearchCV is a faster way of tweaking the hyper-parameters for a given algorithm. It needs the hyper-parameters you want to experiment with, what values to try out, and it will evaluate possible combination of hyperparameters values using cross-validation. We can do that step for RandomForrestRegressor which we found to have lowesst RMSE of the three methods we tried\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3×4) combinations of hyperparameters\n    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n    # then try 6 (2×3) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error', return_train_score=True)\ngrid_search.fit(housing_prepared, housing_labels)\n\nGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n             param_grid=[{'max_features': [2, 4, 6, 8],\n                          'n_estimators': [3, 10, 30]},\n                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n                          'n_estimators': [3, 10]}],\n             return_train_score=True, scoring='neg_mean_squared_error')\n\n\nThe param_grid tells Scikit-learn to: 1. First evaluate 3x4 combinations of n_estimators and max_features with bootstrap True which is the default. 2. Then with bootstrap set as False we look for 2x3 combinations of n_estimators and max_featurs for the random forest 3. Finally, both these models are trained 5 times for the cross validation purposes in a 5-fold cross-validation fashion.\nTotal of (12+6)x5=90 round of training are conducted. Finally when it is done we get the best model parameters which give lowest RMSE.\n\ngrid_search.best_params_\n\n{'max_features': 8, 'n_estimators': 30}\n\n\n\ngrid_search.best_estimator_\n\nRandomForestRegressor(max_features=8, n_estimators=30, random_state=42)\n\n\n\ncvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)\n\n63669.11631261028 {'max_features': 2, 'n_estimators': 3}\n55627.099719926795 {'max_features': 2, 'n_estimators': 10}\n53384.57275149205 {'max_features': 2, 'n_estimators': 30}\n60965.950449450494 {'max_features': 4, 'n_estimators': 3}\n52741.04704299915 {'max_features': 4, 'n_estimators': 10}\n50377.40461678399 {'max_features': 4, 'n_estimators': 30}\n58663.93866579625 {'max_features': 6, 'n_estimators': 3}\n52006.19873526564 {'max_features': 6, 'n_estimators': 10}\n50146.51167415009 {'max_features': 6, 'n_estimators': 30}\n57869.25276169646 {'max_features': 8, 'n_estimators': 3}\n51711.127883959234 {'max_features': 8, 'n_estimators': 10}\n49682.273345071546 {'max_features': 8, 'n_estimators': 30}\n62895.06951262424 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n54658.176157539405 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n59470.40652318466 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n52724.9822587892 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n57490.5691951261 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n51009.495668875716 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n\n\n\npd.DataFrame(grid_search.cv_results_)\n\n\n\n\n\n  \n    \n      \n      mean_fit_time\n      std_fit_time\n      mean_score_time\n      std_score_time\n      param_max_features\n      param_n_estimators\n      param_bootstrap\n      params\n      split0_test_score\n      split1_test_score\n      ...\n      mean_test_score\n      std_test_score\n      rank_test_score\n      split0_train_score\n      split1_train_score\n      split2_train_score\n      split3_train_score\n      split4_train_score\n      mean_train_score\n      std_train_score\n    \n  \n  \n    \n      0\n      0.053401\n      0.002499\n      0.003312\n      0.000173\n      2\n      3\n      NaN\n      {'max_features': 2, 'n_estimators': 3}\n      -3.837622e+09\n      -4.147108e+09\n      ...\n      -4.053756e+09\n      1.519591e+08\n      18\n      -1.064113e+09\n      -1.105142e+09\n      -1.116550e+09\n      -1.112342e+09\n      -1.129650e+09\n      -1.105559e+09\n      2.220402e+07\n    \n    \n      1\n      0.182488\n      0.002683\n      0.010123\n      0.001727\n      2\n      10\n      NaN\n      {'max_features': 2, 'n_estimators': 10}\n      -3.047771e+09\n      -3.254861e+09\n      ...\n      -3.094374e+09\n      1.327062e+08\n      11\n      -5.927175e+08\n      -5.870952e+08\n      -5.776964e+08\n      -5.716332e+08\n      -5.802501e+08\n      -5.818785e+08\n      7.345821e+06\n    \n    \n      2\n      0.503301\n      0.010947\n      0.024532\n      0.000476\n      2\n      30\n      NaN\n      {'max_features': 2, 'n_estimators': 30}\n      -2.689185e+09\n      -3.021086e+09\n      ...\n      -2.849913e+09\n      1.626875e+08\n      9\n      -4.381089e+08\n      -4.391272e+08\n      -4.371702e+08\n      -4.376955e+08\n      -4.452654e+08\n      -4.394734e+08\n      2.966320e+06\n    \n    \n      3\n      0.081569\n      0.001284\n      0.003247\n      0.000154\n      4\n      3\n      NaN\n      {'max_features': 4, 'n_estimators': 3}\n      -3.730181e+09\n      -3.786886e+09\n      ...\n      -3.716847e+09\n      1.631510e+08\n      16\n      -9.865163e+08\n      -1.012565e+09\n      -9.169425e+08\n      -1.037400e+09\n      -9.707739e+08\n      -9.848396e+08\n      4.084607e+07\n    \n    \n      4\n      0.269809\n      0.005145\n      0.008730\n      0.000133\n      4\n      10\n      NaN\n      {'max_features': 4, 'n_estimators': 10}\n      -2.666283e+09\n      -2.784511e+09\n      ...\n      -2.781618e+09\n      1.268607e+08\n      8\n      -5.097115e+08\n      -5.162820e+08\n      -4.962893e+08\n      -5.436192e+08\n      -5.160297e+08\n      -5.163863e+08\n      1.542862e+07\n    \n    \n      5\n      0.800619\n      0.007793\n      0.024065\n      0.000543\n      4\n      30\n      NaN\n      {'max_features': 4, 'n_estimators': 30}\n      -2.387153e+09\n      -2.588448e+09\n      ...\n      -2.537883e+09\n      1.214614e+08\n      3\n      -3.838835e+08\n      -3.880268e+08\n      -3.790867e+08\n      -4.040957e+08\n      -3.845520e+08\n      -3.879289e+08\n      8.571233e+06\n    \n    \n      6\n      0.113473\n      0.004140\n      0.003330\n      0.000178\n      6\n      3\n      NaN\n      {'max_features': 6, 'n_estimators': 3}\n      -3.119657e+09\n      -3.586319e+09\n      ...\n      -3.441458e+09\n      1.893056e+08\n      14\n      -9.245343e+08\n      -8.886939e+08\n      -9.353135e+08\n      -9.009801e+08\n      -8.624664e+08\n      -9.023976e+08\n      2.591445e+07\n    \n    \n      7\n      0.378872\n      0.014358\n      0.009405\n      0.001258\n      6\n      10\n      NaN\n      {'max_features': 6, 'n_estimators': 10}\n      -2.549663e+09\n      -2.782039e+09\n      ...\n      -2.704645e+09\n      1.471569e+08\n      6\n      -4.980344e+08\n      -5.045869e+08\n      -4.994664e+08\n      -4.990325e+08\n      -5.055542e+08\n      -5.013349e+08\n      3.100456e+06\n    \n    \n      8\n      1.222785\n      0.030201\n      0.027815\n      0.001110\n      6\n      30\n      NaN\n      {'max_features': 6, 'n_estimators': 30}\n      -2.370010e+09\n      -2.583638e+09\n      ...\n      -2.514673e+09\n      1.285080e+08\n      2\n      -3.838538e+08\n      -3.804711e+08\n      -3.805218e+08\n      -3.856095e+08\n      -3.901917e+08\n      -3.841296e+08\n      3.617057e+06\n    \n    \n      9\n      0.146751\n      0.002996\n      0.003320\n      0.000174\n      8\n      3\n      NaN\n      {'max_features': 8, 'n_estimators': 3}\n      -3.353504e+09\n      -3.348552e+09\n      ...\n      -3.348850e+09\n      1.241939e+08\n      13\n      -9.228123e+08\n      -8.553031e+08\n      -8.603321e+08\n      -8.881964e+08\n      -9.151287e+08\n      -8.883545e+08\n      2.750227e+07\n    \n    \n      10\n      0.510138\n      0.016372\n      0.009396\n      0.000904\n      8\n      10\n      NaN\n      {'max_features': 8, 'n_estimators': 10}\n      -2.571970e+09\n      -2.718994e+09\n      ...\n      -2.674041e+09\n      1.392777e+08\n      5\n      -4.932416e+08\n      -4.815238e+08\n      -4.730979e+08\n      -5.155367e+08\n      -4.985555e+08\n      -4.923911e+08\n      1.459294e+07\n    \n    \n      11\n      1.518905\n      0.056501\n      0.025125\n      0.001086\n      8\n      30\n      NaN\n      {'max_features': 8, 'n_estimators': 30}\n      -2.357390e+09\n      -2.546640e+09\n      ...\n      -2.468328e+09\n      1.091662e+08\n      1\n      -3.841658e+08\n      -3.744500e+08\n      -3.773239e+08\n      -3.882250e+08\n      -3.810005e+08\n      -3.810330e+08\n      4.871017e+06\n    \n    \n      12\n      0.077979\n      0.001837\n      0.003983\n      0.000390\n      2\n      3\n      False\n      {'bootstrap': False, 'max_features': 2, 'n_est...\n      -3.785816e+09\n      -4.166012e+09\n      ...\n      -3.955790e+09\n      1.900964e+08\n      17\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      0.000000e+00\n      0.000000e+00\n    \n    \n      13\n      0.259085\n      0.003267\n      0.010411\n      0.000311\n      2\n      10\n      False\n      {'bootstrap': False, 'max_features': 2, 'n_est...\n      -2.810721e+09\n      -3.107789e+09\n      ...\n      -2.987516e+09\n      1.539234e+08\n      10\n      -6.056477e-02\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -2.967449e+00\n      -6.056027e-01\n      1.181156e+00\n    \n    \n      14\n      0.104454\n      0.004167\n      0.003841\n      0.000315\n      3\n      3\n      False\n      {'bootstrap': False, 'max_features': 3, 'n_est...\n      -3.618324e+09\n      -3.441527e+09\n      ...\n      -3.536729e+09\n      7.795057e+07\n      15\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -6.072840e+01\n      -1.214568e+01\n      2.429136e+01\n    \n    \n      15\n      0.345978\n      0.004147\n      0.010372\n      0.000444\n      3\n      10\n      False\n      {'bootstrap': False, 'max_features': 3, 'n_est...\n      -2.757999e+09\n      -2.851737e+09\n      ...\n      -2.779924e+09\n      6.286720e+07\n      7\n      -2.089484e+01\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -5.465556e+00\n      -5.272080e+00\n      8.093117e+00\n    \n    \n      16\n      0.135484\n      0.015839\n      0.004140\n      0.000585\n      4\n      3\n      False\n      {'bootstrap': False, 'max_features': 4, 'n_est...\n      -3.134040e+09\n      -3.559375e+09\n      ...\n      -3.305166e+09\n      1.879165e+08\n      12\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      0.000000e+00\n      0.000000e+00\n    \n    \n      17\n      0.453605\n      0.013427\n      0.010725\n      0.000358\n      4\n      10\n      False\n      {'bootstrap': False, 'max_features': 4, 'n_est...\n      -2.525578e+09\n      -2.710011e+09\n      ...\n      -2.601969e+09\n      1.088048e+08\n      4\n      -0.000000e+00\n      -1.514119e-02\n      -0.000000e+00\n      -0.000000e+00\n      -0.000000e+00\n      -3.028238e-03\n      6.056477e-03\n    \n  \n\n18 rows × 23 columns\n\n\n\n\n\nRandomised search\nGrid search approach is fine when we are exploring relatively few combinations. But when hyperparameter space is large it is often preferrable to use RandomizedSearchCV instead. Here instead of doing all the possible combinationes of hyperparameters, it evaluates a given number of random combinations by selecting a random value for each hyper parameter at every iteration.\n\n\nEnsemble search\nCombine models that perform best. The group or ‘ensemble’ will often perform better than the best individual model just like RandomForest peforms better than Decision Trees especially if we have individual models make different types of errors.\n\n\n\nStep 5: Analyze the Best Models and their Errors\nRandomForestRegressor can indicate the relative importance of each attribute for making the accurate predictions.\n\nfeature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances\n\narray([7.33442355e-02, 6.29090705e-02, 4.11437985e-02, 1.46726854e-02,\n       1.41064835e-02, 1.48742809e-02, 1.42575993e-02, 3.66158981e-01,\n       5.64191792e-02, 1.08792957e-01, 5.33510773e-02, 1.03114883e-02,\n       1.64780994e-01, 6.02803867e-05, 1.96041560e-03, 2.85647464e-03])\n\n\n\nextra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_encoder = full_pipeline.named_transformers_[\"cat\"]\ncat_one_hot_attribs = list(cat_encoder.categories_[0])\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)\n\n[(0.36615898061813423, 'median_income'),\n (0.16478099356159054, 'INLAND'),\n (0.10879295677551575, 'pop_per_hhold'),\n (0.07334423551601243, 'longitude'),\n (0.06290907048262032, 'latitude'),\n (0.056419179181954014, 'rooms_per_hhold'),\n (0.053351077347675815, 'bedrooms_per_room'),\n (0.04114379847872964, 'housing_median_age'),\n (0.014874280890402769, 'population'),\n (0.014672685420543239, 'total_rooms'),\n (0.014257599323407808, 'households'),\n (0.014106483453584104, 'total_bedrooms'),\n (0.010311488326303788, '<1H OCEAN'),\n (0.0028564746373201584, 'NEAR OCEAN'),\n (0.0019604155994780706, 'NEAR BAY'),\n (6.0280386727366e-05, 'ISLAND')]\n\n\n\n\nStep 6: Evaluate the model on the Test Set\n\nfinal_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\n\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(y_test, final_predictions, s=100)\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n       ]\n\nax.plot(lims, lims, 'k--', linewidth=2.0, alpha=0.75, zorder=0)\nax.set_aspect('equal')\nax.set_xlim(lims)\nax.set_ylim(lims)\n\nax.set_xlabel('ML Prediction')\nax.set_ylabel('Actual Value')\n\nText(0, 0.5, 'Actual Value')\n\n\n\n\n\n\nfinal_mse = mean_squared_error(y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nprint(final_rmse)\n\n47730.22690385927\n\n\nWe can compute a 95% confidence interval for the test RMSE:\n\nfrom scipy import stats\nconfidence = 0.95\nsquared_errors = (final_predictions - y_test) ** 2\nmean = squared_errors.mean()\nm = len(squared_errors)\n\nnp.sqrt(stats.t.interval(confidence, m - 1,\n                         loc=np.mean(squared_errors),\n                         scale=stats.sem(squared_errors)))\n\narray([45685.10470776, 49691.25001878])\n\n\nAlternatively, we could use a z-scores rather than t-scores:\n\nzscore = stats.norm.ppf((1 + confidence) / 2)\nzmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\nnp.sqrt(mean - zmargin), np.sqrt(mean + zmargin)\n\n(45685.717918136594, 49690.68623889426)"
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html",
    "title": "Convolutional neural network example",
    "section": "",
    "text": "This tutorial is adopted from Python-Engineer’s Pytorch Tutorial | Video\nGood reading links: - CMU’s CS231 Course\nConvolutional neural network is used to train CIFAR-10 dataset. It is implemented in PyTorch"
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html#loading-the-data",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html#loading-the-data",
    "title": "Convolutional neural network example",
    "section": "Loading the data",
    "text": "Loading the data\nDataset has PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1]\n\n# dataset has PILImage images of range [0, 1]. \n# We transform them to Tensors of normalized range [-1, 1]\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n#Importing the training set for the CIFAR10 dataset\ntrain_dataset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True,\n                                        download=True, transform=transform)\n\n#Importing the testing set for the CIFAR10 dataset\ntest_dataset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False,\n                                       download=True, transform=transform)\n\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n\n\n\n\n\nExtracting data/cifar-10-python.tar.gz to data/\nFiles already downloaded and verified\n\n\n\ndef imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n#Define data-loader classs and labels for the images in the dataset\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                          shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n                                         shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n\n# get some random training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\nprint('Images of: {}'.format([classes[i] for i in labels]))\nprint('Size of the image array for a given batch: {}'.format(images.shape))\n\n\n\n\nImages of: ['truck', 'horse', 'deer', 'ship']\nSize of the image array for a given batch: torch.Size([4, 3, 32, 32])"
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html#testing-the-convolutions",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html#testing-the-convolutions",
    "title": "Convolutional neural network example",
    "section": "Testing the convolutions",
    "text": "Testing the convolutions\nBefore implementing the CNN for the image recognition let’s see what the convolutions and the pooling layers do the images\nConvolution is the first layer to extract features from an input image. It preserves the relationship between pixels by learning images features using small squares of input data. It’s a matrix operation that takes two inputs – image matrix and a filter/kernel\nTwo main hyper-parameters for the pooling layers: 1. Stride – controls how filters ‘slides’ on the input volume. Stride is normally set in a way so that the output volume is an integer and not a fraction. Increase the stride if you want receptive fields to overlap less and want smaller spatial dimensions\n\nPadding –  Image matrix multiplies kernel or filter matrix\n\n 3 x 3 Output matrix\n\nCalculating the output size of the image after convolutions:\nTo calculate the output size of the image after convolution layer:\n\\[O = \\frac{W - F + 2P}{S} + 1\\]\nwhere O is the output height/length, W is the input height/length, F is the filter size, P is the padding, and S is the stride."
  },
  {
    "objectID": "posts/2020-03-17-cnn_pytorch_tutorial.html#pooling-layers",
    "href": "posts/2020-03-17-cnn_pytorch_tutorial.html#pooling-layers",
    "title": "Convolutional neural network example",
    "section": "Pooling layers",
    "text": "Pooling layers\nPooling layers section would reduce the number of parameters when the images are too large. Spatial pooling also called subsampling or downsampling which reduces the dimensionality of each map but retains important information. Spatial pooling can be of different types: 1. Max Pooling 2. Average Pooling 3. Sum Pooling\nMax pooling takes the largest element from the rectified feature map. Taking the largest element could also take the average pooling. Sum of all elements in the feature map call as sum pooling.\n Max pooling scheme\n\nconv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\npool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0) #Take max of the 2x2 array and shift by 2 \nconv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n\n\nprint(images.shape)\nx = conv1(images)\nprint(x.shape)\n\ntorch.Size([4, 3, 32, 32])\ntorch.Size([4, 6, 28, 28])\n\n\n\nx = pool(x)\nprint(x.shape)\n\ntorch.Size([4, 6, 14, 14])\n\n\n\nx = conv2(x)\nprint(x.shape)\n\ntorch.Size([4, 16, 10, 10])\n\n\n\nx = pool(x)\nprint(x.shape)\n\ntorch.Size([4, 16, 5, 5])\n\n\n\nBuilding the CNN class\n\nclass ConvNet(nn.Module):\n    '''\n    Inherit from the nn.Module all the necessary routines \n    \n    super() is in the business of delegating method calls \n    to some class in the instance’s ancestor tree.\n    \n    Conv1 = First convolution 3 color channels (RGB) to 6 output, \n    filter size=5\n    \n    pool = Max pool layer of 2x2 and stride of 2 ie. we shift 2 \n    pixel to the right after each pooling operations \n    \n    Conv2 = Second convolution layer with 6 input channel and \n    16 output channel, filter size of 5 \n    \n    Full connected layer \n    \n    FC1 = Flatten output of the final convolution + pooling (16 * 5 * 5)\n    to 120 dim array \n    \n    FC2 = 120 to 84 \n    FC3 = 84 to no of hidden equal to that of class labels \n    \n    Forward operation \n    -----------------------\n    images --> conv --> relu --> pool --> conv2 --> relu --> pool\n    Flatten pooled output --> FC (w/ relu) --> FC (relu) --> FC --> output\n    '''\n    def __init__(self):\n        super(ConvNet, self).__init__()\n        #Here we built the architecture for the CNN\n        #First conv1 function instantiation\n        self.conv1 = nn.Conv2d(3,6,5) \n        #General purpose pooling \n        self.pool = nn.MaxPool2d(2,2) \n        #Second conv2 function instantiation\n        self.conv2 = nn.Conv2d(6,16,5)\n        #1st NN layer\n        self.fc1 = nn.Linear(16*5*5,120)\n        #2nd NN layer \n        self.fc2 = nn.Linear(120,84)\n        #Final output layer \n        self.fc3 = nn.Linear(84,10) \n    \n    def forward(self, x):\n        #Two pooling operations\n        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n        #Flatten the output from pooling/convoltions\n        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n        x = F.relu(self.fc1(x))               # -> n, 120\n        x = F.relu(self.fc2(x))               # -> n, 84\n        x = self.fc3(x)                       # -> n, 10\n        return x\n\n\n\nDefining the training criterion and optmizer\n\n#Define model, criterion, optimizer for the GD \nmodel = ConvNet().to(device)\n#For multiclass classification -- crossentropy loss \ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n\n\n\nTrain the CNN on the test dataset\n\nn_total_steps = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images,labels) in enumerate(train_loader):\n        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        #Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        #Backward prop and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 2000 == 0: \n            print (f'Epoch [{epoch+1}/{num_epochs}],\\\n                   Step [{i+1}/{n_total_steps}],\\\n                   Loss: {loss.item():.4f}')\nprint('Finished Training')\nPATH = './cnn.pth'\ntorch.save(model.state_dict(), PATH)\n\n\nwith torch.no_grad(): #We dont need backward propogation here\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]\n    n_class_samples = [0 for i in range(10)]\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        # max returns (value ,index)\n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n        \n        for i in range(batch_size):\n            label = labels[i]\n            pred = predicted[i]\n            if (label == pred):\n                n_class_correct[label] += 1\n            n_class_samples[label] += 1\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Accuracy of the network: {acc} %')\n\n    for i in range(10):\n        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n        print(f'Accuracy of {classes[i]}: {acc} %')\n\nAccuracy of the network: 48.28 %\nAccuracy of plane: 55.7 %\nAccuracy of car: 62.1 %\nAccuracy of bird: 26.1 %\nAccuracy of cat: 34.2 %\nAccuracy of deer: 31.0 %\nAccuracy of dog: 33.3 %\nAccuracy of frog: 75.1 %\nAccuracy of horse: 50.0 %\nAccuracy of ship: 58.7 %\nAccuracy of truck: 56.6 %"
  },
  {
    "objectID": "posts/2021-09-10-ML_checklit.html",
    "href": "posts/2021-09-10-ML_checklit.html",
    "title": "Model building checklist",
    "section": "",
    "text": "Learn about your data\n\n\nType of the data being analyzed\n\nIs the data set, sensor measure-reading what you think it is measuring\nDsitribution of the data / target\nOutliers in the data\n\n\nSingle variables\n\n\nType – continuous, discreet, categorical\nDistribution in the data\nScale of each variable\nWhat is the resolution I am interested in?\nOutliers in the variables\n\n\nFeature correlations\n\n\nStart simple – linear correlation\nUse domain knowledge and see if they make sense\nLook at subset of the data to make it tractable / subsampling\n\n\nSelection and feature engineering\n\n\nMake new (better?) features combining the orginal features\nRecast, resample, forward difference, simple arthimatic operations\n\n\n\n\n\nSplit in train and test – look at target prop statistics\nSplit train into CV or train / validation\nTrain models on the training data: - Linear model - Non linear models - Ensemble models - Decision models\nModel hyperparameters\n\n\n\n\n\nTrain on full training dataset\nAvenues of data bleed\nSplit quality - is the train/validation data representative of test data / real-life data?\n\n\n\n\n\nWhat is the source of the data (database, publication, direct experiment)?\nHow many data points are in the training, validation and test sets?\nHow were the sets split? Is any bias being introduced based on the type of split?\nAre the data, including the data splits used, released in a public forum?\nHow were the data encoded and preprocessed for the ML algorithm?\nHow many parameters (p) are used in the model?\nHow many features (f) are used as input?\nIs p much larger than the number of training points and/or is f large?\nWhich overfitting prevention techniques used?\nAre the hyperparameter configurations, optimization schedule, model files and optimization parameters reported?\nIs the model black box or interpretable?\nIs the model classification or regression?\nHow much time does a single representative prediction require on a standard machine?\nIs the source code released?\nHow was the method evaluated?\nWhich performance metrics are reported?\nWas a comparison to publicly available methods performed on benchmark datasets?\nDo the performance metrics have confidence intervals?\nAre the raw evaluation files available?"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html",
    "href": "posts/2020-11-08-network_analysis_basics.html",
    "title": "Network analysis hands-on",
    "section": "",
    "text": "Good resource to learn basics of Network science: - http://networksciencebook.com/chapter/0\nRecent summary of Graph Network and their use in ML: - Relational inductive biases, deep learning, and graph networks\nExamples of Network graphs: 1. NetworkX Example dataset 2. Stanford Large Network Dataset Collection\nNetwork building and manipulation will be done using NetworkX - a python package made for this exact function"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#basics",
    "href": "posts/2020-11-08-network_analysis_basics.html#basics",
    "title": "Network analysis hands-on",
    "section": "1. Basics",
    "text": "1. Basics\nNodes: Points which are connected to each other. Can represent people, words, or atoms – objects which have attributes of their own\nEdges: Connection between the nodes - show how nodes (entities) are connected, bond distance, social network (friendships) – property which connect the entities\n\n# Start an empty graph \nG = nx.Graph() \n\n# Add a node \nG.add_node(42)\n\n# Add node from list of entities \ntemp_list = ['A','B','C']\nG.add_nodes_from(temp_list)\n\n\nG.nodes\n\nNodeView((42, 'A', 'B', 'C'))\n\n\n\n# Remove nodes \nG.remove_node(42) #This is definite node name and should exist in the network \n\n# Multiple nodes \nG.remove_nodes_from(['A','Z','Blah']) #Here it is compared to the element to that in the list \n\n\nG.nodes\n\nNodeView(('B', 'C'))\n\n\n\n# add single edge - tuple of nodes (source, target)\n# this also adds nodes if they don't already exist\nG.add_edge('C','Z')\n\n\nprint(G.edges, G.nodes)\n\n[('C', 'Z')] ['B', 'C', 'Z']\n\n\n\n# add multiple edges (list of tuples) [(source, target), (source, target)]\nG.add_edges_from([('B', 'C') , ('B', 'Z')])\n\n\nG.edges\n\nEdgeView([('B', 'C'), ('B', 'Z'), ('C', 'Z')])\n\n\n\n# Like nodes, we can remove multiple edges \n# remove multiple edges (list of tuples)\nG.remove_edges_from([('A', 'B') , ('C', 'B')]) #Here list are commutative \n\n\nG.edges\n\nEdgeView([('B', 'Z'), ('C', 'Z')])\n\n\n\n# get number of nodes in network G\nG.number_of_nodes()\n\n3\n\n\n\n# get number of edges in network G\nG.number_of_edges()\n\n2\n\n\n\n# get number of neighbors (connections)\nG.degree('B')\n\n1\n\n\n\nG.clear()"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#reading-from-a-file",
    "href": "posts/2020-11-08-network_analysis_basics.html#reading-from-a-file",
    "title": "Network analysis hands-on",
    "section": "2. Reading from a file",
    "text": "2. Reading from a file\nFor example we will look at Facebook dataset installed from SNAP dataset\n\n# input edgelist from file\nG = nx.read_edgelist('./data/facebook_combined.txt')\n\n\nG.number_of_nodes()\n\n4039\n\n\n\nG.number_of_edges()\n\n88234\n\n\n\n# get the 2nd node's neighbors (retrieves a dictionary)\ndict_neighbors = G.neighbors('2')\n\n\nG.degree('2')\n\n10\n\n\n\nlist(dict_neighbors)\n\n['0', '20', '115', '116', '149', '226', '312', '326', '333', '343']\n\n\n\nG.clear()"
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#type-of-different-networks",
    "href": "posts/2020-11-08-network_analysis_basics.html#type-of-different-networks",
    "title": "Network analysis hands-on",
    "section": "3. Type of different networks",
    "text": "3. Type of different networks\n\na. Weighted Graphs\nEdge weight Consider that the edge that you are adding should contain additional information, such as the strength of the connection. This would be important, for example, when analyzing communication networks to check friendship/connectivity strength. You want to capture how many times they exchanged e-mails, calls, text messages, to indicate the strength of the connection. For this you will assign weights to the edge, values that can be the number of communications, or the fraction of communications, normalized.\nI had used this type of graph in my analysis for Indian spices. In that case, the edge was assigned a weight corresponding to the number of times a pair of spice occured together in a recipe.\n\n# assign weight to edge\nG.add_edge('Water','Soda', weight=10)\n\nWays to access edge property:\n\nG.edges.data()\n\nEdgeDataView([('Water', 'Soda', {'weight': 10})])\n\n\n\nG['Soda']['Water']\n\n{'weight': 10}\n\n\n\nG['Water']['Soda']\n\n{'weight': 10}\n\n\n\n# change edge weight\nG['Water']['Soda']['weight'] = -1\n\n\nG.edges.data()\n\nEdgeDataView([('Water', 'Soda', {'weight': -1})])\n\n\n\n\nb. Directed Graphs\nIncorporate directionality in the edge. Instead of having just the edge showing the connection: A — B encode a type of connection. If A is giving (food, resources, atoms, electrons) to B. In that case: A —-> B\n\n#undirected\nG.nodes\n\nNodeView(('Water', 'Soda'))\n\n\n\n# you can create a directed representation of network G\ndg = nx.to_directed(G)\n\n\ndg.edges\n\nOutEdgeView([('Water', 'Soda'), ('Soda', 'Water')])\n\n\n\ndg.get_edge_data('Water','Soda')\n\n{'weight': -1}\n\n\n\n\nc. Multigraphs\nNetworkX provides classes for graphs which allow multiple edges between any pair of nodes. The MultiGraph and MultiDiGraph classes allow you to add the same edge twice, possibly with different edge data. This can be powerful for some applications, but many algorithms are not well defined on such graphs.\n\n# multigraphs can store multiple edges information between same two nodes that can have different properties\nMG = nx.MultiGraph()\nMG.add_weighted_edges_from([(1, 2, 3.0), (1, 2, 75), (2, 3, 5), (1, 2, 4.2)])\n\n\n# lists the edges (node1, node2, edge_index), including the multiedges, adding the multiedge index as 3rd element in edge tuple\nMG.edges\n\nMultiEdgeView([(1, 2, 0), (1, 2, 1), (1, 2, 2), (2, 3, 0)])\n\n\n\n# lists the edges (node1, node2, weight/edge_attribute), the 3rd element is the weights of the edges\nMG.edges.data('weight')\n\nMultiEdgeDataView([(1, 2, 3.0), (1, 2, 75), (1, 2, 4.2), (2, 3, 5)])\n\n\n\nMG.edges.data()\n\nMultiEdgeDataView([(1, 2, {'weight': 3.0}), (1, 2, {'weight': 75}), (1, 2, {'weight': 4.2}), (2, 3, {'weight': 5})])\n\n\n\n# check the weight of an edge\nMG[1][2]\n\nAtlasView({0: {'weight': 3.0}, 1: {'weight': 75}, 2: {'weight': 4.2}})\n\n\n\n\nd. Bipartite\nBipartite graphs B = (U, V, E) have two node sets U,V and edges in E that only connect nodes from opposite sets. It is common in the literature to use an spatial analogy referring to the two node sets as top and bottom nodes.\n\nfrom networkx.algorithms import bipartite\n\n\nbip = nx.Graph()\n\n\n# add nodes with the node attribute \"bipartite\", a network of who likes what fruits\nbip.add_nodes_from(['apple', 'peach', 'watermelon', 'pear'], bipartite=0)\nbip.add_nodes_from(['Alice', 'Steve', 'Mary'], bipartite=1)\n\n\nbip.add_edges_from([('Alice', 'apple'), ('Alice', 'peach'), ('Steve', 'watermelon'), \n                    ('Mary', 'pear'), ('Mary', 'apple'), ('Mary', 'watermelon')])\n\n\nnx.draw(bip, with_labels=True)\n\n\n\n\nCurrently, NetworkX does not provide a bipartite graph visualization method to visually delimit the two sets of nodes. However, we can draw the left and right set of nodes and see how they connect to each other. Further, you can play around with coloring the nodes based on the ‘bipartite’ attribute to further refine visually to which node set each node belongs to.\n\nimport scipy.sparse as sparse\n\nX, Y = bipartite.sets(bip)\npos = dict()\npos.update((n, (1, i*10)) for i, n in enumerate(X))\npos.update((n, (1.5, i*10)) for i, n in enumerate(Y))\n\nnx.draw(bip, with_labels=True, pos=pos)\n\n\n\n\nBipartite graphs can be projected as two separate graphs G1 = (U, E1) and G2 = (V, E2). The edges will be different though.\nWe can create a network of fruits, where nodes will be fruits and the edges will between two fruits will be created if someone likes both fruits. Such, peach and apple will have one edge, as Alice likes both. Same for apple and pear, which are both liked by Mary. Likewise, we can create the second network as the network of individuals, where connections between them will be their preference for the same fruit. Here, we can create a connection/edge between Steve and Mary since both of them like watermelon."
  },
  {
    "objectID": "posts/2020-11-08-network_analysis_basics.html#network-models",
    "href": "posts/2020-11-08-network_analysis_basics.html#network-models",
    "title": "Network analysis hands-on",
    "section": "3. Network Models",
    "text": "3. Network Models\nNetwork models can be very useful for comparing their topology to the structural properties of our network built from real data. Different network models have very distinct structural characteristics, which defines their behavior in case of information flow on the network, attacks/failures on the nodes/edges, etc, and these properties have been extensively studied and are well documented. Knowing to which network model your graph corresponds to can provide valuable insights about its potential behavior under various circumstances.\nThere are a miriad of network models with different topological properties. Here we will try out some of the most useful ones (that frequently occur in real complex systems).\n\n# Barabasi-Albert (scale-free) network \nba = nx.barabasi_albert_graph(10, 5)\nnx.draw_spectral(ba, node_size=200)\n\n\n\n\nBarabasi-Alber Graph. A graph of N nodes is grown by attaching new nodes each with M edges that are preferentially attached to existing nodes with high degree.\n\n# Erdos-Renyi (random) network \ner = nx.erdos_renyi_graph(50, 0.1)\nnx.draw_circular(er)\n\n\n\n\n\n# complete graph (every pair of nodes is connected by a unique edge)\ncomplete = nx.complete_graph(5)\nnx.draw(complete)"
  },
  {
    "objectID": "posts/2020-04-22-activation_functions.html",
    "href": "posts/2020-04-22-activation_functions.html",
    "title": "Activation functions",
    "section": "",
    "text": "Function that activates the particular neuron or node if the value across a particular threshold. These functions add the necessary non-linearity in the ANNs. Each perceptron is, in reality (and traditionally), a logistic regression unit. When N units are stacked on top of each other we get a basic single layer perceptron which serves as the basis of Artificial neural network.\nClick here for Google’s ML glossary definition\nThere are different types of activation function and each has its benefits and faults. One of the consideration is the ease in evaluation of the gradient. It should be easy but also help in the final learning process by translating the necessary abstraction and non-linearity across the network. Some of the activation functions are primarily used to model the output of the ANN. Traditionally for a classification task, we would use a sigmoid activation function for a binary classification to predict a binary output (yes/no). In the case of multi-class classification that activation is replaced by softmax activation to estimate the ‘probability’ across different classes."
  },
  {
    "objectID": "posts/2020-04-22-activation_functions.html#baseline-reference",
    "href": "posts/2020-04-22-activation_functions.html#baseline-reference",
    "title": "Activation functions",
    "section": "## Baseline reference",
    "text": "## Baseline reference\n\nz = np.linspace(-10,10,100)\n\n\nSigmoid activation function\n\ndef sigmoid(z):\n    return 1/(1+np.exp(-z))\n# derivative of Sigmoid Function\ndef dsigmoid(a):\n    return a*(1-a) # returns a derivative od sigmoid function if a=sigmoid then a'=a(1-a)\n\n\nplt.plot(z, sigmoid(z), label = r'$sigmoid$')\nplt.plot(z, dsigmoid(sigmoid(z)), label = r'$ \\frac{\\partial (sigmoid)}{\\partial z}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.show()\n\n\n\n\n\n# Pytorch autograd example\nimport torch\nx = torch.tensor(z, requires_grad=True)\nprint(x.requires_grad)\nb = torch.sigmoid(x)\n\nTrue\n\n\n\nx\n\ntensor([-10.0000,  -9.7980,  -9.5960,  -9.3939,  -9.1919,  -8.9899,  -8.7879,\n         -8.5859,  -8.3838,  -8.1818,  -7.9798,  -7.7778,  -7.5758,  -7.3737,\n         -7.1717,  -6.9697,  -6.7677,  -6.5657,  -6.3636,  -6.1616,  -5.9596,\n         -5.7576,  -5.5556,  -5.3535,  -5.1515,  -4.9495,  -4.7475,  -4.5455,\n         -4.3434,  -4.1414,  -3.9394,  -3.7374,  -3.5354,  -3.3333,  -3.1313,\n         -2.9293,  -2.7273,  -2.5253,  -2.3232,  -2.1212,  -1.9192,  -1.7172,\n         -1.5152,  -1.3131,  -1.1111,  -0.9091,  -0.7071,  -0.5051,  -0.3030,\n         -0.1010,   0.1010,   0.3030,   0.5051,   0.7071,   0.9091,   1.1111,\n          1.3131,   1.5152,   1.7172,   1.9192,   2.1212,   2.3232,   2.5253,\n          2.7273,   2.9293,   3.1313,   3.3333,   3.5354,   3.7374,   3.9394,\n          4.1414,   4.3434,   4.5455,   4.7475,   4.9495,   5.1515,   5.3535,\n          5.5556,   5.7576,   5.9596,   6.1616,   6.3636,   6.5657,   6.7677,\n          6.9697,   7.1717,   7.3737,   7.5758,   7.7778,   7.9798,   8.1818,\n          8.3838,   8.5859,   8.7879,   8.9899,   9.1919,   9.3939,   9.5960,\n          9.7980,  10.0000], dtype=torch.float64, requires_grad=True)\n\n\n\nb.backward(torch.ones(x.shape))\n\n\nx.grad\n\ntensor([4.5396e-05, 5.5558e-05, 6.7994e-05, 8.3213e-05, 1.0184e-04, 1.2463e-04,\n        1.5252e-04, 1.8666e-04, 2.2843e-04, 2.7954e-04, 3.4207e-04, 4.1859e-04,\n        5.1221e-04, 6.2673e-04, 7.6682e-04, 9.3817e-04, 1.1477e-03, 1.4039e-03,\n        1.7172e-03, 2.1000e-03, 2.5677e-03, 3.1389e-03, 3.8362e-03, 4.6869e-03,\n        5.7241e-03, 6.9876e-03, 8.5250e-03, 1.0394e-02, 1.2661e-02, 1.5407e-02,\n        1.8724e-02, 2.2721e-02, 2.7521e-02, 3.3259e-02, 4.0084e-02, 4.8151e-02,\n        5.7615e-02, 6.8615e-02, 8.1257e-02, 9.5592e-02, 1.1158e-01, 1.2906e-01,\n        1.4771e-01, 1.6703e-01, 1.8633e-01, 2.0471e-01, 2.2118e-01, 2.3471e-01,\n        2.4435e-01, 2.4936e-01, 2.4936e-01, 2.4435e-01, 2.3471e-01, 2.2118e-01,\n        2.0471e-01, 1.8633e-01, 1.6703e-01, 1.4771e-01, 1.2906e-01, 1.1158e-01,\n        9.5592e-02, 8.1257e-02, 6.8615e-02, 5.7615e-02, 4.8151e-02, 4.0084e-02,\n        3.3259e-02, 2.7521e-02, 2.2721e-02, 1.8724e-02, 1.5407e-02, 1.2661e-02,\n        1.0394e-02, 8.5250e-03, 6.9876e-03, 5.7241e-03, 4.6869e-03, 3.8362e-03,\n        3.1389e-03, 2.5677e-03, 2.1000e-03, 1.7172e-03, 1.4039e-03, 1.1477e-03,\n        9.3817e-04, 7.6682e-04, 6.2673e-04, 5.1221e-04, 4.1859e-04, 3.4207e-04,\n        2.7954e-04, 2.2843e-04, 1.8666e-04, 1.5252e-04, 1.2463e-04, 1.0184e-04,\n        8.3213e-05, 6.7994e-05, 5.5558e-05, 4.5396e-05], dtype=torch.float64)\n\n\n\nplt.plot(x.data.numpy(), b.data.numpy(), label = r'$sigmoid$')\nplt.plot(x.data.numpy(), x.grad.data.numpy(), label = r'$ \\frac{\\partial (sigmoid)}{\\partial z}$')\nplt.legend(fontsize = 12)\n\n<matplotlib.legend.Legend at 0x7f8b5f3ece48>\n\n\n\n\n\n\nnp.unique(np.round((x.grad.data.numpy() - dsigmoid(sigmoid(z))),4))\n\narray([0.])\n\n\n\n\nHyperbolic tangent activation function\n\ndef tanh(z):\n    return np.tanh(z)\n\n# derivative of tanh\ndef dtanh(a):\n    return 1-np.power(a,2)\n\n\nplt.plot(z, tanh(z),'b', label = 'tanh')\nplt.plot(z, dtanh(tanh(z)),'r', label=r'$ \\frac{dtanh}{dz}$')\nplt.legend(fontsize = 12)\nplt.show()\n\n\n\n\n\n\nReLU (Rectified Linear Unit) Activation function\n\ndef ReLU(z):\n    return np.maximum(0,z)\n\n# derivative of ReLu\ndef dReLU(a):\n    return 1*(a>0)\n\n\nplt.plot(z, ReLU(z),'b', label ='ReLU')\nplt.plot(z, dReLU(ReLU(z)),'r', label=r'$ \\frac{dReLU}{dz}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.ylim(0,4)\nplt.xlim(-4,4)\nplt.show()\n\n\n\n\n\n\nLeaky ReLU Activation function\n\ndef LeakyReLU(z):\n    return np.maximum(0.01*z,z)\n\n# derivative of ReLu\ndef dLeakyReLU(a):\n    return 0.01*(a>0)\n\n\nplt.plot(z, LeakyReLU(z),'b', label = 'LeakyReLU')\nplt.plot(z, dLeakyReLU(LeakyReLU(z)),'r', label=r'$ \\frac{dLeakyReLU}{dz}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.ylim(0,4)\nplt.xlim(-4,4)\nplt.show()\n\n\n\n\n\n\nComparison of derivative for activation functions\n\nplt.plot(z, dsigmoid(sigmoid(z)),label = r'$ \\frac{dsigmoid}{dz}$' )\nplt.plot(z, dtanh(tanh(z)), label = r'$ \\frac{dtanh}{dz}$')\nplt.plot(z, dReLU(ReLU(z)), label=r'$ \\frac{dReLU}{dz}$')\nplt.plot(z, dLeakyReLU(LeakyReLU(z)), label=r'$ \\frac{dLeakyReLU}{dz}$')\nplt.legend(fontsize = 12)\nplt.xlabel('z')\nplt.title('Derivatives of activation functions')\nplt.show()"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html",
    "href": "posts/2022-12-28-small_molecule_resources.html",
    "title": "Small Molecules Resources",
    "section": "",
    "text": "Last update: 15th August 2023"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#noteworthy-blogs-to-follow",
    "href": "posts/2022-12-28-small_molecule_resources.html#noteworthy-blogs-to-follow",
    "title": "Small Molecules Resources",
    "section": "Noteworthy blogs to follow:",
    "text": "Noteworthy blogs to follow:\n\nPatrick Walters Blog on Cheminformatics\n\nPat Walter’s Cheminformatics Resources list\n\nIs Life Worth Living\nAndrew White’s ML for Molecules and Materials Online Book\nCheminformia\nDepth-First\nDrugDiscovery.NET - Andreas Bender\nDrugHunter - Dennis Hu\nPractical Fragments\nDerek Lowe’s In the Pipeline"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#online-resources",
    "href": "posts/2022-12-28-small_molecule_resources.html#online-resources",
    "title": "Small Molecules Resources",
    "section": "Online resources",
    "text": "Online resources\n\nAndrea Volkmer, TeachOpenCADD: a teaching platform for computer-aided drug design (CADD) - Highly recommended.\nPatrick Walter’s Cheminformatics Tutorials\nPat Walters’ RSC CICAG Open Source Tools for Chemistry.Video. Github\nPen’s Python cookbook for Cheminformatics\nChem LibreText collection from ACS Division of Chemical Education"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#books",
    "href": "posts/2022-12-28-small_molecule_resources.html#books",
    "title": "Small Molecules Resources",
    "section": "Books",
    "text": "Books\n\nBajorath, 2011. Chemoinformatics and Computational Chemical Biology. Methods in Molecular Biology.\nHeifetz, Alexander. (Ed.) (2022). “Artificial Intelligence in Drug Design.”"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#best-practices",
    "href": "posts/2022-12-28-small_molecule_resources.html#best-practices",
    "title": "Small Molecules Resources",
    "section": "Best practices",
    "text": "Best practices\n\nBender, Andreas, et al. “Evaluation guidelines for machine learning tools in the chemical sciences.” Nature Reviews Chemistry (2022): 1-15.. Temporary SharedIt Link\n\nNice account outlining guidelines for evaluating different AI/ML methodologies in molecular science. They propose a checklist of tests and best practices to assess the practicality and importance of different methodologies thereby providing a framework on how to evaluate plethora of ML workflows being proposed in different areas of chemical science. The basis for not overlooking the older non-ML method when evaluating the ‘new’ learning-based method, emphasis on model interpretation to translate the corrleation to chemical causality and finally\n\nArtrith, Nongnuch, et al. “Best practices in machine learning for chemistry.” Nature chemistry 13.6 (2021): 505-508.\n\nSet of rules, considerations, and caveats to keep in mind when designing ML model for chemical science. The authors propose a checklist when evaluating ML models, while intuitive at first, when lot of the new ML papers are scanned through that lens, you can identify the shortcommings of the proposed model. This checklist is especially helpful for those entering just entering the field."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#reviews",
    "href": "posts/2022-12-28-small_molecule_resources.html#reviews",
    "title": "Small Molecules Resources",
    "section": "Reviews",
    "text": "Reviews\n\nF. Strieth-Kalthoff, F. Sandfort, M. H. S. Segler, and F. Glorius, Machine learning the ropes: principles, applications and directions in synthetic chemistry, Chem. Soc. Rev\n\nPedagogical account of various machine learning techniques, models, representation schemes from perspective of synthetic chemistry. Covers different applications of machine learning in synthesis planning, property prediction, molecular design, and reactivity prediction\n\nRodríguez-Pérez, Raquel, Filip Miljković, and Jürgen Bajorath. “Machine Learning in Chemoinformatics and Medicinal Chemistry.” Annual review of biomedical data science 5 (2022)\nMariia Matveieva & Pavel Polishchuk. Benchmarks for interpretation of QSAR models. Github. Patrick Walter’s blog on the paper.\n\nPaper outlining good practices for interpretating QSAR (Quantative Structure-Property Prediction) models. Good set of heuristics and comparison in the paper in terms of model interpretability. Create 6 synthetic datasets with varying complexity for QSAR tasks. The authors compare interpretability of graph-based methods to conventional QSAR methods. In regards to performance graph-based models show low interpretation compared to conventional QSAR method.\n\nW. Patrick Walters & Regina Barzilay. Applications of Deep Learning in Molecule Generation and Molecular Property Prediction\n\nRecent review summarising the state of the molecular property prediction and structure generation research. In spite of exciting recent advances in the modeling efforts, there is a need to generate better (realistic) training data, assess model prediction confidence, and metrics to quantify molecular generation performance.\n\nKeith, John A., et al. “Combining machine learning and computational chemistry for predictive insights into chemical systems.” Chemical reviews 121.16 (2021): 9816-9872.\n\nIn-depth account of the machine learning and computational methods used in material science and small molecules. Nice introduction to the mathematics and theory behind first-principles based methods.\n\nNavigating through the Maze of Homogeneous Catalyst Design with Machine Learning\nColey, C. W. Defining and Exploring Chemical Spaces. Trends in Chemistry 2020\nApplications of Deep learning in molecular generation and molecular property prediction\nUtilising Graph Machine Learning within Drug Discovery and Development\nMachine learning directed drug formulation development\n\nReview from Aspuru-Guzik and Allen’s group discussing how ML can be leveraged for various tasks in drug formulation tasks."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#industry-focused-drug-discovery-reviews",
    "href": "posts/2022-12-28-small_molecule_resources.html#industry-focused-drug-discovery-reviews",
    "title": "Small Molecules Resources",
    "section": "Industry-focused drug discovery reviews",
    "text": "Industry-focused drug discovery reviews\n\nJayatunga, Madura KP, et al. “AI in small-molecule drug discovery: A coming wave.” Nat. Rev. Drug Discov 21 (2022): 175-176.\nAbramov, Yuriy A., Guangxu Sun, and Qun Zeng. “Emerging Landscape of Computational Modeling in Pharmaceutical Development.” Journal of Chemical Information and Modeling (2022).\n\nOverview of methods and scope of computational methods used in the drug development process.\n\nDragovich, Peter S., et al. “Small-Molecule Lead-Finding Trends across the Roche and Genentech Research Organizations.” Journal of Medicinal Chemistry (2022).\nA. Bender and I. Cortés-Ciriano, “Artificial intelligence in drug discovery: what is realistic, what are illusions? Part 1: Ways to make an impact, and why we are not there yet,” Drug Discov. Today, vol. 26, no. 2, pp. 511–524, 2021\nA. H. Göller et al., “Bayer’s in silico ADMET platform: a journey of machine learning over the past two decades,” Drug Discov. Today, vol. 25, no. 9, pp. 1702–1709, 2020.\nJ. Shen and C. A. Nicolaou, “Molecular property prediction: recent trends in the era of artificial intelligence,” Drug Discov. Today Technol., vol. 32–33, no. xx, pp. 29–36, 2019.\nMervin, L. H., Johansson, S., Semenova, E., Giblin, K. A., & Engkvist, O. (2021). Uncertainty quantification in drug design. Drug discovery today, 26(2), 474-489.\nCongreve, Miles, et al. “Recent developments in fragment-based drug discovery.” Journal of medicinal chemistry 51.13 (2008): 3661-3680."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#special-journal-issues",
    "href": "posts/2022-12-28-small_molecule_resources.html#special-journal-issues",
    "title": "Small Molecules Resources",
    "section": "Special Journal Issues",
    "text": "Special Journal Issues\n\nNice collection of recent papers in Nature Communications on ML application and modeling\nData Science Meets Chemistry\n\nThis issue includes contributions that demonstrate the profound impact data science techniques have had in chemistry including chemical and materials synthesis, catalyst and materials design, and overhauling the models used in traditional theoretical or computational chemistry.\n\nJournal of Medicinal Chemistry compendium of AI in Drug discovery issue\nAccount of Chemical Research Special Issue on advances in data-driven chemistry research\nSpecial Issue on Reaction Informatics and Chemical Space, Journal of Chemical Information and Modeling (2022)"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#meeting-notes",
    "href": "posts/2022-12-28-small_molecule_resources.html#meeting-notes",
    "title": "Small Molecules Resources",
    "section": "Meeting notes",
    "text": "Meeting notes\n\nWarr, W. (2021). National Institutes of Health (NIH) Workshop on Reaction Informatics\nWarr, W. (2021). Report on an NIH Workshop on Ultralarge Chemistry Databases."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#chemical-modalities",
    "href": "posts/2022-12-28-small_molecule_resources.html#chemical-modalities",
    "title": "Small Molecules Resources",
    "section": "Chemical modalities",
    "text": "Chemical modalities\n\nBlanco, Maria-Jesus, and Kevin M. Gardinier. “New chemical modalities and strategic thinking in early drug discovery.” ACS medicinal chemistry letters 11.3 (2020): 228-231.\n\nOverview of different chemical modalities currently at work to address different disease targets. The article addresses the small molecule medicinal chemists and how they can expand their outlook of small molecules to include other molecular entities when considering the angle of attack for different target engagement strategies. The authors offer a nice set of tools and thought process when selecting possible drug modalities for different target classes and what questions should be asked when zeroing in a possible mode of action."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#meta-themes-on-optimizing-small-molecules",
    "href": "posts/2022-12-28-small_molecule_resources.html#meta-themes-on-optimizing-small-molecules",
    "title": "Small Molecules Resources",
    "section": "Meta themes on optimizing small molecules",
    "text": "Meta themes on optimizing small molecules\n\nWalters, W. Patrick, and Mark A. Murcko. “Prediction of ‘drug-likeness’.” Advanced drug delivery reviews 54.3 (2002): 255-271.\nVeber, Daniel F., et al. “Molecular properties that influence the oral bioavailability of drug candidates.” Journal of medicinal chemistry 45.12 (2002): 2615-2623.\n\nRetrospective analysis on factors influencing the bioavailability of drug candidates. Authors find rotatable bonds and polar surface area or hydrogen bond count (sum of donor and accpetors) found to be important predictors of good oral bioavailability. Compounds having <10 rotatable bonds and <140 A (or < 12 hydrogen bonds) have good chances of being orally bioavailable.\n\nDeGoey, David A., et al. “Beyond the rule of 5: lessons learned from AbbVie’s drugs and compound collection: miniperspective.” Journal of Medicinal Chemistry 61.7 (2017): 2636-2651.\n\nAB-MPS calculated using cLogD, the number of aromatic rings (nAr), and the number of rotatable bonds (nRotB) according to the formula AB-MPS = Abs(cLogD −3) + nAr + nRotB. The lower the AB-MPS score, the more likely the compound is to be absorbed, and a value of ≤14 is reported to predict a higher probability of oral absorption.\n\nPoongavanam, Vasanthanathan, Bradley C. Doak, and Jan Kihlberg. “Opportunities and guidelines for discovery of orally absorbed drugs in beyond rule of 5 space.” Current Opinion in Chemical Biology 44 (2018): 23-29.\n\nHueristics for oral bioavailability of molecules that are violating the rule of 5. MW may reach up to approximately 1000 Da provided that TPSA increases proportionally up to 250 Å2. In contrast, cLogP and HBDs must be carefully controlled at high MW. Our lack of ability to predict compound conformations and flexibility is currently a hurdle that is critical to overcome to enable further prospective design in oral bRo5 space.\n\nTaylor, R. D.; MacCoss, M.; Lawson, A. D. G. Rings in Drugs. J. Med. Chem. 2014, 57 (14), 5845–5859. https://doi.org/10.1021/jm4017625.\nSubbaiah, Murugaiah AM, and Nicholas A. Meanwell. “Bioisosteres of the phenyl ring: Recent strategic applications in lead optimization and drug design.” Journal of Medicinal Chemistry 64.19 (2021): 14046-14128.\n\nLooks at biosteric replacements for the phenyl rings in the lead optimization phase. Phenyl rings results in improve potency but have poor solubility and lipophilicitty. Find biosteres can be used to improve them.\n\nErtl, Peter. “Magic Rings: Navigation in the Ring Chemical Space Guided by the Bioactive Rings.” Journal of Chemical Information and Modeling (2021).\n\nAnalyze the nature of rings which appear in bioactive compounds. Ring systems are systematically extracted from one billion molecules and are analyzed to discover a structure or correlation in the bioactivity and type of rings. No simple set of structural descriptors separating active and inactive rings could be identified, the separation is best described by a neural network model taking into account a complex combination of many substructure features.\n\nHartung, Ingo V., Bayard R. Huck, and Alejandro Crespo. “Rules were made to be broken.” Nature Reviews Chemistry 7.1 (2023): 3-4.\n\nLongitudinal analysis of physico-chemical properties for approved drugs in the clinic. They show that most of the drugs flout most of the Lipinski’s rule of 5 except the HBD which is always consistently less 4. In addition, they show that in recent times, by categorizing the drugs in different time-bound classes, the mean MW and HBA has increased but mean HBD has constantly stayed less than 2."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#synthesis-chemistry",
    "href": "posts/2022-12-28-small_molecule_resources.html#synthesis-chemistry",
    "title": "Small Molecules Resources",
    "section": "Synthesis Chemistry",
    "text": "Synthesis Chemistry\nCatalog of recent research articles that look at synthesis chemistry from a point of view of computational workflows, how traditional synthetic chemistry methods can be combined with informatics to augment drug discovery and synthesis processes.\n\nRuck, Rebecca T., Neil A. Strotman, and Shane W. Krska. “The Catalysis Laboratory at Merck: 20 Years of Catalyzing Innovation.” ACS Catalysis 13 (2022): 475-503.\nDreher, Spencer D., and Shane W. Krska. “Chemistry informer libraries: Conception, early experience, and role in the future of cheminformatics.” Accounts of Chemical Research 54.7 (2021): 1586-1596.\n\nCurated set of substrates to quickly assess the practicality of synthetic methods with the complete capture of success and failure, that can optimize reaction conditions with a broader scope with respect to relevant applications.\n\nCampos, Kevin R., et al. “The importance of synthetic chemistry in the pharmaceutical industry.” Science 363.6424 (2019): eaat0805.\nLate-stage diversification of indole skeletons through nitrogen atom insertion\nLenci, Elena, and Andrea Trabocchi. “Smart Design of Small‐Molecule Libraries: When Organic Synthesis Meets Cheminformatics.” ChemBioChem 20.9 (2019): 1115-1123."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#large-chemical-libraries-and-virtual-screening",
    "href": "posts/2022-12-28-small_molecule_resources.html#large-chemical-libraries-and-virtual-screening",
    "title": "Small Molecules Resources",
    "section": "Large chemical libraries and Virtual Screening",
    "text": "Large chemical libraries and Virtual Screening\nOver the past few years several entites offering ultra-large ensembles of chemical libraries which can be made on-demand or purchased immediately have emerged. The existence of such services has reinvigorated the field of virtual screening and combinatorial library design. In addition, research groups have devised novel ways to navigate these libraries, more efficiently and also understand the differences in the chemical space these library cover. Following are some of the key papers in the field.\n\nWarr, W. (2021). Report on an NIH Workshop on Ultralarge Chemistry Databases.\nWarr, Wendy A., et al. “Exploration of ultralarge compound collections for drug discovery.” Journal of Chemical Information and Modeling 62.9 (2022): 2021-2034.\nThe next level in chemical space navigation: going far beyond enumerable compound libraries\nBellmann, Louis, et al. “Comparison of combinatorial fragment spaces and its application to ultralarge make-on-demand compound catalogs.” Journal of Chemical Information and Modeling 62.3 (2022): 553-566.\n\nSpaceCompare: calculation of the overlap of large, nonenumerable combinatorial fragment spaces, utilizes topological fingerprints and the combinatorial character of these chemical spaces. Enamine’s REAL Space, WuXi’s GalaXi Space, and Otava’s CHEMriya. The overlap of the commercial make-on-demand catalogs is only in the low single-digit percent range, despite their large overall size.\n\nKonze, Kyle D., et al. “Reaction-based enumeration, active learning, and free energy calculations to rapidly explore synthetically tractable chemical space and optimize potency of cyclin-dependent kinase 2 inhibitors.” Journal of chemical information and modeling 59.9 (2019): 3782-3793.\n\nPathFinder uses retrosynthetic analysis followed by combinatorial synthesis to generate novel compounds in synthetically accessible chemical space.\n\nIrwin, John J., et al. “ZINC20—a free ultralarge-scale chemical database for ligand discovery.” Journal of chemical information and modeling 60.12 (2020): 6065-6073.\n\nNew version of ZINC with two major new features: billions of new molecules and new methods to search them. As a fully enumerated database, ZINC can be searched precisely using explicit atomic-level graph-based methods. Over 97% of the core Bemis–Murcko scaffolds in make-on-demand libraries are unavailable from “in-stock” collections. Correspondingly, the number of new Bemis–Murcko scaffolds is rising almost as a linear fraction of the elaborated molecules. Thus, an 88-fold increase in the number of molecules in the make-on-demand versus the in-stock sets is built upon a 16-fold increase in the number of Bemis–Murcko scaffolds. The make-on-demand library is also more structurally diverse than physical libraries\n\nNeumann, Alexander, Lester Marrison, and Raphael Klein. “Relevance of the Trillion-Sized Chemical Space “eXplore” as a Source for Drug Discovery.” ACS Medicinal Chemistry Letters (2023).\n\nThe authors examine the composition of the recently published and, so far, biggest chemical space, “eXplore”, which comprises approximately 2.8 trillion virtual product molecules. The utility of eXplore to retrieve interesting chemistry around approved drugs and common Bemis Murcko scaffolds has been assessed with several methods (FTrees, SpaceLight, SpaceMACS). Further, the overlap between several vendor chemical spaces and a physicochemical property distribution analysis has been performed. Despite the straightforward chemical reactions underlying its setup, eXplore is demonstrated to provide relevant and, most importantly, easily accessible molecules for drug discovery campaigns.\n\nMedina, Jorge, and Andrew D. White. “Bloom filters for molecules.” arXiv preprint arXiv:2304.05386 (2023).\n\nThis paper proposes and studies Bloom filters for testing if a molecule is present in a set using either string or fingerprint representations. Bloom filters are small enough to hold billions of molecules in just a few GB of memory and check membership in sub-milliseconds. The authors found string representations can have a false positive rate below 1% and require significantly less storage than using fingerprints. Canonical SMILES with Bloom filters with the simple FNV hashing function provide fast and accurate membership tests with small memory requirements. They provide a general implementation and specific filters for detecting if a molecule is purchasable, patented, or a natural product according to existing databases at https://github.com/whitead/molbloom.\nVirtual screeening\n\nLyu, Jiankun, et al. “Ultra-large library docking for discovering new chemotypes.” Nature 566.7743 (2019): 224-229.\n\nResearchers at UCSF looking at large scale docking for making ultra-large libraries accessible. They dock 170 million make-on-demand compounds from 130 well characterized reactions. Found new chemotypes that have interaction with 2 targets.\n\nSadybekov, Anastasiia V., and Vsevolod Katritch. “Computational approaches streamlining drug discovery.” Nature 616.7958 (2023): 673-685.\n\nNice review on virtual screening workflow for streamlining drug discovery\n\nMüller, Janis, et al. “Magnet for the needle in haystack:“crystal structure first” fragment hits unlock active chemical matter using targeted exploration of vast chemical spaces.” Journal of Medicinal Chemistry 65.23 (2022): 15663-15678.. Blog\n\nThe authors use a fragment screening approach to look at hits for protein kinase target and instead of using biophysical assay in fragment screening use crystallographic data directly to learn the conformation of the fragments. They find 4 ‘seed’ substructures which fit nicely in the protein(not affinity) and use those to inform the latter expansion which is done through the Enamine REAL dataset and known reaction classes. What I liked the most and found interesting is the high throughput binding pose and docking workflow of 200k compounds, the large scale crystallographic fragment hit analysis, and the focused curated library generation using Enamine REAL dataset. I was curious to know what seasoned experts had to say about this."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#binding-free-energetic-calculations",
    "href": "posts/2022-12-28-small_molecule_resources.html#binding-free-energetic-calculations",
    "title": "Small Molecules Resources",
    "section": "Binding free energetic calculations",
    "text": "Binding free energetic calculations\n\nXu, Huafeng. “The slow but steady rise of binding free energy calculations in drug discovery.” Journal of Computer-Aided Molecular Design (2022): 1-8.\nThompson, James, et al. “Optimizing active learning for free energy calculations.” Artificial Intelligence in the Life Sciences 2 (2022): 100050.\nPitman, Mary, et al. “To Design Scalable Free Energy Perturbation Networks, Optimal Is Not Enough.” (2022).\nGanguly, Abir, et al. “AMBER Drug Discovery Boost Tools: Automated Workflow for Production Free-Energy Simulation Setup and Analysis (ProFESSA).” Journal of Chemical Information and Modeling (2022)."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#cheminformatics-focus",
    "href": "posts/2022-12-28-small_molecule_resources.html#cheminformatics-focus",
    "title": "Small Molecules Resources",
    "section": "Cheminformatics-focus",
    "text": "Cheminformatics-focus\nCatalog of recent reviews and manuscripts I have found useful when learning more about the state-of-the-art in Cheminformatics. I’ve tried to categorize them roughly based on their area of application:\n\nRepresentation\nSmall molecules to be understood by computers and used for model training have to represented in a form amenable for optimization. In addition, this form of abstraction much capture appropriate level of chemical properties so as to imbue the data-driven models with necessary chemistry and physics for modeling. A lot of times different properties of the molecules are ‘lost in translation’ or obfuscated when converting them into machine-ready forms. Formerly the process of converting molecules from one form to another is called featurization. There are different forms, methods, theories to encode the molecules. Broadly there are as follows: * Fingerprints * Descriptors * Pharmacophores * Graph-based * Natural language-based * Shape-based\nReviews\n\nRepresentation of Molecules in NN: Molecular representation in AI-driven drug discovery: review and guide\nScreening of energetic molecules – comparing different representations\n\nArticles\n\nM. Krenn, F. Hase, A. Nigam, P. Friederich, and A. Aspuru-Guzik, “Self-Referencing Embedded Strings (SELFIES): A 100% robust molecular string representation,” Mach. Learn. Sci. Technol., pp. 1–9, 2020\nCould graph neural networks learn better molecular representation for drug discovery? A comparison study of descriptor-based and graph-based models\n\nComparative study of descriptor-based and graph-based models using public data set. Used descriptor-based models (XGBoost, RF, SVM, using ECFP) and compared them to graph-based models (GCN, GAT, AttentiveFP, MPNN). They show descriptor-based models outperform the graph-based models in terms of prediction accuracy and computational efficiency with SVM having best predictions. Graph-based methods are good for multi-task learning.\n\n\nPredictive modeling\n\nFang, Xiaomin, et al. “Geometry-enhanced molecular representation learning for property prediction.” Nature Machine Intelligence (2022): 1-8.\n\nSelf-supervised learning using special type of GNN architecture (GeoGNN) that includes molecule geometric / spatial information. Geometry-enhanced molecular representation learning method (GEM). The model achieves SOTA performance on 14 of 15 public classification and regression datasets.\n\nYang, K., Swanson, K., Jin, W., Coley, C., Eiden, P., Gao, H., Guzman-Perez, A., Hopper, T., Kelley, B., Mathea, M. and Palmer, A., 2019. Analyzing learned molecular representations for property prediction. Journal of chemical information and modeling, 59(8), pp.3370-3388\n\nBenchmark property prediction models on 19 public and 16 proprietary industrial data sets spanning a wide variety of chemical end points. Introduce a modeling framework (Chemprop) that consistently matches or outperforms models using fixed molecular descriptors as well as previous graph neural architectures on both public and proprietary data sets.\n\nStuyver, T. and Coley, C.W., 2021. Quantum chemistry-augmented neural networks for reactivity prediction: Performance, generalizability and interpretability. arXiv preprint arXiv:2107.10402\n\nCombine structure (Graph-networks) and descriptor based features (QM-derived) to predict activation energies (E2/SN2 barrier height prediction) and regioselectivity. Incorporating QM and structure leads to better overall accuracy and generalizability even in low data regions. Atom and bond level features derived using QM and used in the model generation with a smaller dataset.\n\nSystematic Evaluation of Local and Global Machine Learning Models for the Prediction of ADME Properties\n\nAuthors provide an evaluation of global and local models for ADME endpoint prediction. They compare the performance of global models and domain-specific local models. 10 different asays and 112 drug discovery projects were analyzed. The results showed consistent superior performance of global ADME models for property prediction. Performance improvement of global models over project-wise local models ranged from 3% to 25% in MAE. Local model improvements higher than 20% were achieved for only 7% of the assay-project pairs.\n\n\nQSAR benchmarks\n\nExposing the Limitations of Molecular Machine Learning with Activity Cliffs\n\nAccount on how to treat and analyze activity cliffs in context of developing a predictive model. The authors outline best practices to probe activity cliffs. They show, using 24 DL and ML models and 30 targets, ML approaches based on molecular descriptors outperformed more complex deep learning methods. Activity cliff pairs were defined on similarity of the molecule SMILES and the bioactivity difference. Compared to most traditional machine learning approaches, deep neural networks seem to fall short at picking up subtle structural differences (and the corresponding property change) that give rise to activity cliffs.\n\nMoleculeNet: a benchmark for molecular machine learning (rsc.org)\nLarge-scale comparison of machine learning methods for drug target prediction on ChEMBL - Chemical Science (RSC Publishing)\nBeyond the hype: deep neural networks outperform established methods using a ChEMBL bioactivity benchmark set, Journal of Cheminformatics\n\n\n\nEnumeration of chemical space\n\nBellmann, Louis, et al. “Comparison of Combinatorial Fragment Spaces and Its Application to Ultralarge Make-on-Demand Compound Catalogs.” Journal of Chemical Information and Modeling (2022).\n\nAuthors propose an algorithmic approach called as SpaceCompare to calculate overlap and diversity of the ultra-large combinatorial chemical libraries. The tool uses topological fragment spaces to capture the subtlties of the reaction having same product but different reactant substructures.\n\nNicolaou, Christos A., et al. “The proximal lilly collection: Mapping, exploring and exploiting feasible chemical space.” Journal of chemical information and modeling 56.7 (2016): 1253-1266.\nZabolotna, Y., et al. (2021). “SynthI: A New Open-Source Tool for Synthon-Based Library Design.” Journal of Chemical Information and Modeling.\n\nInteresting work on de-novo design of molecules wherein, the molecules being created are made up from the fragments that is known to exist and are available to the user. New molecules are generated based on the fragmented (synthons) made available in the dataset.\n\nFully Automated Creation of Virtual Chemical Fragment Spaces Using the Open-Source Library OpenChemLib\n\nOpen-source tool to generate synthetically accessible chemical spaces using reaction definitions and building blocks. Virtual fragments are generated using one-step reaction and real-world building blocks - the workflow also support 2-3 steps creation.\n\n\nChemical-space exploration\n\nZabolotna, Yuliana, et al. “NP navigator: a new look at the natural product chemical space.” Molecular informatics 40.9 (2021): 2100068..\n\nOrganizing the chemical space of ChEMBL, and ZINC to compare its overlap with natural products through COCONUT. Generative Topological Mapping is used for the clustering and analysis. Helpful overview of the method with its application to drug discovery can be found here\n\n\nMatched molecular-pair*\n\nRaymond, John W., and Peter Willett. “Maximum common subgraph isomorphism algorithms for the matching of chemical structures.” Journal of computer-aided molecular design 16.7 (2002): 521-533.\nDalke, Andrew, Jerome Hert, and Christian Kramer. “mmpdb: An open-source matched molecular pair platform for large multiproperty data sets.” Journal of chemical information and modeling 58.5 (2018): 902-910.\n\n\n\nExplainable/Interpretable Machine Learning\nReviews/Perspectives\n\nWellawatte, Geemi P., et al. “A Perspective on Explanations of Molecular Prediction Models.” (2022).\nRodríguez-Pérez, Raquel, and Jürgen Bajorath. “Explainable Machine Learning for Property Predictions in Compound Optimization.” Journal of medicinal chemistry 64.24 (2021): 17744-17752\n\nArticles\n\nWellawatte, Geemi P., Aditi Seshadri, and Andrew D. White. “Model agnostic generation of counterfactual explanations for molecules.” (2021).\nMatveieva, Mariia, and Pavel Polishchuk. “Benchmarks for interpretation of QSAR models.” Journal of cheminformatics 13.1 (2021): 1-20. Patrick Walter’s blog\n\n\n\nUncertainty quantification\n\nMervin, Lewis H., et al. “Uncertainty quantification in drug design.” Drug discovery today 26.2 (2021): 474-489.\nAlan Aspuru-Guzik perspective on uncertainty and confidence\nUncertainty Quantification Using Neural Networks for Molecular Property Prediction. J. Chem. Inf. Model. (2020) Hirschfeld, L., Swanson, K., Yang, K., Barzilay, R. & Coley, C. W.\n\nBenchmark different models and uncertainty metrics for molecular property prediction.\n\nEvidential Deep learning for guided molecular property prediction and disocovery Ava Soleimany, Conor Coley, et. al.. Slides\n\nTrain network to output the parameters of an evidential distribution. One forward-pass to find the uncertainty as opposed to dropout or ensemble - principled incorporation of uncertainties\n\nDifferentiable sampling of molecular geometries with uncertainty-based adversarial attacks\nJ. P. Janet, S. Ramesh, C. Duan, H. J. Kulik, ACS Cent. Sci. 2020\n\nConduct a global multi-objective optimization with expected improvement criterion. Find transition metal complex redox couples for Redox flow batteries that address stability, solubility, and redox potential metric. Use distance of a point from a training data in latent space as a metric to quantify uncertainty.\n\nJ. P. Janet, C. Duan, T. Yang, A. Nandy, H. J. Kulik, Chem. Sci. 2019, 10, 7913–7922\n\nDistance from available data in NN latent space is used as a variable for low-cost, quantitative uncertainty metric that works for both inorganic and organic chemistry. Introduce a technique to calibrate latent distances enabling conversion of distance-based metric to error estimates in units of predicted property\n\n\nActive Learning\nActive learning provides strategies for efficient screening of subsets of the library. In many cases, we can identify a large portion of the most promising molecules with a fraction of the compute cost.\n\nGraff, David E., Eugene I. Shakhnovich, and Connor W. Coley. “Accelerating high-throughput virtual screening through molecular pool-based active learning.” Chemical science 12.22 (2021): 7866-7881.\n\nArticle talks about MolPAL as an active learning methodology. The team explores the application of these techniques to computational docking datasets and assess the impact of surrogate model architecture, acquisition function, and acquisition batch size on optimization performance. We observe significant reductions in computational costs; for example, using a directedmessage passing neural network we can identify 94.8% or 89.3% of the top-50 000 ligands in a 100M member library after testing only 2.4% of candidate ligands using an upper confidence bound or greedy acquisition strategy, respectively.\n\nThompson, James, et al. “Optimizing active learning for free energy calculations.” Artificial Intelligence in the Life Sciences 2 (2022): 100050.\n\nArticle exploring different active learning strategies for looking at sampling the congeneric RBFE calculations. The paper explores the impact of several AL design choices. They show that in their case, the overall AL performance is largely insensitive to the specific ML method and acquisition functions used. The significant factor affecting the performance was the number of molecules sampled at each iteration.\n\nReker, D. Practical Considerations for Active Machine Learning in Drug Discovery. Drug Discov. Today Technol. 2020\nJanet, J. P., Ramesh, S., Duan, C., & Kulik, H. J. (2020). Accurate multiobjective design in a space of millions of transition metal complexes with neural-network-driven efficient global optimization. ACS central science, 6(4), 513-524.\nA. P. Soleimany, A. Amini, S. Goldman, D. Rus, S. N. Bhatia, and C. W. Coley, “Evidential Deep Learning for Guided Molecular Property Prediction and Discovery,” ACS Cent. Sci., Jul. 2021.. Slideshare\n\nTrain property prediction model to output a distribution statistics in single pass that describes the uncertainty. This is in contrast to using ensemble models like MC dropout. Interesting way to estimate the epistemic (due to / from model) uncertainty in the prediction. Use this approach on antibiotic search problem of Stokes et. al. Compare Chemprop and SchNet models on different tasks.\n\n\nTransfer Learning\nReviews\n\nCai, Chenjing, et al. “Transfer learning for drug discovery.” Journal of Medicinal Chemistry 63.16 (2020): 8683-8694.\n\nArticles\n\nApproaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning\n\nTransfer learning by training a network to DFT data and then retrain on a dataset of gold standard QM calculations (CCSD(T)/CBS) that optimally spans chemical space. The resulting potential is broadly applicable to materials science, biology, and chemistry, and billions of times faster than CCSD(T)/CBS calculations.\n\nImproving the generative performance of chemical autoencoders through transfer learning\n\n\n\nMeta Learning\n\nAltae-Tran, H., Ramsundar, B., Pappu, A. S., & Pande, V. (2017). Low data drug discovery with one-shot learning. ACS central science, 3(4), 283-293.\n\nAuthors demonstrate how one-shot learning can be used to signifinicantly lower the amount of data required to make predictions in drug discovery tasks. LSTM combined with GCNNs is shown to improve learning capabilities of the model. In the simplest one-shot learning formalism these continuous vectors are then fed into a simple nearest-neighbor classifier that labels new examples by distance-weighted combination of support set labels\n\nNguyen, C. Q., Kreatsoulas, C., & Branson, K. M. (2020). Meta-learning GNN initializations for low-resource molecular property prediction. arXiv preprint arXiv:2003.05996.\n\nUse CheMBL dataset to train a gated graph neural network (GGNN) for prediction and classification tasks using meta learning protocols. Show appreciable model performance even with just approx. 256 datapoints.\n\n\nFederated Learning\n\nSimm, Jaak, et al. “Splitting chemical structure data sets for federated privacy-preserving machine learning.” Journal of Cheminformatics 13.1 (2021): 1-14.\nMelloddy consortium\n\nConsortia comprising of leading resarch labs and companies working on decentralized datasets and predictive modeling of biochemical and cellular activity."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#generative-design",
    "href": "posts/2022-12-28-small_molecule_resources.html#generative-design",
    "title": "Small Molecules Resources",
    "section": "Generative design",
    "text": "Generative design\nReviews\n\nComment about generative design from Patrick Walters\nWalters, W. Patrick, and Mark Murcko. “Assessing the impact of generative AI on medicinal chemistry.” Nature biotechnology 38.2 (2020): 143-145.\n\nCorrespondence on assessing the impact of AI on medicinal chemistry. It is a well written account on practical implication of generative design on pharmaceutical research.They outline two recent cases of ‘success’ of AI generative design in drug discovery and give more context and propose best practices for furthering the development of algorithms and drug discovery pipelines.\n\nMouchlis VD, Afantitis A, Serra A, et al. Advances in de Novo Drug Design: From Conventional to Machine Learning Methods. Int J Mol Sci. 2021;22(4):1676. Published 2021 Feb 7. doi:10.3390/ijms22041676\nB. Sanchez-Lengeling and A. Aspuru-Guzik, “Inverse molecular design using machine learning: Generative models for matter engineering,” Science (80)., vol. 361, no. 6400, pp. 360–365, Jul. 2018\nMeyers, Joshua, Benedek Fabian, and Nathan Brown. “De novo molecular design and generative models.” Drug Discovery Today 26.11 (2021): 2707-2715.\n\nVery nice review of different atom-based, reaction-based, and fragment-based generative design workflows proposed by the community.\nBenchmarks\n\nFlam-Shepherd, Daniel, Kevin Zhu, and Alán Aspuru-Guzik. “Keeping it Simple: Language Models can learn Complex Molecular Distributions.” arXiv preprint arXiv:2112.03041 (2021).. Nature Comms Link\n\nTest SOTA language models and representation performance against graph-based methods (CGVAE, JTVAE) for ‘challenging’ generative modeling tasks - generate a molecule - property distribution as a function of synthetic feasiblity. Graph models faced chanllenge in generating large molcules (> 100 HAs). Selfies provided advantage here. All of the models seem to generate novel molecules - how practical each of these novel molecules are is yet an open question.\n\nMOSES - Benchmarking platform for generative models.\n\nPropose a platform to deploy and compare state-of-the-art generative models for exploring molecular space on same dataset. In addition the authors also propose list of metrics to evaluate the quality and diversity of the generated structures.\n\nGuacaMol: Benchmarking models for De Novo Molecular Design. Blogpost\n\nEvaluation framework from BenevolentAI to compare different de-novo design models.\n\nJ. Zhang, R. Mercado, O. Engkvist, and H. Chen, “Comparative Study of Deep Generative Models on Chemical Space Coverage,” J. Chem. Inf. Model., vol. 61, no. 6, pp. 2572–2581, Jun. 2021.\n\nInteresting analysis from team at AstraZeneca R&D. They look at the chemical space coverage accounted by the SOTA generative models. Proposes a metric for evaluating space coverage, and thereby comparing different SOTA models, using a reference data (GDB-13 in this case). The new metric computes how much of the GDB-13 dataset can be recovered by a model that is trained on small GDB subset. Generative models were trained on same 1M data points and 1B molecules were then sampled from each model. It was seen that at most 39% of the molecules in the parent dataset were sampled / generated by the model. Most models sampled the same compounds atleast twice. It was observed that graph-based model sampled much diverse molecules than string-based methods. Besides, the coverage of GAN-based models was worse compared to Language and Graph models.\n\nGao, W.; Coley, C. W. The Synthesizability of Molecules Proposed by Generative Models. J. Chem. Inf. Model. 2020\n\nThis paper looks at different ways of integrating synthesizability criteria into generative models.\n\nComparative analysis of graph traversal schemes for GraphINVENT\n\nBechmark work from AstraZeneca/MIT AI team to document different graph architecture schemes and algorithms for generative models.\nLanguage models:\n\nR. Gómez-Bombarelli et al., “Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules,” ACS Cent. Sci., vol. 4, no. 2, pp. 268–276, 2018\n\nOne of the first implementation of a variation auto-encoder for molecule generation\n\nPenalized Variational Autoencoder\nSELFIES and generative models using STONED\n\nRepresentation using SELFIES proposed to make it much more powerful\n\nReproducibility study of the STONED work from Jablonka et. al.\nLSTM based (RNN) approaches to small molecule generation. Github\nChithrananda, S.; Grand, G.; Ramsundar, B. ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction. arXiv [cs.LG], 2020.\nSMILES-based deep generative scaffold decorator for de-novo drug design. Github\n\nSMILES-based language model that generates molecules from scaffolds and can be trained from any arbitrary molecular set. Uses randomized SMILES to improve final prediction validity.\n\nIovanac, Nicolae C., Robert MacKnight, and Brett Savoie. “Actively Searching: Inverse Design of Novel Molecules with Simultaneously Optimized Properties.” ChemRxiv (2021)\n\nUsing quantum chemistry attributes calculated on-the-fly as scoring functions for sampling the generative model chemical space. Active learning strategy is deployed to explore the area of space where the properties of the molecules are unknown.\nGraph-based\n\nFlam-Shepherd, Daniel, Alexander Zhigalin, and Alán Aspuru-Guzik. “Scalable Fragment-Based 3D Molecular Design with Reinforcement Learning.” arXiv preprint arXiv:2202.00658 (2022)\n\nReinforcement learning-based generative model whici is an update on point cloud approach by the same group to now incorporate ‘grammar’ for building molecules in form of functional groups in 3D space.\n\nW. Jin, R. Barzilay, and T. Jaakkola, “Junction tree variational autoencoder for molecular graph generation,” 35th Int. Conf. Mach. Learn. ICML 2018, vol. 5, pp. 3632–3648, 2018\n\nJunction tree based decoding. Define a grammar for the small molecule and find sub-units based on that grammar to construct a molecule. The molecule is generated in two-steps: first being generating the scaffold or backbone of the molelcule, then the nodes are added with molecular substructure as identified from the ‘molecular grammar’.\n\nMPGVAE: Message passing graph networks for molecular generation, Daniel Flam-Shepherd et al 2021 Mach. Learn.: Sci. Technol.\n\nIntroduce a graph generation model by building a Message Passing Neural Network (MPNNs) into the encoder and decoder of a VAE (MPGVAE).\n\nConfVAE: End-to-end framework for molecular conformation generation via bilevel programming\n\nAlgorithm to predict 3D conforms from molecular graphs.\n\nGraphINVENT: R. Mercado, T. Rastemo, E. Lindelöf, G. Klambauer and O. Engkvist, “Graph networks for molecular design,” Mach. Learn. Sci. Technol., vol. 2, no. 2, p. 25023, 2021. Github. Blogpost\n\nGraphINVENT uses a tiered deep neural network architecture to probabilistically generate new molecules a single bond at a time.\n\nRL-GraphINVENT: Reinforcement learning-based variant of the above code.\n\nGANs\n\nMolGAN: An implicit generative model for small molecular graphs, N. De Cao and T. Kipf, 2018\n\nGenerative adversarial network for finding small molecules using graph networks, quite interesting. Avoids issues arising from node ordering that are associated with likelihood based methods by using an adversarial loss instead (GAN)\n\nLatentGAN: A de novo molecular generation method using latent vector based generative adversarial network\n\nMolecular generation strategy is described which combines an autoencoder and a GAN. Generator and discriminator network do not use SMILES strings as input, but instead n-dimensional vectors derived from the code-layer of an autoencoder trained as a SMILES heteroencoder that way syntax issues are expected to be addressed.\nScaffold-retained\n\nKaitoh, Kazuma, and Yoshihiro Yamanishi. “Scaffold-Retained Structure Generator to Exhaustively Create Molecules in an Arbitrary Chemical Space.” Journal of Chemical Information and Modeling (2022).\nMaziarz, Krzysztof, et al. “Learning to extend molecular scaffolds with structural motifs.” arXiv preprint arXiv:2103.03864 (2021).\n\nTeam at Novartis and Microsoft propose MoLeR, graph based model to generate molecule using scaffold as a seed. Scaffold based SAR speed up shown.\nReaction tranformation-based\nHere the idea is to constraint the molecules generated by the transformations amenable to a particular platform, like automated synthesis workflow.\n\nSeo, Seonghwan, Jaechang Lim, and Woo Youn Kim. “Molecular Generative Model via Retrosynthetically Prepared Chemical Building Block Assembly.” Advanced Science (2023): 2206674.\nBradshaw, John, et al. “Barking up the right tree: an approach to search over molecule synthesis dags.” Advances in neural information processing systems 33 (2020): 6852-6866.\nFialková, Vendy, et al. “LibINVENT: reaction-based generative scaffold decoration for in silico library design.” Journal of Chemical Information and Modeling 62.9 (2021): 2046-2063.\nNguyen, Dai Hai, and Koji Tsuda. “A generative model for molecule generation based on chemical reaction trees.” arXiv preprint arXiv:2106.03394 (2021).\n\nAuthors propose a generative model to generate molecules via multi-step chemical reaction trees, each campaign first generates a reaction-tree with template transformations as breaking points.\n\nBradshaw, John, et al. “A model to search for synthesizable molecules.” Advances in Neural Information Processing Systems 32 (2019).\n\n3D conformations-aware\n\nBolcato, Giovanni, Esther Heid, and Jonas Boström. “On the Value of Using 3D Shape and Electrostatic Similarities in Deep Generative Methods.” Journal of chemical information and modeling 62.6 (2022): 1388-1398.\n\nExtension to the fragment-based generative design model (DeepFMPO) using reinforcement learning now incorporating 3D electrostatic similarity in the analysis. Ability to replace fragment with similar 3D shape and electrostatics. ESP_sim tutorial for comparison of electrostatic potential and molecule shape is used for this purpose. The authors find scaffold-hopping bioisoteres for CDK2.\n\nImrie, Fergus, et al. “Deep generative design with 3D pharmacophoric constraints.” Chemical science 12.43 (2021): 14577-14589.\n\nMethod that combines GNNs with CNNs to incorporate 3D pharmacophoric constraints into molecular generation.\n\nImrie, Fergus, et al. “Deep generative models for 3D linker design.” Journal of chemical information and modeling 60.4 (2020): 1983-1995.\n\nInteresting work on designing linkers using conformation aware generative design algorithm. Think of it like fragment-growing.\nProtein-ligand interactions aware\n\nZhang, Jie, and Hongming Chen. “De novo molecule design using molecular generative models constrained by ligand–protein interactions.” Journal of Chemical Information and Modeling 62.14 (2022): 3291-3306.\n\nLinker design\n\nIgashov, Ilia, et al. “Equivariant 3d-conditional diffusion models for molecular linker design.” arXiv preprint arXiv:2210.05274 (2022).\nGuo, Jeff, et al. “Link-INVENT: Generative Linker Design with Reinforcement Learning.” (2022).. BlogPost\nImrie, Fergus, et al. “Deep generative models for 3D linker design.” Journal of chemical information and modeling 60.4 (2020): 1983-1995.. Blogpost\nNori, Divya, Connor W. Coley, and Rocío Mercado. “De novo PROTAC design using graph-based deep generative models.” arXiv preprint arXiv:2211.02660 (2022).\n\n\nComputer Aided Synthesis Planning (CASP)\nReviews:\n\nThakkar, Amol, et al. “Artificial intelligence and automation in computer aided synthesis planning.” Reaction chemistry & engineering 6.1 (2021): 27-51.\n\nPerspective on the current SOTA of synthesis planning, automation, and reaction optimization in drug discovery and development phases using AI and ML.\n\nMadzhidov, T. I., et al. (2021). “Machine learning modelling of chemical reaction characteristics: yesterday, today, tomorrow.” Mendeleev Communications 31(6): 769-780.\nJorner, K., et al. (2021). “Organic reactivity from mechanism to machine learning.” Nature Reviews Chemistry 5(4): 240-255.\nStruble, T. J., et al. (2020). “Current and Future Roles of Artificial Intelligence in Medicinal Chemistry Synthesis.” J Med Chem 63(16): 8667-8682\nZuranski, Andrzej M., et al. “Predicting reaction yields via supervised learning.” Accounts of chemical research 54.8 (2021): 1856-1865.\n\nPerspective on ML for organic chemistry reactivity prediction. Group uses DFT-derived physical features of the reaction molecules and conditions for representation. Small data set plus HTE experimentation dataset for yield estimation.\n\nThe Exploration of Chemical Reaction Networks\n\nPerspective article summarising their position on the current state of research and future considerations on developing better reaction network models. Break down the analysis of reaction networks as into 3 classes (1) Front Open End: exploration of products from reactants (2) Backward Open Start: Know the product and explore potential reactants (3) Start to End: Product and reactant known, explore the likely intermediates.\nNice summary of potential challenges in the field:\n\nValidating exploration algorithms on a consistent set of reaction system.\nNeed to generate a comparative metric to benchmark different algorithms.\n\nConsidering effect of solvents and/or protein embeddings in the analysis\n\nPrevious review article by same group: Exploration of Reaction Pathways and Chemical Transformation Networks\n\n\nTechnical details of various algorithms being implemented for reaction mechanism discovery at the time of writing the review.\nBest practices\n\nGimadiev, T. R., Lin, A., Afonina, V. A., Batyrshin, D., Nugmanov, R. I., Akhmetshin, T., … & Varnek, A. (2021). Reaction Data Curation I: Chemical Structures and Transformations Standardization. Molecular Informatics, 2100119.\n\nArticle from Varnek group on best practices on processing data for reaction informatics.\nBenchmarking\n\nGenheden S, Bjerrum E. PaRoutes: a framework for benchmarking retrosynthesis route predictions. ChemRxiv. Cambridge: Cambridge Open Engage; 2022. Github\n\nBenchmarking framework for comparing different multi-step retrosynthesis methods from researchers at AstraZeneca R&D. Provides 10k synthetic routes which can be used as a validation set for different methodologies, providing a platform for systematic comparison of different methods being proposed in the community.\nClassifying chemical reactions:\n\nSchneider, N., et al. (2015). “Development of a Novel Fingerprint for Chemical Reactions and Its Application to Large-Scale Reaction Classification and Similarity.” Journal of Chemical Information and Modeling 55(1): 39-53.\n\nUsing scrapped US Patent data to classify chemical reactions and deploy various fingerprints and ML models for classification.\n\nSchwaller, Philippe, et al. “Mapping the space of chemical reactions using attention-based neural networks.” Nature Machine Intelligence 3.2 (2021): 144-152.. rxnfp - Github. Preprint. News Article.\n\nTransformer-based model for reaction classification. Compared it with BERT. Besides classification, the work also formalizes the reaction fingerprint generation using the learned representations. The reaction fingerprints are visualized using TMAPS.\n\nProbst, Daniel, Philippe Schwaller, and Jean-Louis Reymond. “Reaction Classification and Yield Prediction Using the Differential Reaction Fingerprint DRFP.” ChemRxiv (2021)\nDelannée, V., Nicklaus, M.C. ReactionCode: format for reaction searching, analysis, classification, transform, and encoding/decoding. J Cheminform 12, 72 (2020)\nHeid, E; Green, W; Machine learning of reaction properties via learned representations of the condensed graph of reaction. ChemRxiv (2021)\n\nReaction classifiction prediction using atom-mapped reaction that are used to generate condensed reaction graphs and passed through a GCN-variant as implemented in chemprop.\nAtom mapping:\n\nLin, A., et al. (2021). “Atom-to-atom Mapping: A Benchmarking Study of Popular Mapping Algorithms and Consensus Strategies.”\n\nComparative analysis of different atom-mapping schemes for generating atom-mapped reaction features. Comments on the state of the art methods and their performance on a curated reaction database.\n\nExtraction of organic chemistry grammar from unsupervised learning of chemical reactions. RXMapper\n\nData-driven atom mapping schemes which uses transformers for learning the context of the chemical reaction. Researchers at IBM trained a flavor of language model based on Transformer architecture and used it to find reaction centers and maps atoms. Shown to be robust compared to other SOTA methods.\n\nAutomatic mapping of atoms across both simple and complex chemical reactions\n\nPredicting reaction outcomes:\n\nJin, Wengong, et al. “Predicting organic reaction outcomes with weisfeiler-lehman network.” Advances in neural information processing systems 30 (2017).\nC. W. Coley et al., “A graph-convolutional neural network model for the prediction of chemical reactivity,” Chem. Sci., vol. 10, no. 2, pp. 370–377, 2019.\n\nTemplate-free prediction of organic reaction outcomes using graph convolutional neural networks\n\nPrediction of Organic Reaction Outcomes Using Machine Learning, ACS Cent. Sci. 2017\nGuan, Y., et al. (2021). “Regio-selectivity prediction with a machine-learned reaction representation and on-the-fly quantum mechanical descriptors.” Chemical Science 12(6): 2198-2208\nSchwaller, P., et al. (2019). “Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction.” ACS Central Science 5(9): 1572-1583.\nSchwaller, P., et al. (2021). “Prediction of chemical reaction yields using deep learning.” Machine Learning: Science and Technology 2(1)\n\nRetrosynthetic routes:\n\nSchwaller, P., et al. (2020). “Predicting retrosynthetic pathways using transformer-based models and a hyper-graph exploration strategy.” Chemical Science 11(12): 3316-3325.\nComputational planning of the synthesis of complex natural products\nWatson, I. A., et al. (2019). “A retrosynthetic analysis algorithm implementation.” J Cheminform 11(1)\nSegler, Marwin HS, and Mark P. Waller. “Neural‐symbolic machine learning for retrosynthesis and reaction prediction.” Chemistry–A European Journal 23.25 (2017): 5966-5971.\n\nHybrid neural-symbolic approach for both retrosynthesis and reaction prediction that can be trained with large reaction sets from databases. Template extraction from known reaction datasets to classify new reaction to known reaction classes.\n\nFortunato, Michael E., et al. “Data augmentation and pretraining for template-based retrosynthetic prediction in computer-aided synthesis planning.” Journal of chemical information and modeling 60.7 (2020): 3398-3407.\n\nIn template-based retrosynthesis predictions, templates with few examples are excluded from training. This works talks on methods to augment the current set of data to account for the cases where examples for training are few.\n\nSeidl, Philipp, et al. “Improving Few-and Zero-Shot Reaction Template Prediction Using Modern Hopfield Networks.” Journal of chemical information and modeling 62.9 (2022): 2111-2120.\n\nIntroduce a template-based single-step retrosynthesis model based on Modern Hopfield Networks, which learn an encoding of both molecules and reaction templates in order to predict the relevance of templates for a given molecule. The model does not consider templates as distinct categories, but can leverage structural information about the template. The retrieval approach enables generalization across templates, which makes zero-shot learning possible and improves few-shot learning. On the single-step retrosynthesis benchmark USPTO-50k, the MHN model reaction reaches the state-of-the-art at top-k accuracy for k ≥ 3.\n\nTu, Zhengkai, and Connor W. Coley. “Permutation invariant graph-to-sequence model for template-free retrosynthesis and reaction prediction.” Journal of Chemical Information and Modeling (2021).\n\nGraph2SMILES, a template-free retrosynthesis model to predict reaction outcomes and retrosynthesis routes. This model eliminates the need for any input-side SMILES augmentation, while achieving noticeable improvements over Transformer baselines (especially for top-1 accuracy).\nGenerate reaction networks:\n\nM. Liu et al., “Reaction Mechanism Generator v3.0: Advances in Automatic Mechanism Generation,” J. Chem. Inf. Model., May 2021\n\nNewest version of RMG (v3) is updated to Python v3. It has ability to generate heterogeneous catalyst models, uncertainty analysis to conduct first order sensitivity analysis. RMG dataset for the thermochemical and kinetic parameters have been expanded.\n\nMore and Faster: Simultaneously Improving Reaction Coverage and Computational Cost in Automated Reaction Prediction Tasks\n\nPresents an algorithmic improvement to the reaction network prediction task through their YARP (Yet Another Reaction Program) methodology. Shown to reduce computational cost of optimization while improving the diversity of identified products and reaction pathways.\n\nMolecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction\n\nFollow-up: Quantitative interpretation explains machine learning models for chemical reaction prediction and uncovers bias\n\nAutomatic discovery of chemical reactions using imposed activation\nMachine learning in chemical reaction space\n\nLook at exploration of reaction space rather than compound space. SOAP kernel for representing the moelcules. Estimate atomization energy for the molecules using ML. Calculate the d(AE) for different ML-estimated AEs. Reaction energies (RE) are estimated and uncertainty propogation is used to estimate the errors. Uncorrelated constant error propogation. 30,000 bond breaking reaction steps Rad-6-RE network used. RE prediction is not as good as AE.\nEstimate molecular synthesizability\nThe idea of estimating whether a molecule is ‘synthesizable’ can be thought of from two areas: 1. Complexity based - compare the fragments in the molecule to the known fragments in the chemical space\n2. Full retrosynthesis based - entire route is considered for molecule generation. Reactant complexity drives route complexity.\n\nErtl, Peter, and Ansgar Schuffenhauer. “Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions.” Journal of cheminformatics 1.1 (2009): 1-11.. RDkit implementation\n\nSynthetic Accessbility score (SA_Score) is a popular heuristic score for quantifying synthesizability. It computes a score using a fragment-contribution approach, where rarer fragments (as judged by their abundance in the PubChem database of 1mil representative cmpds) are taken as an indication of lower synthesizability.\n\nColey, Connor W., et al. “SCScore: synthetic complexity learned from a reaction corpus.” Journal of chemical information and modeling 58.2 (2018): 252-261.. DeepChem implementation\n\nSCScore is a learned synthetic complexity score computed as a neural network model trained on reaction data from the Reaxys database. It was designed with synthesis planning in mind to operate on molecules resembling not just drug-like products but intermediates and simpler building blocks as well.\n\nLiu, Cheng-Hao, et al. “RetroGNN: Fast Estimation of Synthesizability for Virtual Screening and De Novo Design by Learning from Slow Retrosynthesis Software.” Journal of Chemical Information and Modeling 62.10 (2022): 2293-2300.\n\nRetroGNN is a graph neural network based model to predict outcome of a synthesis planner given the target molecule. Shown to better perform than SAScore. Code is yet to be released.\n\n\nData-driven chemistry modeling and reaction optimization\nReview / Perspectives\n\nWilliams, Wendy L., et al. “The evolution of data-driven modeling in organic chemistry.” ACS central science 7.10 (2021): 1622-1637.\nMaloney, Michael P., et al. “Negative Data in Data Sets for Machine Learning Training.” Organic Letters (2023).\n\nThoughts from industry practioners on how to label low/no yield reactions in electronic lab notebooks (eLNs). This is important when building ML model for reaction outcomes.\nArticles\n\nB. J. Shields et al., “Bayesian reaction optimization as a tool for chemical synthesis,” Nature, vol. 590, no. June 2020, p. 89, 2021. Github\n\nExperimental design using Bayesian Optimization. Look at 3 rxn class with multiple reaction parameters - temp solvent ligand. Algorithm identifies the optimal conditions. Variables looked into: ligands, bases, solvents, temperatures, concentrations. Algorithm arrived at 99% yields consistently - which was possible by using unusual ligand not known to work well (cognitive bias).\n\nTorres, Jose Garrido, et al. “A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.” (2022).. Follow-up Version 2.0\nHickman, Riley J., et al. “Bayesian optimization with known experimental and design constraints for chemistry applications.” arXiv preprint arXiv:2203.17241 (2022).\nHäse, Florian, et al. “Gryffin: An algorithm for Bayesian optimization of categorical variables informed by expert knowledge.” Applied Physics Reviews 8.3 (2021): 031406.\nDotson, Jordan, et al. “Data-driven multi-objective optimization tactics for catalytic asymmetric reactions.” (2022).\n\nMulti-objective optimization of catalytic reactions that employ chiral bisphosphine ligands. Optimization of 2 sequential reactions in asymmetric synthesis of API. Classification method identify active catalysts – 5% yield (user provided) cutoff for binary classification. Linear regression to model reaction selectivity. DFT-derived descriptor dataset of >550 bisphosphine ligands. Develop an interpretable chemical space mapping tool using PCA. Look at the domain of applicability with the euclidean distance in chemical space.\n\nZhang, Ying, et al. “Descriptor-Free Design of Multicomponent Catalysts.” ACS Catalysis 12 (2022): 10562-10571.\n\nBayesian optimization (BO) to improve the experimental measured activity as a direct function of compositional variables without educating physical knowledge to the machine. We applied BO in screening spinel CraMnbFecCodNieCufZn3–a–b–c–d–e–fO4 for the decomposition of nitric oxide into environmentally friendly nitrogen.\nYield prediction\n\nPredicting reaction performance in C–N cross-coupling using machine learning\nMultilabel Classification Models for the Prediction of Cross-Coupling Reaction Conditions\n\nGenerate catalysts\n\nSchilter, Oliver, et al. “Designing catalysts with deep generative models and computational data. A case study for Suzuki cross coupling reactions.” Digital Discovery (2023).\n\nUse VAE and RNN to propose new catalyst for Suzuki cross-coupling reaction. The trained models are used to find catalyst’s binding energy and find high percentage of novel and valid designs.\nDatabases\n\nKearnes, S. M., et al. (2021). “The Open Reaction Database.” Journal of the American Chemical Society.\nRohrbach, Simon, et al. “Digitization and validation of a chemical synthesis literature database in the ChemPU.” Science 377.6602 (2022): 172-180.\n\n\n\nAutomated chemistry workflows\n\nSeifrid, Martin, et al. “Autonomous Chemical Experiments: Challenges and Perspectives on Establishing a Self-Driving Lab.” Accounts of Chemical Research (2022): e0229862-131.\nNambiar, Anirudh MK, et al. “Bayesian Optimization of Computer-Proposed Multistep Synthetic Routes on an Automated Robotic Flow Platform.” ACS Central Science (2022).\nWilbraham, Liam, S. Hessam M. Mehr, and Leroy Cronin. “Digitizing chemistry using the chemical processing unit: from synthesis to discovery.” Accounts of Chemical Research 54.2 (2020): 253-262.\nGodfrey, Alexander G., Thierry Masquelin, and Horst Hemmerle. “A remote-controlled adaptive medchem lab: an innovative approach to enable drug discovery in the 21st Century.” Drug Discovery Today 18.17-18 (2013): 795-802.\n\nAccount of Eli Lilly and Company’s ASL (Automated Synthesis Lab)\n\n\nDNA-encoded Libraries\n\nMatthew Clark, et. al. DNA-encoded small-molecule libraries (DEL). C&EN article on the topic\n\nNew form of storing huge amounts of molecule related data using DNA. Made partially possible by low cost of DNA sequencing. Each molecule in the storage is attached with a DNA strand which encode information about its recipe.\n\nFollow up to the work with Machine Learning for hit finding.\n\nDNA encodings for discovery of novel small-molecule protein inhibitors. Outline a process for building a ML model using DEL. Compare graph convolutions to random forest for classification tasks with application to protein target binding. Graph models seemed to achieve high hit rate comapred to random forest. Apply diversity, logistical, structural filtering to search for novel candidates. First work to use GCN for hit searching.\n\nMartín, A., et al. (2020). “Navigating the DNA encoded libraries chemical space.” Communications Chemistry 3(1).\nZabolotna, Y., Pikalyova, R., Volochnyuk, D., Horvath, D., Marcou, G., & Varnek, A. (2021). Exploration of the chemical space of DNA-encoded libraries.\nShmilovich, Kirill, et al. “DEL-Dock: Molecular Docking-Enabled Modeling of DNA-Encoded Libraries.” arXiv preprint arXiv:2212.00136 (2022).\n\nPropose a way to incoporate 3D-spatial information in the DEL read outs to denoise the data.\n\nZhang, Chris, et al. “Building Block-Based Binding Predictions for DNA-Encoded Libraries.” (2023). Github\n\nSet of informatic tools to look at BBs producitivity in DEL screens and guide designs for new DELs. Authors calculate joint probabilities of the BBs for its activity and find increasing binding metric for individual BBs also increases the overall binding energy. The authors then cluster these BBs using 2D and 3D tanimoto FPs (3D Tanimoto Combo) and HDBSCAN clustering."
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#protein-ligand-interactions",
    "href": "posts/2022-12-28-small_molecule_resources.html#protein-ligand-interactions",
    "title": "Small Molecules Resources",
    "section": "Protein-ligand interactions",
    "text": "Protein-ligand interactions\n\nDiffDock\nMatchMaker"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#code-packages",
    "href": "posts/2022-12-28-small_molecule_resources.html#code-packages",
    "title": "Small Molecules Resources",
    "section": "Code / Packages:",
    "text": "Code / Packages:\n\nMolecular AI department at AstraZeneca R&D\nJazzy: Fast calculation of hydrogen-bond strengths and free energy of hydration of small molecules\nGHOST: Generalized threshold shifting procedure. Paper. Blogpost\n\nAutomates the selection of decision threshold for imbalanced classification task. The assumption for this method to work is the similar characteristics (like imbalance ratio) of training and test data.\n\nMOSES - Benchmarking platform for generative models (PyTorch Implementation). Github\n\nBenchmarking platform to implement molecular generative models. It also provides a set of metrics to evaluate the quality and diversity of the generated molecules. A benchmark dataset (subset of ZINC) is provided for training the models.\n\nReinvent 2.0 - an AI tool forr de novo drug design. Github\n\nProduction-ready tool for de novo design from Astra Zeneca. It can be effectively applied on drug discovery projects that are striving to resolve either exploration or exploitation problems while navigating the chemical space. Language model with SMILE output and trained by “randomizing” the SMILES representation of the input data. Implement reinforcement-leraning for directing the model towards relevant area of interest.\n\nSchnet by Jacobsen et. al. (Neural message passing). Github. Tutorial\nOpenChem. Github\nDeepChem (Tensorflow). Website\n\nDeepChem aims to provide a high quality open-source toolchain that democratizes the use of deep-learning in drug discovery, materials science, quantum chemistry, and biology - from Github\n\nChemProp (Pytorch)\n\nGithub repository for implmenting message passing neural networks for molecular property prediction as described in the paper Analyzing Learned Molecular Representations for Property Prediction by Yang et. al. \n\nChainer-Chemistry\n\n“Chainer Chemistry is a deep learning framework (based on Chainer) with applications in Biology and Chemistry. It supports various state-of-the-art models (especially GCNN - Graph Convolutional Neural Network) for chemical property prediction” - from their Github repo introduction\n\nFastJTNN - python 3 version of the JT-NN\nDimeNet++ - extension of Directional message pasing working (DimeNet). Github\nBondNet - Graph neural network model for predicting bond dissociation energies, considers both homolytic and heterolytic bond breaking. Github\nPhysNet\nRNN based encoder software\nAutodE\nDScribe\nRMG - Reaction Mechanism Generator\n\nTool to generate chemical reaction networks. Includes Arkane, package for calculating thermodynamics from quantum mechanical calculations.\n\nPyePAL\n\nActive learning approach to efficiently and confidently identify the Pareto front with any regression model that can output a mean and a standard deviation.\n\nrxnfp\n\nGithub repository to generate chemical reaction fingerprints from reaction SMILES.\n\nmols2grid\n\nInteractive chemical viewer for small molecules (RDKit wrapper)\n\nmolplotly\n\nSpotfire like capabilities to jupyter notebook. Medium article on explaining the MolPlotly. Link\n\nESPsim\n\nCalculate similarities of shapes and electrostatic potentials between molecules. Pen has a nice blogpost on using to estimate electronic similarities of common bioisosteres. blog\n\nGenerative Toolkit 4 Scientific Discovery\nJazzy\n\nFast calculation of H-bond strength and free energy of hydration of small molecules\n\nJazzy + Chemprop\n\nChemprop version that combines Jazzy (AZ’s workflow for predicting H-bond strength)"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#datasets-chemical-libraries",
    "href": "posts/2022-12-28-small_molecule_resources.html#datasets-chemical-libraries",
    "title": "Small Molecules Resources",
    "section": "Datasets & Chemical libraries",
    "text": "Datasets & Chemical libraries\nMolecule datasets\n\nPubChem: public sourced molecules\nChEMBL: bioactive molecules (most synthetic)\nSUREChEMBL: small molecules appearing in Patents\nZINC: collection of synthetic molecules (not all are bioactive)\nQM 7/8/9: small molecules having not more than 7/8/9 heavy atoms\nGDB-11\nPapyrus\nCOCONUT: NP 400k there are some which are not NP\nMcule: Used in DEL enumerations\nDrugBank\nQMugs\n\nQMugs (Quantum mechanical properties of drug-like molecules) collection comprises quantum mechanical properties of more than 665 k biologically and pharmacologically relevant molecules extracted from the ChEMBL database, totaling 2M conformers.\nReaction Datasets\n\nUSPTO\nPistachio\nReaxys\nOpen Reaction Database\n\nCommericial (building block) vendors\n\neMolecules building blocks\nEnamine Fragments\nWuXi GalaXi space\nOtava’s CHEMriya"
  },
  {
    "objectID": "posts/2022-12-28-small_molecule_resources.html#helpful-utilities",
    "href": "posts/2022-12-28-small_molecule_resources.html#helpful-utilities",
    "title": "Small Molecules Resources",
    "section": "Helpful utilities:",
    "text": "Helpful utilities:\n\nRD-Kit\n\nGet Atom Indices in the SMILE:\nDatamol for manipulating RDKit molecules\n\nPapers with code benchmark for QM9 energy predictions\nMOSES: Molecular generation models benchmark\nTherapeutics Data Commons “Therapeutics Data Commons is an open-science platform with AI/ML-ready datasets and learning tasks for therapeutics, spanning the discovery and development of safe and effective medicines. TDC also provides an ecosystem of tools, libraries, leaderboards, and community resources, including data functions, strategies for systematic model evaluation, meaning”"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html",
    "href": "posts/2020-01-14-test-markdown-post.html",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Jekyll requires blog post files to be named according to the following format:\nYEAR-MONTH-DAY-filename.md\nWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files.\nThe first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above.\n\n\n\nYou can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule:\n\n\n\n\nHere’s a list:\n\nitem 1\nitem 2\n\nAnd a numbered list:\n\nitem 1\nitem 2\n\n\n\n\n\nThis is a quotation\n\n{% include alert.html text=“You can include alert boxes” %}\n…and…\n{% include info.html text=“You can include info boxes” %}\n\n\n\n\n\n\n\nYou can format text and code per usual\nGeneral preformatted text:\n# Do a thing\ndo_thing()\nPython code and output:\n# Prints '2'\nprint(1+1)\n2\nFormatting text as shell commands:\necho \"hello world\"\n./some_script.sh --option \"value\"\nwget https://example.com/cat_photo1.png\nFormatting text as YAML:\nkey: value\n- another_key: \"another value\"\n\n\n\n\n\n\nColumn 1\nColumn 2\n\n\n\n\nA thing\nAnother thing\n\n\n\n\n\n\n{% twitter https://twitter.com/jakevdp/status/1204765621767901185?s=20 %}"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html",
    "href": "posts/2021-01-27-bayesian_optimization.html",
    "title": "Bayesian optimisation implementation",
    "section": "",
    "text": "If \\(f\\) (objective function) is cheap to evaluate we can sample various points and built a potential surface however, if the \\(f\\) is expensive – like in case of first-principles electronic structure calculations, it is important to minimize the number of \\(f\\) calls and number of samples drawn from this evaluation. In that case, if an exact functional form for f is not available (that is, f behaves as a “black box”), what can we do?\nBayesian optimization proceeds by maintaining a probabilistic belief about \\(f\\) and designing a so called acquisition function to determine where to evaluate the next function call. Bayesian optimization is particularly well-suited to global optimization problems where: 1. \\(f\\) is an expensive black-box function 2. Analytical solution for the gradient of the function is difficult to evaluate\nThe idea is the find “global” minimum with least number of steps. Incorporating prior beliefs about the underlying process and update the prior with samples draw from the model to better estimate the posterior.\nModel used for approximating the objective function is called the surrogate model.\nFollowing are few links I have found useful in understanding the inner workings of the Bayesian opitmization and certain typical surrogate functions used in it:"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#import-the-acquisition-functions-implemented",
    "href": "posts/2021-01-27-bayesian_optimization.html#import-the-acquisition-functions-implemented",
    "title": "Bayesian optimisation implementation",
    "section": "## Import the acquisition functions implemented",
    "text": "## Import the acquisition functions implemented\n\nEI = acquisition.ExpectedImprovement(delta = 0.01)\nLCB = acquisition.LowerConfidenceBound(sigma = 1.96)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#fit-a-gpr-model-surrogate-function-to-the-sampled-points",
    "href": "posts/2021-01-27-bayesian_optimization.html#fit-a-gpr-model-surrogate-function-to-the-sampled-points",
    "title": "Bayesian optimisation implementation",
    "section": "Fit a GPR model (surrogate function) to the sampled points",
    "text": "Fit a GPR model (surrogate function) to the sampled points\n\nconstant = kernels.ConstantKernel()\nmatern = kernels.Matern(nu = 2.5)\nrbf = kernels.RBF()\n\ngpr_model = GPR(kernel = constant*rbf, alpha = 1e-3, n_restarts_optimizer = 20, normalize_y = False, random_state = 42)\n\ngpr_model.fit(x_sample, y_sample)\n\nGaussianProcessRegressor(alpha=0.001, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=20, random_state=42)\n\n\n\n(mean_pred, stddev_pred) = gpr_model.predict(x_pts, return_std = True)\ngpr_model.kernel_\n\n2.78**2 * RBF(length_scale=0.782)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#plot-the-initial-sample",
    "href": "posts/2021-01-27-bayesian_optimization.html#plot-the-initial-sample",
    "title": "Bayesian optimisation implementation",
    "section": "Plot the Initial Sample",
    "text": "Plot the Initial Sample\n\n(fig_ec, ax_ec) = plotting_utils.illustrate_1d_gpr(objective, gpr_model, x_pts, EI, LCB)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#run-a-few-iterations-and-assess",
    "href": "posts/2021-01-27-bayesian_optimization.html#run-a-few-iterations-and-assess",
    "title": "Bayesian optimisation implementation",
    "section": "Run a Few Iterations and Assess",
    "text": "Run a Few Iterations and Assess\n\npkwargs = {\"num_sample\": 10,\n           \"num_improve\": 5,\n           \"generator\": generator}\n\nres_ec, _ = opti.bayesian_optimization(objective, gpr_model, LCB, domain, max_iter=10, noise=noise_, prop_kwargs = pkwargs)\ngpr_model.fit(res_ec[\"X\"], res_ec[\"y\"]) # Incorporate final point into plots.\n\n10\n\n\nGaussianProcessRegressor(alpha=0.001, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=20, random_state=42)\n\n\n\n(fig_ec, ax_ec) = plotting_utils.illustrate_1d_gpr(objective, gpr_model, x_pts, EI, LCB, num_sample_points)"
  },
  {
    "objectID": "posts/2021-01-27-bayesian_optimization.html#run-a-few-more-iterations",
    "href": "posts/2021-01-27-bayesian_optimization.html#run-a-few-more-iterations",
    "title": "Bayesian optimisation implementation",
    "section": "Run a Few More Iterations",
    "text": "Run a Few More Iterations\n\nres_ec, _ = opti.bayesian_optimization(objective, gpr_model, LCB, domain, noise=noise_, prop_kwargs = pkwargs)\ngpr_model.fit(res_ec[\"X\"], res_ec[\"y\"]) # Incorporate final point into plots.\n\n20\n\n\nGaussianProcessRegressor(alpha=0.001, kernel=1**2 * RBF(length_scale=1),\n                         n_restarts_optimizer=20, random_state=42)\n\n\n\n(fig_ec, ax_ec) = plotting_utils.illustrate_1d_gpr(objective, gpr_model, x_pts, EI, LCB, num_sample_points)\n\n\n\n\nIn total the noisy estimation of the ground-truth is conducted on 30 additional points. It is evident from the plot that most of those points are near the x = (4,6) since that is the minimum value region for the function."
  },
  {
    "objectID": "posts/data/fingerprints.html",
    "href": "posts/data/fingerprints.html",
    "title": "Fingerprints",
    "section": "",
    "text": "import os \nimport pandas as pd\nimport numpy as np \nimport tqdm.notebook as tqdm\nThe QM9 dataset from the MoleculeNet: A Benchmark for Molecular Machine Learning paper, consisting of about 130,000 molecules with multiple regression targets.\nEach molecule includes complete spatial information for the single low energy conformation of the atoms in the molecule.\nMore information on each descriptor here\nTake a small sample from QM9 dataset\nPandasTools module helps add mol molecule objects from RDKit as per the SMILES in the dataframe\nCheck the new ROMol columns being appended in the dataframe\nVisualize the dataframe, add properties of interest at the bottom, you can add index too if need"
  },
  {
    "objectID": "posts/data/fingerprints.html#fingerprints",
    "href": "posts/data/fingerprints.html#fingerprints",
    "title": "Fingerprints",
    "section": "Fingerprints",
    "text": "Fingerprints\nCompress molecules into vectors for mathetical operations and comparisons. First we will look at MorganFingerprint method. For this method we have to define the radius and the size of the vector being used. More information on Morgan Fingerprints can be read at this blogpost\n\nNice Review on this matter from Peter Willet\nPresentation by Gregory Landrum (creator of RDkit) on Fingerprints\nOfficial Documentation on Fingerprints in RDkit\n\n\n# Fingerprints\nfrom rdkit.Chem import AllChem\n\n\n_radius = 2\n_nBits = 2 ** 10\nECFP6 = [AllChem.GetMorganFingerprint(m, radius) for m in QM9_df_smol['ROMol']]\n\n\nlen(ECFP6)\n\n\nTypes of fingerprints to consider:\n\nDescriptor based fingerprints - more information here\nCount or binary-based fingerprints\n2.1. Circular Fingerprints (Morgan) - Extended Connectivity (ECFP)\n2.2. Atom pair\n2.3. Torsion\n2.4. MACCS Keys\n2.5. RDkit\nData-driven fingerprints\n\nfps1 = [Chem.RDKFingerprint(x, fpSize=1024, minPath=1, maxPath=4) for x in suppl]\nfps2 = [Chem.GetHashedMorganFingerprint(x, radius=2, nBits=1024) for x in suppl]\nfps3 = [Chem.GetMorganFingerprint(x, radius=2, useCounts= True) for x in suppl]\nfps4 = [Pairs.GetAtomPairFingerprintAsIntVect(x) for x in suppl]\narr = np.zeros((4,1024), dtype = np.int8)\nfor i in range(0,len(suppl)):\nDataStructs.ConvertToNumpyArray(fps2[i], arr[i])\nprint(arr)"
  },
  {
    "objectID": "posts/data/fingerprints.html#count-or-binary-fingerprint",
    "href": "posts/data/fingerprints.html#count-or-binary-fingerprint",
    "title": "Fingerprints",
    "section": "2. Count or binary fingerprint",
    "text": "2. Count or binary fingerprint\n\nfrom rdkit.Chem import AllChem\n\n\nfp = AllChem.GetMorganFingerprintAsBitVect(mol_obj, _radius, nBits= _nBits)\nfp_array = [int(x) for x in fp.ToBitString()]\n\nPairs.GetHashedAtomPairFingerprint GetMorganFingerprintAsBitVect GetHashedMorganFingerprint\n\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\nfpvect1 = Pairs.GetHashedAtomPairFingerprint(mol_obj)\nfpvect2 = Pairs.GetAtomPairFingerprint(mol_obj)\nfp1 = np.zeros((1,))\nfp2 = np.zeros((1,))\n#DataStructs.ConvertToNumpyArray(fp_vect, fp) \n#print(type(fp))\n\n\nDataStructs.ConvertToNumpyArray(fpvect1, fp1) \n\n\nDataStructs.ConvertToNumpyArray(fpvect2, fp2) \n\n\nfp1.shape\n\n\nfp2.shape\n\n\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\nfrom rdkit import Chem, DataStructs\nfpvect1 = AllChem.GetHashedMorganFingerprint(mol_obj, 2, nBits= 1024)\nfpvect2 = AllChem.GetMorganFingerprint(mol_obj, 2)\nfp1 = np.zeros((1,))\nfp2 = np.zeros((1,))\nDataStructs.ConvertToNumpyArray(fpvect1, fp1) \nDataStructs.ConvertToNumpyArray(fpvect2, fp2) \n\n\nfrom rdkit import Chem, DataStructs\nfrom rdkit.Chem import MACCSkeys\nfrom rdkit.Chem.AtomPairs import Pairs, Torsions\n\ndef get_fingerprint(smiles: str, radius: int = 2, num_bits: int = 2048, use_counts: bool = False, type_fp: str = 'Morgan') -> np.ndarray:\n    \"\"\"\n    Generates a morgan fingerprint for a smiles string.\n\n    :param smiles: A smiles string for a molecule.\n    :param radius: The radius of the fingerprint.\n    :param num_bits: The number of bits to use in the fingerprint.\n    :param use_counts: Whether to use counts or just a bit vector for the fingerprint\n    :return: A 1-D numpy array containing the morgan fingerprint.\n    \"\"\"\n    if type(smiles) == str:\n        mol = Chem.MolFromSmiles(smiles)\n    else:\n        mol = smiles\n    \n    if type_fp == 'Morgan': \n        if use_counts:\n            fp_vect = AllChem.GetHashedMorganFingerprint(mol, radius, nBits=num_bits)\n        else:\n            fp_vect = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n    \n    if type_fp == 'MACCS': \n        fp_vect = MACCSkeys.GenMACCSKeys(mol)\n        \n    if type_fp == 'RDkit':\n        Chem.RDKFingerprint(x)\n        \n    fp = np.zeros((1,))\n    DataStructs.ConvertToNumpyArray(fp_vect, fp)\n\n    return fp"
  },
  {
    "objectID": "posts/data/fingerprints.html#similarity",
    "href": "posts/data/fingerprints.html#similarity",
    "title": "Fingerprints",
    "section": "Similarity",
    "text": "Similarity\nRDKit provides tools for different kinds of similarity search, including Tanimoto, Dice, Cosine, Sokal, Russel… and more. Tanimoto is a very widely use similarity search metric because it incorporates substructure matching. Here is an example\n\nref_mol = QM9_df_smol.iloc[3]['ROMol']\n\n\nref_mol\n\n\n# Generate finger print based representation for that molecule \nref_ECFP4_fps = AllChem.GetMorganFingerprintAsBitVect(ref_mol, radius= _radius, nBits=_nBits)\n\n\nQM9_smol_ECFP4_fps = [AllChem.GetMorganFingerprintAsBitVect(x, _radius, _nBits) for x in QM9_df_smol['ROMol']]\n\n\nfrom rdkit import DataStructs\nsimilarity_efcp4 = [DataStructs.FingerprintSimilarity(ref_ECFP4_fps, x) for x in QM9_smol_ECFP4_fps]\n\n\nQM9_df_smol = QM9_df_smol.sort_values(['Tanimoto_Similarity (ECFP4)'], ascending=False)\nPandasTools.FrameToGridImage(QM9_df_smol, legendsCol=\"Tanimoto_Similarity (ECFP4)\", molsPerRow=4)"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html",
    "title": "Classification-based algorithms walkthrough",
    "section": "",
    "text": "Some times the data in a supervised learning task is more qualitative than quantitative such as high, medium, low; or the task has categorical outputs such as colors - red, blue, green, or type of fruits: orange or apple. In such cases we look at classification models for training a model predictor. Various types of classification tasks exists:\n\n\n\n\nDistinguish between two classes - high, low, or cat and a dog. A simplest algorithm to train for such a task is logistic regression. Most of the off-the-shelf algorithms work directly on the such tasks – SVM, Random Forests, Naive Bayes.\n\n\n\nDistinguish between more than two classes - digits classifier is an example of multi-class classification since for a given digit image the answer could any number from 0-9. It is still one class but multiple options exists. Certain algorithms like Random Forest, Naive Bayes are capable of handling multi-class classifier. Others like SVM and linear classifiers are strictly binary classifier.\nThere are ways you can convert a binary classifier: * One-versus-all:\nTrain n classifier for n classes such that each classifier ONLY predicts whether that class is present or not. Eg: Train a classifier to predict if a digit is 2 or not.\n\nOne-versus-one:\n\nPair-wise classifier, in this case models are trained in a binary fashion for as many pair there can be between n classes. This can become computationally expensive since for n classes: \\(n(n-1)/2\\) classifiers are needed.\nMain advantage in this approach is that size of training data is small as only pair-wise data is required. Such an approach is useful when models dont scale well with large data – such as SVM or gaussian based\n\n\n\nDistinguish between more than class but also the answer is not just one value but a list of possiblities. When the output amongst the list is only Binary it is usually refered to as Multi-label classification. For example:\nIf we train a model to classify a digit image as:\n1. Is it smaller than 4? (1:yes; 0:no)\n\n2. Is it odd number? (1:yes; 0:no)\n\n3. Is it is greater than 7? (1:yes; 0:no)\nThen the output would be a list - for 5: [0, 1, 0] ; 4: [0, 0, 0]; 3: [1, 1, 0]\nK-Nearest neighbor is a type of classifier which supports such a classification.\nScikit-learn has a wonderful documentation on metrics to be used for different types of classification tasks (Link here)\nFrom the Scikit-learn documentation:\nSome metrics are essentially defined for binary classification tasks (e.g. f1_score, roc_auc_score). In these cases, by default only the positive label is evaluated, assuming by default that the positive class is labelled 1 (though this may be configurable through the pos_label parameter).\n\nIn extending a binary metric to multiclass or multilabel problems, the data is treated as a collection of binary problems, one for each class. There are then a number of ways to average binary metric calculations across the set of classes, each of which may be useful in some scenario. Where available, you should select among these using the average parameter.\nThe code in this notebook is adapted from Aurélien Geron’s hands-on machine learning tutorial on Classifications Github Link\n\nimport os \nimport copy\nimport numpy as np\n\nnp.random.seed(42)\n\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n\nplt.rcParams.update(plot_params)"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#mnist-dataset",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#mnist-dataset",
    "title": "Classification-based algorithms walkthrough",
    "section": "MNIST dataset",
    "text": "MNIST dataset\n70,000 small images of hand-written numbers. Each image has 784 features. Those features are split in 28x28 pixels and each feature is simply that pixel gray-scale intensity. Value for each pixel ranges from 0 to 255.\n\nfrom sklearn.datasets import load_digits\nmnist = load_digits()\nprint(mnist.data.shape)\n\n(1797, 64)\n\n\n\n# Using MNIST data from openML website \nfrom sklearn.datasets import fetch_openml\nmnist = fetch_openml('mnist_784', version=1, cache=True)\nmnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings\n\n\ndef sort_by_target(mnist):\n    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n    \n    #minist.data is a pandas DataFrame\n    mnist_data_numpy = np.array(mnist.data.values)\n    mnist_target_numpy = np.array(mnist.target.values)\n    \n    mnist_data_numpy[:60000] = mnist_data_numpy[reorder_train]\n    mnist_target_numpy[:60000] = mnist_target_numpy[reorder_train]\n    mnist_data_numpy[60000:] = mnist_data_numpy[reorder_test + 60000]\n    mnist_target_numpy[60000:] = mnist_target_numpy[reorder_test + 60000]\n    \n    return mnist_data_numpy, mnist_target_numpy\n\n\nX, y = sort_by_target(mnist)\n\n\nrandom_idx = 62123\n\ndigit_image, digit_label = X[random_idx], y[random_idx]\nprint('The {0} entry is a photo of {1}'.format(random_idx, digit_label))\n\nrandom_digit_image=digit_image.reshape(28,28)\nplt.imshow(random_digit_image, cmap=cm.binary,\n          interpolation=\"nearest\")\nplt.axis(\"off\");\n\nThe 62123 entry is a photo of 2\n\n\n\n\n\n\n#Plot digit convenience function\ndef plot_digit(data):\n    image = data.reshape(28, 28)\n    plt.imshow(image, cmap = mpl.cm.binary,\n               interpolation=\"nearest\")\n    plt.axis(\"off\")\n\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n\nBefore training we shuffle the data to ensure all cross-validation folds to be similar. Moreover some classficiation algorithms are sensitive to the order of training instances, and they perform poorly if they get many similar instances in a row.\n\n#Index shuffling \nimport numpy as np \nindex_shuffle = np.random.permutation(60000)\nX_train, y_train = X_train[index_shuffle], y_train[index_shuffle]"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#binary-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#binary-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "Binary classification",
    "text": "Binary classification\nHere we will build a single digit classifier – for example looking at just 2. Hence in total there will be only 2 classes – Those which are 2 and those which are not.\n\ny_train_2 = (y_train == 2) #True for all 2s, False for all other digits \ny_test_2 = (y_test == 2)\n\nUsing Stochastic Gradient Descent classifier. Known to handle large datasets very well.\n\nfrom sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(X_train, y_train_2)\n\nSGDClassifier(max_iter=5, random_state=42, tol=-inf)\n\n\n\nsgd_clf.predict([digit_image])\n\narray([ True])"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#performance-metrics",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#performance-metrics",
    "title": "Classification-based algorithms walkthrough",
    "section": "Performance metrics",
    "text": "Performance metrics\nEvaluating classifiers is often significantly challenging than the case for a regressor wherein we can use RMSE or MAE. Let’s look at some usual metrics used to gauge the classifier performance.\n\n1. Accuracy using Cross-validation\nIt involves splitting your training data in K-folds. Training the model on K-1 folds and testing it on the left out fold. Scikit learn has in-built method to do so: cross_val_score(). We can implement our own version as well.\n\\[ \\% Accuracy = \\frac{Correct}{Total} * 100 \\]\n\n#Inside the scikit-learn's crossvalidation accuracy method\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.base import clone \n\nskfolds = StratifiedKFold(n_splits=3, shuffle=False)\n\nfor train_index, test_index in skfolds.split(X_train,y_train_2):\n    clone_clf = clone(sgd_clf)\n    X_train_folds = X_train[train_index]\n    y_train_folds = y_train_2[train_index]\n    \n    X_test_folds = X_train[test_index]\n    y_test_folds = y_train_2[test_index]\n    \n    clone_clf.fit(X_train_folds, y_train_folds)\n    y_pred=clone_clf.predict(X_test_folds)\n    \n    n_correct = sum(y_pred == y_test_folds)\n    print(n_correct/len(y_pred))\n\n0.97365\n0.96255\n0.96165\n\n\n\n#Using scikit-learn's in-built method \nfrom sklearn.model_selection import cross_val_score\ncross_val_score(sgd_clf, X_train, y_train_2, cv=3, scoring='accuracy')\n\narray([0.97365, 0.96255, 0.96165])\n\n\nDoes this high accuracy tell us anything?\nIs the sample space we are looking at uniform enough for this accuracy?\nMaybe we have way less one-digit samples for training in the first place.\n\n_count=0.\nfor i in range(len(y_train)):\n    if y_train[i] == 2: \n        _count=_count+1.\nprint(_count/len(y_train)*100)     \n\n9.93\n\n\nSo ~9% of the sample are actually 2. So even if we guess ALWAYS that image is not 2 we will be right 90% of the time!\n\n\nThe dumb classifier\nTo check whether classifier accuracy of ~95% is good enough so just a over-exagerration\n\nfrom sklearn.base import BaseEstimator\nclass Never2(BaseEstimator):\n    def fit(self, X, y=None):\n        pass\n    def predict(self, X):\n        return(np.zeros((len(X),1),dtype=bool))\n\n\nnever2 = Never2()\ncross_val_score(never2,X_train,y_train_2,cv=3,scoring='accuracy')\n\narray([0.9017, 0.9001, 0.9003])\n\n\nThis shows our data is skewed!\n\n\n2. Confusion Matrix\nGeneral idea is to count the number of times instances of Class A are classified as Class B.\nTable that describes the performance of a classification model by grouping predictions into 4 categories. - True Positives: we correctly predicted they do have diabetes - True Negatives: we correctly predicted they don’t have diabetes - False Positives: we incorrectly predicted they do have diabetes (Type I error) - False Negatives: we incorrectly predicted they don’t have diabetes (Type II error)\nThe ROWS in the matrix are the real class-labels i.e. the TRUTH values while COLUMNS are the predicted values.\n\n<td colspan=\"2\"><p><b>Actual class (observation)</b></p></td>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicted class (expectation)\n\n\n\n\ntp (true positive) Correct result\n\n\n\n\nfp (false positive) Unexpected result\n\n\n\n\n\n\nfn (false negative) Missing result\n\n\n\n\ntn (true negative) Correct absence of result\n\n\n\n\n\n\n\nfrom sklearn.model_selection import cross_val_predict\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3)\n\n\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_train_2, y_train_pred)\n\narray([[53159,   883],\n       [ 1160,  4798]])\n\n\nEach row in the confusion matrix represent actual class, while each column represents a predicted class. Following are the terms of the confusion matrix: 1. First row of this matrix is the non-2 images – - (0,0) instances were correctly classified as non 2 (True Negative) - (0,1) instances were wrongly classified as 2s (False Positive) 2. Second row considers the images of 5 – - (1,0) instances were wrongly classified as non 2s (False negatives) - (1,1) instances were correctly classified as 2s (True positives)\nAn ideal classifier would be a diagonal matrix with no false positives or false negatives\n\nPrecision\nThink of this as precision of the model in estimating the binary class. FROM POV of the MODEL\nIt is the ratio of the total classification whether as True or Wrongly classified as True to True. That is, \\[Precision = \\frac{TP}{TP+FP}\\]\nThis is looking at +ve classification and how many are really +ve and how many are wrongly shown as +ve. So Precision looks at the prediction of +ve results.\n\n\nRecall\nThink of this as comparing to the actual data in the model training. FROM POV of the REAL DATA\nIt is the ratio of total classification on the +ve samples from where they are classified correctly (TP) to wrongly classified as negative (FN).\n\\[Recall = \\frac{TP}{FN+TP}\\]\nSo Recall looks at the prediction of the +ve samples.\n\nThis is by just comparing the +ve samples in the binary classification. To check how many of them are correctly recalled as +ve.\n\n\n\nF1 score\nHarmonic mean of recall and precision. Higher the Precision and Recall, lower are the instances of FP and FN. So we want to have higher Recall and Precision both.\nF1 favors classifiers with similar recall and precision.\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nprint('Precision score: {}'.format(precision_score(y_train_2, y_train_pred)))\nprint('Recall score: {}'.format(recall_score(y_train_2, y_train_pred)))\nprint('F1 score: {}'.format(f1_score(y_train_2, y_train_pred)))\n\nPrecision score: 0.8445696180249956\nRecall score: 0.8053037932192011\nF1 score: 0.8244694561388435\n\n\n\n\n\nRecall/Precision tradeoff\nUnfortunately increasing precision reduces recall and vise-versa. However sometimes one of the qualities could be desirable in a model.\nRecall looks at lowering the False Negatives so culling +ve cases. That could be detrimental in catching robberies. So we need classifiers with high recall and we are okay with low Precision wherein we would get False alarms.\nMeanwhile, if we are censoring videos we need high Precision to ensure unsafe videos categorised as Safe ones. While we could be removing good videos by wrongly classifying them to be Unsafe (low recall).\nMore discussion here: Link\nDecision functions evaluate a decision_score we can manually set the threshold for the score to whether that will accpted or rejected for the binary case.\nIncreasing threshold reduces recall, but increases precision.\nWhy? The more Precise you want to be i.e. more True Positive than False Positives – the higher the threshold for passing the case of accepting the data as a given class. However doing so we are strict in what we define as a ideal class and can neglect samples which are positive but are not closest to ideal. Hence we do incorrectly mark them as Negative thus increasing the case of False Negaitives and hence lowering Recall.\n\n#Decision scores for all instnces in the training set -- \ny_scores = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3,\n                             method=\"decision_function\")\n\n\nfrom sklearn.metrics import precision_recall_curve\nprecisions, recalls, thresholds = precision_recall_curve(y_train_2, y_scores)\n\n\ndef plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n    plt.xlabel(\"Threshold\", fontsize=10)\n    plt.legend(loc=\"best\", fontsize=12)\n    \n    plt.ylim([0, 1])\n\nplt.figure(figsize=(8, 4))\nplot_precision_recall_vs_threshold(precisions, recalls, thresholds)\nplt.xlim([-700000, 700000])\nplt.show()\n\n\n\n\n\nplt.figure(figsize=(8, 4))    \nplt.plot(recalls[:-1],precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\nplt.ylabel(\"Precision\", fontsize=16)\nplt.xlabel(\"Recall\", fontsize=16)\n\nText(0.5, 0, 'Recall')\n\n\n\n\n\n\nIf someone says let’s reach 99% PRECISION, we must ALWAYS ask at what RECALL?\n\n\nManually set the Recall/Precision using threshold\n\ny_scores = sgd_clf.decision_function([digit_image])\nprint(y_scores)\n\ny_pred_thresh = sgd_clf.predict([digit_image])\nprint(y_pred_thresh)\n#Setting threshold higher than the y_score\nthreshold = y_scores + 1.0 \ny_pred_thresh = (y_scores > threshold)\nprint(y_pred_thresh)\n\n[247991.40436599]\n[ True]\n[False]\n\n\n\n#Changing the threshold for everyother training example -- more than 90% precision\ny_scores = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3,\n                             method=\"decision_function\")\ny_train_pred_90 = (y_scores > 200000)\nprint('Precision score: {}'.format(precision_score(y_train_2, y_train_pred_90)))\nprint('Recall score: {}'.format(recall_score(y_train_2, y_train_pred_90)))\nprint('F1 score: {}'.format(f1_score(y_train_2, y_train_pred_90)))\n\nPrecision score: 0.9637028700056275\nRecall score: 0.5748573346760658\nF1 score: 0.720142977291842\n\n\nWe have made classifier with an arbitrary Precision score: 97% However doing so we reduced the Recall.\n\n\n\nThe ROC curve\nAnother common tool used for binary classifiers apart from Precision/Recall. Instead of plotting precision vs recall we plot True Positive Rate (TPR) i.e. Recall against False Positive Rate (FPR). FPR is the ratio of negative instances that are incorrectly classified as positive.\nROC plots sensitivity vs 1-specificty\n\nfrom sklearn.metrics import roc_curve\n\n#Decision scores for all instnces in the training set -- \ny_scores = cross_val_predict(sgd_clf, X_train, y_train_2, cv=3,\n                             method=\"decision_function\")\n\nfpr, tpr, thresholds = roc_curve(y_train_2, y_scores)\n\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n\nplt.figure(figsize=(8, 6))\nplot_roc_curve(fpr, tpr)\nplt.show()\n\n\n\n\n\nfrom sklearn.metrics import roc_auc_score\nroc_auc_score(y_train_2, y_scores)\n\n0.9651158581307573\n\n\nPR curve when we care of precision – getting False +ve and not so much of getting False -ve. We are okay with losing some +ve cases but for sure do not want to neglect any -ve ones."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#random-forest-classifier",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#random-forest-classifier",
    "title": "Classification-based algorithms walkthrough",
    "section": "Random forest classifier",
    "text": "Random forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\nforest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\ny_probas_forest = cross_val_predict(forest_clf, X_train, y_train_2, cv=3,\n                                    method=\"predict_proba\")\n\n\ny_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\nfpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_2, y_scores_forest)\n\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\")\nplot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\nplt.legend(loc=\"lower right\", fontsize=16)\nplt.show()"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#multiclass-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#multiclass-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "Multiclass classification",
    "text": "Multiclass classification\nMulticlass classifiers are able to label and distinguish between more than two classes. Some algorithms such as Random Forest and Näive Bayes are capable of handling this directly. Having said that, Naive Baye’s has shortcomming of considering class conditional independence and having discrete entries in the input.\n\nOvA (One-versus-all classifiers): Herein, we would train n binary classifiers for n type of labels and see which n-th classifier has highest decision score.\nOvO (One-versus-one strategy): Binary classifier for every pair. So for n labels we will have n(n-1)/2 classifiers."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#error-analysis",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#error-analysis",
    "title": "Classification-based algorithms walkthrough",
    "section": "Error analysis",
    "text": "Error analysis\n\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\nindex_shuffle = np.random.permutation(60000)\nX_train, y_train = X_train[index_shuffle], y_train[index_shuffle]\n\nsgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)\nsgd_clf.fit(X_train, y_train)\n\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\ny_scores = cross_val_predict(sgd_clf, X_train, y_train, cv=3,\n                             method=\"decision_function\")\nconf_mx = confusion_matrix(y_train, y_train_pred)\n\n\nplt.matshow(conf_mx, cmap=plt.cm.gray)\nplt.show()"
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#plotting-heat-map-for-the-errors-in-the-classification",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#plotting-heat-map-for-the-errors-in-the-classification",
    "title": "Classification-based algorithms walkthrough",
    "section": "Plotting heat-map for the errors in the classification",
    "text": "Plotting heat-map for the errors in the classification\n\nrow_sums = conf_mx.sum(axis=1, keepdims=True)\nnorm_conf_mx = conf_mx / row_sums\n#Diagonals are filled to be zero to concentrate only at the errors\nnp.fill_diagonal(norm_conf_mx, 0)\nplt.matshow(norm_conf_mx, cmap=plt.cm.gray)\nplt.show()\n\n\n\n\nROWS in the confusion matrix are the REAL labels. COLUMNS in the confusion matrix are the PREDICTED values. It can seen that in the case of row 3 and column 5: - 5 is most of the times confused with 3 and 8 - 9 is confused with 4 and 7\n\ndef plot_digits(instances, images_per_row=10, **options):\n    size = 28\n    images_per_row = min(len(instances), images_per_row)\n    images = [instance.reshape(size,size) for instance in instances]\n    n_rows = (len(instances) - 1) // images_per_row + 1\n    row_images = []\n    n_empty = n_rows * images_per_row - len(instances)\n    images.append(np.zeros((size, size * n_empty)))\n    for row in range(n_rows):\n        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n        row_images.append(np.concatenate(rimages, axis=1))\n    image = np.concatenate(row_images, axis=0)\n    plt.imshow(image, cmap = cm.binary, **options)\n    plt.axis(\"off\")\n\n\ncl_a, cl_b = 3, 5\nX_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\nX_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\nX_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\nX_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n\n\nplt.figure(figsize=(8,8))\nplt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\nplt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\nplt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\nplt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\nplt.show()\n\n\n\n\nGiven above are two sets of ‘3’ and ‘5’ – the boxes to the left are 3 and 5 classified as 3. Top left are the images of 3 classified as 3 while Bottom left are the images of 5 classified as 3. It can seen that some imags of 5 quite poor and the algorithm (which is linear in this case) will have difficulty predicting it."
  },
  {
    "objectID": "posts/2020-08-12-mnist_scikit_learn-classification.html#multi-label-classifier",
    "href": "posts/2020-08-12-mnist_scikit_learn-classification.html#multi-label-classifier",
    "title": "Classification-based algorithms walkthrough",
    "section": "Multi-label classifier",
    "text": "Multi-label classifier\nDetermine a label such that it is a list for a every digit answering two questions: 1. Is this number odd? 1: Yes, 0: No 2. Is this number greater than 7? 1: Yes, 0: No\nCreating new y_label for model\n\n# Setting two conditions \nis_odd = (y % 2 == 0).astype(int)\nis_greater_7 = (y > 7).astype(int)\n\ny_multilabel = np.c_[is_odd, is_greater_7]\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_clf = KNeighborsClassifier()\n\n\nX_train, X_test, y_ml_train, y_ml_test = X[:60000], X[60000:], y_multilabel[:60000], y_multilabel[60000:]\nindex_shuffle = np.random.permutation(60000)\nX_train, y_ml_train = X_train[index_shuffle], y_ml_train[index_shuffle]\n\n\nknn_clf.fit(X_train, y_ml_train)\n\nKNeighborsClassifier()\n\n\n\n# Predict\nknn_clf.predict([X_train[12]])\n\narray([[0, 0]])\n\n\n\ny_ml_train[12]\n\narray([0, 0])\n\n\n\n# Metric \ny_knn_ml_pred= cross_val_predict(knn_clf, X_train, y_ml_train, cv=3)\n\n\n# macro assumes all labels are equally important \n# another option is the 'weighted' \nf1_score(y_ml_train, y_knn_ml_pred, average='macro')\n\n0.9719059410724892"
  },
  {
    "objectID": "posts/2020-12-09-food_relations.html",
    "href": "posts/2020-12-09-food_relations.html",
    "title": "Relational analysis of spices used in Indian cuisine",
    "section": "",
    "text": "Spices are central to Indian cuisine. What is referred to colloquially as ‘Indian’ food is made of many different sub-cuisines. As a result, there are a plethora of spices usually brought up when considering ‘Indian’ food. Knowing which spices are most frequently used can help cooks novice or seasoned to make an informed decision about spices that promise the most bang for the buck.\nI use a Kaggle dataset containing 6000+ recipes from https://www.archanaskitchen.com/. Using this data as base collection of recipes representing most of the indian food, I analyze which spices occur most freqeuntly and which spices are most connected to each other.\n\nDataset for Indian recipe: This dataset 6000+ recipe scrapped from | Link to the dataset\n\n\nimport pandas as pd \nimport numpy as np \n\n\n#----- PLOTTING PARAMS ----# \nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport seaborn as sns\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n\n\nfood_df = pd.read_csv('./data/IndianFoodDatasetCSV.csv')\n\n\nfood_df.columns\n\nIndex(['Srno', 'RecipeName', 'TranslatedRecipeName', 'Ingredients',\n       'TranslatedIngredients', 'PrepTimeInMins', 'CookTimeInMins',\n       'TotalTimeInMins', 'Servings', 'Cuisine', 'Course', 'Diet',\n       'Instructions', 'TranslatedInstructions', 'URL'],\n      dtype='object')\n\n\n\nfood_df.shape\n\n(6871, 15)\n\n\n\n# dropping miscellaneous columns and NaN entries\ncolumns_to_drop = ['CookTimeInMins', 'Servings', 'Course', 'Diet', 'Instructions', 'TranslatedInstructions', 'URL']\nfood_df = food_df.drop(columns = columns_to_drop).dropna()\n\n\n# data has indian-inspired international cuisines which are not what we are interested in\ncuisines_to_drop = ['Mexican', 'Italian Recipes', 'Thai', 'Chinese', 'Asian', 'Middle Eastern', 'European',\n                   'Arab', 'Japanese', 'Vietnamese', 'British', 'Greek', 'French', 'Mediterranean', 'Sri Lankan',\n                   'Indonesian', 'African', 'Korean', 'American', 'Carribbean', 'World Breakfast', 'Malaysian', 'Dessert',\n                   'Afghan', 'Snack', 'Jewish', 'Brunch', 'Lunch', 'Continental', 'Fusion']\n\nfood_df = food_df.loc[ ~ food_df['Cuisine'].isin(cuisines_to_drop) ] #Dropping entries in `food_df` which have non-indian cuisines \n\n\nfood_df.shape\n\n(4881, 8)\n\n\n\nfood_df.head(5)\n\n\n\n\n\n  \n    \n      \n      Srno\n      RecipeName\n      TranslatedRecipeName\n      Ingredients\n      TranslatedIngredients\n      PrepTimeInMins\n      TotalTimeInMins\n      Cuisine\n    \n  \n  \n    \n      0\n      1\n      Masala Karela Recipe\n      Masala Karela Recipe\n      6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n      6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n      15\n      45\n      Indian\n    \n    \n      1\n      2\n      टमाटर पुलियोगरे रेसिपी - Spicy Tomato Rice (Re...\n      Spicy Tomato Rice (Recipe)\n      2-1/2 कप चावल - पका ले,3 टमाटर,3 छोटा चमच्च बी...\n      2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n      5\n      15\n      South Indian Recipes\n    \n    \n      2\n      3\n      Ragi Semiya Upma Recipe - Ragi Millet Vermicel...\n      Ragi Semiya Upma Recipe - Ragi Millet Vermicel...\n      1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n      1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n      20\n      50\n      South Indian Recipes\n    \n    \n      3\n      4\n      Gongura Chicken Curry Recipe - Andhra Style Go...\n      Gongura Chicken Curry Recipe - Andhra Style Go...\n      500 grams Chicken,2 Onion - chopped,1 Tomato -...\n      500 grams Chicken,2 Onion - chopped,1 Tomato -...\n      15\n      45\n      Andhra\n    \n    \n      4\n      5\n      आंध्रा स्टाइल आलम पचड़ी रेसिपी - Adrak Chutney ...\n      Andhra Style Alam Pachadi Recipe - Adrak Chutn...\n      1 बड़ा चमच्च चना दाल,1 बड़ा चमच्च सफ़ेद उरद दाल,2...\n      1 tablespoon chana dal, 1 tablespoon white ura...\n      10\n      30\n      Andhra\n    \n  \n\n\n\n\n\n\n\n\n# Some entries in the `TranslatedIngredients` have non-english entries \ndef filter_english(string):\n    try:\n        string.encode('utf-8').decode('ascii')\n        out = True\n    except UnicodeDecodeError: \n        out = False\n    return out\n\n\n# Droping columns in the dataset having ingredients in language other than english \ndf = food_df.loc[ food_df['TranslatedIngredients'].apply(filter_english) ]\n\n\ndf.shape\n\n(4273, 8)\n\n\n\ndf = df.reset_index()\n\n\n\n\nNext for consistent tabulation I needed a list of spices to look for. Wikipedia has a page on Indian spices which lists various spices used in Indian cuisine. I use this list to search names of spices in the recipe entries.\n\n#read file of all indian spices on wikipedia\nwiki_file_pd = pd.read_html('https://en.wikipedia.org/wiki/List_of_Indian_spices')\nspices_list = wiki_file_pd[0]['Standard English'].copy().str.lower()\n\n#some important spices to add\nspices_to_add = pd.Series(['black salt', 'green chillies', 'chilli powder'])\n\n#some spices are too common (such as pepper) or not a spice, but a vegetable, or are otherwise corrupted (for example,\n#cardamom is often listed as \"cardamom\" nto specifying whether it is black or green)\n\nspices_to_drop = ['black pepper', 'capers', 'chili pepper powder', 'cinnamon buds', 'citric acid', 'garlic', 'capsicum', 'charoli', 'garcinia gummi-gutta', 'inknut', 'garcinia indica',\n                  'black mustard seeds/raee', 'cumin seed ground into balls', 'dried ginger', 'green chili pepper', 'long pepper', 'four seeds', 'cubeb', 'gum tragacanth', 'jakhya', 'licorice powder',\n                  'indian bedellium tree', 'mango extract', 'coriander powder', 'saffron pulp', 'black cardamom', 'brown mustard seed', 'black cumin', 'panch phoron']\n\nspices_list = spices_list.loc[ ~spices_list.isin(spices_to_drop) ].append(spices_to_add).reset_index(drop=True)\n\n\nspices_list\n\n0                      alkanet root\n1                           amchoor\n2                        asafoetida\n3             celery / radhuni seed\n4         bay leaf, indian bay leaf\n5                          cinnamon\n6                            cloves\n7                    coriander seed\n8                        cumin seed\n9     curry tree or sweet neem leaf\n10                      fennel seed\n11                   fenugreek leaf\n12                   fenugreek seed\n13                     garam masala\n14                           ginger\n15                   green cardamom\n16                indian gooseberry\n17                          kalpasi\n18                     mustard seed\n19                     nigella seed\n20                           nutmeg\n21                             mace\n22                 pomegranate seed\n23                       poppy seed\n24                          saffron\n25                      sesame seed\n26                      star aniseh\n27                         tamarind\n28                thymol/carom seed\n29                         turmeric\n30                     white pepper\n31                       black salt\n32                   green chillies\n33                    chilli powder\ndtype: object\n\n\nOne more step is editing the spices so that my string counter can find different versions of the same spice.\n\n#editing the spices so that my string counter can find different versions of the same spice\nspices_list = spices_list.str.replace('amchoor', 'amchur/amchoor/mango extract') \\\n                    .replace('asafoetida', 'asafetida/asafoetida/hing') \\\n                    .replace('thymol/carom seed', 'ajwain/thymol/carom seed') \\\n                    .replace('alkanet root', 'alkanet/alkanet root') \\\n                    .replace('chilli powder', 'red chilli powder/chilli powder/kashmiri red chilli powder') \\\n                    .replace('celery / radhuni seed', 'celery/radhuni seed') \\\n                    .replace('bay leaf, indian bay leaf', 'bay leaf/bay leaves/tej patta') \\\n                    .replace('curry tree or sweet neem leaf', 'curry leaf/curry leaves') \\\n                    .replace('fenugreek leaf', 'fenugreek/kasoori methi') \\\n                    .replace('nigella seed', 'nigella/black cumin') \\\n                    .replace('ginger', 'dried ginger/ginger powder') \\\n                    .replace('cloves', 'cloves/laung') \\\n                    .replace('green cardamom', 'cardamom/green cardamom/black cardamom')\\\n                    .replace('indian gooseberry', 'indian gooseberry/amla')\\\n                    .replace('coriander seed', 'coriander seed/coriander powder')\\\n                    .replace('star aniseh', 'star anise')\\\n                    .replace('cumin seed', 'cumin powder/cumin seeds/cumin/jeera')\n\n\nspices_list\n\n0                                  alkanet/alkanet root\n1                          amchur/amchoor/mango extract\n2                             asafetida/asafoetida/hing\n3                                   celery/radhuni seed\n4                         bay leaf/bay leaves/tej patta\n5                                              cinnamon\n6                                          cloves/laung\n7                       coriander seed/coriander powder\n8                  cumin powder/cumin seeds/cumin/jeera\n9                               curry leaf/curry leaves\n10                                          fennel seed\n11                              fenugreek/kasoori methi\n12                                       fenugreek seed\n13                                         garam masala\n14                           dried ginger/ginger powder\n15               cardamom/green cardamom/black cardamom\n16                               indian gooseberry/amla\n17                                              kalpasi\n18                                         mustard seed\n19                                  nigella/black cumin\n20                                               nutmeg\n21                                                 mace\n22                                     pomegranate seed\n23                                           poppy seed\n24                                              saffron\n25                                          sesame seed\n26                                           star anise\n27                                             tamarind\n28                             ajwain/thymol/carom seed\n29                                             turmeric\n30                                         white pepper\n31                                           black salt\n32                                       green chillies\n33    red chilli powder/chilli powder/kashmiri red c...\ndtype: object\n\n\n\n\n\n\ningredients_series = df[['TranslatedRecipeName','TranslatedIngredients']]\n\n\ningredients_series\n\n\n\n\n\n  \n    \n      \n      TranslatedRecipeName\n      TranslatedIngredients\n    \n  \n  \n    \n      0\n      Masala Karela Recipe\n      6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n    \n    \n      1\n      Spicy Tomato Rice (Recipe)\n      2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n    \n    \n      2\n      Ragi Semiya Upma Recipe - Ragi Millet Vermicel...\n      1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n    \n    \n      3\n      Gongura Chicken Curry Recipe - Andhra Style Go...\n      500 grams Chicken,2 Onion - chopped,1 Tomato -...\n    \n    \n      4\n      Andhra Style Alam Pachadi Recipe - Adrak Chutn...\n      1 tablespoon chana dal, 1 tablespoon white ura...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      4268\n      One Pot Punjabi Rajma Masala Recipe In Preethi...\n      1 cup Rajma (Large Kidney Beans),1 inch Ginger...\n    \n    \n      4269\n      Saffron Paneer Peda Recipe\n      2 cups Paneer (Homemade Cottage Cheese) - crum...\n    \n    \n      4270\n      Quinoa Phirnee Recipe (Quinoa Milk Pudding)\n      1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n    \n    \n      4271\n      Ullikadala Pulusu Recipe | Spring Onion Curry\n      150 grams Spring Onion (Bulb & Greens) - chopp...\n    \n    \n      4272\n      Kashmiri Style Kokur Yakhni Recipe-Chicken Coo...\n      1 kg Chicken - medium pieces,1/2 cup Mustard o...\n    \n  \n\n4273 rows × 2 columns\n\n\n\n\nspices_list_column_to_add = {i: np.zeros(len(ingredients_series)) for i in spices_list.to_list()}\n\n\ningredients_series = ingredients_series.join(pd.DataFrame(spices_list_column_to_add))\n\n\ningredients_series\n\n\n\n\n\n  \n    \n      \n      TranslatedRecipeName\n      TranslatedIngredients\n      alkanet/alkanet root\n      amchur/amchoor/mango extract\n      asafetida/asafoetida/hing\n      celery/radhuni seed\n      bay leaf/bay leaves/tej patta\n      cinnamon\n      cloves/laung\n      coriander seed/coriander powder\n      ...\n      saffron\n      sesame seed\n      star anise\n      tamarind\n      ajwain/thymol/carom seed\n      turmeric\n      white pepper\n      black salt\n      green chillies\n      red chilli powder/chilli powder/kashmiri red chilli powder\n    \n  \n  \n    \n      0\n      Masala Karela Recipe\n      6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      Spicy Tomato Rice (Recipe)\n      2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      Ragi Semiya Upma Recipe - Ragi Millet Vermicel...\n      1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      Gongura Chicken Curry Recipe - Andhra Style Go...\n      500 grams Chicken,2 Onion - chopped,1 Tomato -...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4\n      Andhra Style Alam Pachadi Recipe - Adrak Chutn...\n      1 tablespoon chana dal, 1 tablespoon white ura...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      4268\n      One Pot Punjabi Rajma Masala Recipe In Preethi...\n      1 cup Rajma (Large Kidney Beans),1 inch Ginger...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4269\n      Saffron Paneer Peda Recipe\n      2 cups Paneer (Homemade Cottage Cheese) - crum...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4270\n      Quinoa Phirnee Recipe (Quinoa Milk Pudding)\n      1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4271\n      Ullikadala Pulusu Recipe | Spring Onion Curry\n      150 grams Spring Onion (Bulb & Greens) - chopp...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      4272\n      Kashmiri Style Kokur Yakhni Recipe-Chicken Coo...\n      1 kg Chicken - medium pieces,1/2 cup Mustard o...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      ...\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n4273 rows × 36 columns\n\n\n\n\n\n\nI used regular expression to search for spice names in the entries\n\n# Convenience function to search a given ingredient list for spice names\nimport re \ndef search_spice(ingredient_string, spice_string):\n    '''\n    Check if a spice exists in the list of ingredients for a recipe \n    '''\n    spice_list = spice_string.split('/')\n    for _spice in spice_list:\n        if re.search(_spice.lower(), ingredient_string.lower()):\n            return True\n            break\n\n\nfor row, values in ingredients_series.iterrows():\n    for spice_entry in spices_list:\n        if search_spice(values['TranslatedIngredients'], spice_entry):\n            ingredients_series.loc[row, spice_entry] = 1\n        else:\n            ingredients_series.loc[row, spice_entry] = 0\n\n\nfood_spice_mix = ingredients_series.drop(['TranslatedIngredients'], axis=1).reset_index(drop=True)\n\n\n#editing the spices so that my string counter can find different versions of the same spice\nfood_spice_mix.rename(columns={'amchur/amchoor/mango extract':'amchoor', \\\n                    'asafetida/asafoetida/hing': 'asafoetida', \\\n                    'ajwain/thymol/carom seed': 'ajwain', \\\n                    'alkanet/alkanet root': 'alkanet root', \\\n                    'red chilli powder/chilli powder/kashmiri red chilli powder': 'chilli powder', \\\n                    'celery/radhuni seed': 'celery seeds',\\\n                    'bay leaf/bay leaves/tej patta': 'bay leaf', \\\n                    'curry leaf/curry leaves': 'curry leaves',\\\n                    'fenugreek/kasoori methi': 'fenugreek leaf', \\\n                    'nigella/black cumin': 'nigella seed', \\\n                    'ginger': 'dried ginger',\\\n                    'cloves/laung': 'cloves', \\\n                    'cardamom/green cardamom/black cardamom': 'cardamom',\\\n                    'indian gooseberry/amla': 'indian gooseberry',\\\n                    'coriander seed/coriander powder': 'coriander seeds/powder',\\\n                    'cumin powder/cumin seeds/cumin/jeera': 'cumin seeds/powder',\\\n                    'dried ginger/ginger powder': 'ginger powder'}, inplace=True)\n\n\nfood_spice_mix.columns\n\nIndex(['TranslatedRecipeName', 'alkanet root', 'amchoor', 'asafoetida',\n       'celery seeds', 'bay leaf', 'cinnamon', 'cloves',\n       'coriander seeds/powder', 'cumin seeds/powder', 'curry leaves',\n       'fennel seed', 'fenugreek leaf', 'fenugreek seed', 'garam masala',\n       'ginger powder', 'cardamom', 'indian gooseberry', 'kalpasi',\n       'mustard seed', 'nigella seed', 'nutmeg', 'mace', 'pomegranate seed',\n       'poppy seed', 'saffron', 'sesame seed', 'star anise', 'tamarind',\n       'ajwain', 'turmeric', 'white pepper', 'black salt', 'green chillies',\n       'chilli powder'],\n      dtype='object')\n\n\n\nfood_spice_mix = food_spice_mix.sort_index(axis=1)\n\n\n\n\n\nnum_spice = len(spices_list)\nspice_col_name = [i for i in food_spice_mix.columns[1:].to_list()]\nspice_adj = pd.DataFrame(np.zeros(shape=(len(spices_list),len(spices_list))), columns= spice_col_name, index=spice_col_name)\nspice_adj_freq = pd.DataFrame(np.zeros(shape=(len(spices_list),len(spices_list))), columns= spice_col_name, index=spice_col_name)\n\n\nfor row, value in food_spice_mix.iterrows():\n    for i in spice_col_name:\n        for j in spice_col_name:\n            if (value[i] == 1) & (value[j] == 1):\n                spice_adj_freq.loc[i,j] += 1\n                spice_adj.loc[i,j] = 1\n\nNormalize the spice occurance frequency with the total entries in the main dataset\n\nspice_adj_freq = spice_adj_freq / len(food_spice_mix) * 100\n\n\nspice_adj_freq.round(2)\n\n\n\n\n\n  \n    \n      \n      ajwain\n      alkanet root\n      amchoor\n      asafoetida\n      bay leaf\n      black salt\n      cardamom\n      celery seeds\n      chilli powder\n      cinnamon\n      ...\n      nigella seed\n      nutmeg\n      pomegranate seed\n      poppy seed\n      saffron\n      sesame seed\n      star anise\n      tamarind\n      turmeric\n      white pepper\n    \n  \n  \n    \n      ajwain\n      5.22\n      0.00\n      0.70\n      1.45\n      0.98\n      0.07\n      1.05\n      0.00\n      3.49\n      1.33\n      ...\n      0.16\n      0.16\n      0.09\n      0.23\n      0.21\n      0.40\n      0.23\n      0.37\n      2.97\n      0.00\n    \n    \n      alkanet root\n      0.00\n      0.07\n      0.00\n      0.07\n      0.05\n      0.00\n      0.07\n      0.00\n      0.07\n      0.07\n      ...\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n    \n    \n      amchoor\n      0.70\n      0.00\n      4.98\n      1.54\n      0.37\n      0.21\n      0.35\n      0.02\n      3.86\n      0.47\n      ...\n      0.35\n      0.00\n      0.14\n      0.02\n      0.05\n      0.26\n      0.05\n      0.33\n      3.51\n      0.02\n    \n    \n      asafoetida\n      1.45\n      0.07\n      1.54\n      24.60\n      1.33\n      0.30\n      1.61\n      0.21\n      9.69\n      1.87\n      ...\n      0.30\n      0.14\n      0.09\n      0.54\n      0.28\n      1.57\n      0.26\n      5.17\n      15.05\n      0.02\n    \n    \n      bay leaf\n      0.98\n      0.05\n      0.37\n      1.33\n      10.70\n      0.09\n      6.04\n      0.07\n      6.72\n      6.65\n      ...\n      0.26\n      0.61\n      0.12\n      0.75\n      0.66\n      0.16\n      1.10\n      0.26\n      7.54\n      0.07\n    \n    \n      black salt\n      0.07\n      0.00\n      0.21\n      0.30\n      0.09\n      1.64\n      0.09\n      0.02\n      0.61\n      0.09\n      ...\n      0.02\n      0.00\n      0.09\n      0.00\n      0.09\n      0.02\n      0.02\n      0.28\n      0.33\n      0.00\n    \n    \n      cardamom\n      1.05\n      0.07\n      0.35\n      1.61\n      6.04\n      0.09\n      17.79\n      0.14\n      6.13\n      7.98\n      ...\n      0.07\n      1.08\n      0.23\n      1.47\n      3.14\n      0.35\n      1.29\n      0.42\n      6.60\n      0.07\n    \n    \n      celery seeds\n      0.00\n      0.00\n      0.02\n      0.21\n      0.07\n      0.02\n      0.14\n      0.80\n      0.37\n      0.19\n      ...\n      0.00\n      0.09\n      0.00\n      0.00\n      0.02\n      0.00\n      0.02\n      0.00\n      0.51\n      0.00\n    \n    \n      chilli powder\n      3.49\n      0.07\n      3.86\n      9.69\n      6.72\n      0.61\n      6.13\n      0.37\n      37.96\n      7.04\n      ...\n      0.84\n      0.44\n      0.47\n      1.38\n      0.68\n      1.59\n      0.82\n      3.58\n      28.39\n      0.05\n    \n    \n      cinnamon\n      1.33\n      0.07\n      0.47\n      1.87\n      6.65\n      0.09\n      7.98\n      0.19\n      7.04\n      13.13\n      ...\n      0.14\n      0.96\n      0.19\n      1.40\n      0.84\n      0.23\n      1.38\n      0.89\n      8.10\n      0.07\n    \n    \n      cloves\n      2.01\n      0.07\n      1.43\n      5.05\n      6.58\n      0.16\n      7.65\n      0.19\n      14.14\n      9.29\n      ...\n      0.35\n      0.70\n      0.23\n      1.59\n      0.80\n      0.96\n      1.43\n      3.93\n      17.29\n      0.02\n    \n    \n      coriander seeds/powder\n      1.76\n      0.00\n      2.41\n      5.13\n      4.91\n      0.26\n      4.31\n      0.47\n      16.26\n      4.35\n      ...\n      0.35\n      0.30\n      0.28\n      0.70\n      0.33\n      0.56\n      0.59\n      1.85\n      16.78\n      0.00\n    \n    \n      cumin seeds/powder\n      2.15\n      0.00\n      3.28\n      13.27\n      5.87\n      1.19\n      5.20\n      0.35\n      21.55\n      6.67\n      ...\n      0.89\n      0.54\n      0.51\n      1.24\n      0.54\n      1.92\n      0.91\n      5.87\n      27.45\n      0.07\n    \n    \n      curry leaves\n      0.61\n      0.00\n      0.44\n      12.54\n      1.01\n      0.12\n      1.17\n      0.05\n      8.64\n      2.04\n      ...\n      0.16\n      0.07\n      0.07\n      0.66\n      0.02\n      1.73\n      0.28\n      7.33\n      16.52\n      0.05\n    \n    \n      fennel seed\n      0.75\n      0.05\n      0.82\n      1.68\n      1.45\n      0.16\n      1.99\n      0.07\n      3.77\n      2.46\n      ...\n      0.70\n      0.26\n      0.09\n      0.91\n      0.42\n      0.37\n      0.75\n      0.82\n      4.21\n      0.00\n    \n    \n      fenugreek leaf\n      0.87\n      0.00\n      0.80\n      4.54\n      1.64\n      0.12\n      1.52\n      0.12\n      6.39\n      1.73\n      ...\n      0.70\n      0.02\n      0.16\n      0.37\n      0.07\n      0.89\n      0.26\n      3.23\n      8.71\n      0.00\n    \n    \n      fenugreek seed\n      0.14\n      0.00\n      0.47\n      3.16\n      0.35\n      0.07\n      0.37\n      0.07\n      2.36\n      0.61\n      ...\n      0.61\n      0.00\n      0.05\n      0.30\n      0.02\n      0.59\n      0.07\n      2.93\n      4.52\n      0.00\n    \n    \n      garam masala\n      1.43\n      0.00\n      2.29\n      3.18\n      4.40\n      0.26\n      3.98\n      0.28\n      14.07\n      4.00\n      ...\n      0.33\n      0.14\n      0.30\n      0.63\n      0.49\n      0.42\n      0.44\n      0.49\n      13.25\n      0.00\n    \n    \n      ginger powder\n      0.21\n      0.02\n      0.05\n      0.44\n      0.35\n      0.05\n      0.84\n      0.02\n      0.59\n      0.49\n      ...\n      0.00\n      0.19\n      0.02\n      0.02\n      0.12\n      0.07\n      0.00\n      0.07\n      0.47\n      0.00\n    \n    \n      green chillies\n      1.80\n      0.00\n      1.59\n      7.61\n      4.61\n      0.28\n      3.96\n      0.21\n      12.22\n      4.84\n      ...\n      0.77\n      0.19\n      0.33\n      1.19\n      0.33\n      1.08\n      0.66\n      2.36\n      17.11\n      0.07\n    \n    \n      indian gooseberry\n      0.05\n      0.00\n      0.00\n      0.30\n      0.00\n      0.02\n      0.00\n      0.02\n      0.16\n      0.00\n      ...\n      0.00\n      0.00\n      0.00\n      0.00\n      0.00\n      0.02\n      0.00\n      0.05\n      0.21\n      0.00\n    \n    \n      kalpasi\n      0.02\n      0.00\n      0.00\n      0.02\n      0.02\n      0.00\n      0.07\n      0.00\n      0.02\n      0.07\n      ...\n      0.00\n      0.02\n      0.00\n      0.07\n      0.00\n      0.00\n      0.05\n      0.00\n      0.00\n      0.00\n    \n    \n      mace\n      0.37\n      0.00\n      0.02\n      0.09\n      0.82\n      0.00\n      1.08\n      0.05\n      0.80\n      1.05\n      ...\n      0.00\n      0.49\n      0.02\n      0.26\n      0.14\n      0.00\n      0.30\n      0.00\n      0.89\n      0.00\n    \n    \n      mustard seed\n      0.75\n      0.00\n      0.87\n      12.71\n      1.15\n      0.07\n      0.73\n      0.02\n      8.03\n      1.59\n      ...\n      0.70\n      0.09\n      0.07\n      0.80\n      0.05\n      1.64\n      0.28\n      6.74\n      15.35\n      0.00\n    \n    \n      nigella seed\n      0.16\n      0.00\n      0.35\n      0.30\n      0.26\n      0.02\n      0.07\n      0.00\n      0.84\n      0.14\n      ...\n      1.66\n      0.00\n      0.02\n      0.16\n      0.02\n      0.07\n      0.02\n      0.07\n      1.26\n      0.02\n    \n    \n      nutmeg\n      0.16\n      0.00\n      0.00\n      0.14\n      0.61\n      0.00\n      1.08\n      0.09\n      0.44\n      0.96\n      ...\n      0.00\n      1.52\n      0.00\n      0.30\n      0.23\n      0.07\n      0.28\n      0.05\n      0.56\n      0.00\n    \n    \n      pomegranate seed\n      0.09\n      0.00\n      0.14\n      0.09\n      0.12\n      0.09\n      0.23\n      0.00\n      0.47\n      0.19\n      ...\n      0.02\n      0.00\n      0.77\n      0.05\n      0.07\n      0.02\n      0.02\n      0.07\n      0.33\n      0.00\n    \n    \n      poppy seed\n      0.23\n      0.00\n      0.02\n      0.54\n      0.75\n      0.00\n      1.47\n      0.00\n      1.38\n      1.40\n      ...\n      0.16\n      0.30\n      0.05\n      3.25\n      0.19\n      0.26\n      0.37\n      0.42\n      1.80\n      0.02\n    \n    \n      saffron\n      0.21\n      0.00\n      0.05\n      0.28\n      0.66\n      0.09\n      3.14\n      0.02\n      0.68\n      0.84\n      ...\n      0.02\n      0.23\n      0.07\n      0.19\n      4.03\n      0.07\n      0.14\n      0.00\n      0.59\n      0.00\n    \n    \n      sesame seed\n      0.40\n      0.00\n      0.26\n      1.57\n      0.16\n      0.02\n      0.35\n      0.00\n      1.59\n      0.23\n      ...\n      0.07\n      0.07\n      0.02\n      0.26\n      0.07\n      4.19\n      0.07\n      0.82\n      1.61\n      0.00\n    \n    \n      star anise\n      0.23\n      0.00\n      0.05\n      0.26\n      1.10\n      0.02\n      1.29\n      0.02\n      0.82\n      1.38\n      ...\n      0.02\n      0.28\n      0.02\n      0.37\n      0.14\n      0.07\n      1.73\n      0.14\n      0.89\n      0.00\n    \n    \n      tamarind\n      0.37\n      0.00\n      0.33\n      5.17\n      0.26\n      0.28\n      0.42\n      0.00\n      3.58\n      0.89\n      ...\n      0.07\n      0.05\n      0.07\n      0.42\n      0.00\n      0.82\n      0.14\n      11.96\n      7.21\n      0.00\n    \n    \n      turmeric\n      2.97\n      0.00\n      3.51\n      15.05\n      7.54\n      0.33\n      6.60\n      0.51\n      28.39\n      8.10\n      ...\n      1.26\n      0.56\n      0.33\n      1.80\n      0.59\n      1.61\n      0.89\n      7.21\n      48.47\n      0.05\n    \n    \n      white pepper\n      0.00\n      0.00\n      0.02\n      0.02\n      0.07\n      0.00\n      0.07\n      0.00\n      0.05\n      0.07\n      ...\n      0.02\n      0.00\n      0.00\n      0.02\n      0.00\n      0.00\n      0.00\n      0.00\n      0.05\n      0.16\n    \n  \n\n34 rows × 34 columns\n\n\n\n\ntemp_name = [i.title() for i in spice_adj_freq.index.to_list()]\nspice_adj_freq['Plot_name'] = temp_name\n\n\nspice_adj_freq = spice_adj_freq.set_index('Plot_name')\n\n\nspice_adj_freq.columns = temp_name\n\n\nspice_adj_freq\n\n\n\n\n\n  \n    \n      \n      Ajwain\n      Alkanet Root\n      Amchoor\n      Asafoetida\n      Bay Leaf\n      Black Salt\n      Cardamom\n      Celery Seeds\n      Chilli Powder\n      Cinnamon\n      ...\n      Nigella Seed\n      Nutmeg\n      Pomegranate Seed\n      Poppy Seed\n      Saffron\n      Sesame Seed\n      Star Anise\n      Tamarind\n      Turmeric\n      White Pepper\n    \n    \n      Plot_name\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Ajwain\n      5.218816\n      0.000000\n      0.702083\n      1.450971\n      0.982916\n      0.070208\n      1.053124\n      0.000000\n      3.487011\n      1.333957\n      ...\n      0.163819\n      0.163819\n      0.093611\n      0.234028\n      0.210625\n      0.397847\n      0.234028\n      0.374444\n      2.972151\n      0.000000\n    \n    \n      Alkanet Root\n      0.000000\n      0.070208\n      0.000000\n      0.070208\n      0.046806\n      0.000000\n      0.070208\n      0.000000\n      0.070208\n      0.070208\n      ...\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      Amchoor\n      0.702083\n      0.000000\n      4.984788\n      1.544582\n      0.374444\n      0.210625\n      0.351041\n      0.023403\n      3.861456\n      0.468055\n      ...\n      0.351041\n      0.000000\n      0.140417\n      0.023403\n      0.046806\n      0.257430\n      0.046806\n      0.327639\n      3.510414\n      0.023403\n    \n    \n      Asafoetida\n      1.450971\n      0.070208\n      1.544582\n      24.596302\n      1.333957\n      0.304236\n      1.614791\n      0.210625\n      9.688743\n      1.872221\n      ...\n      0.304236\n      0.140417\n      0.093611\n      0.538264\n      0.280833\n      1.567985\n      0.257430\n      5.172010\n      15.047976\n      0.023403\n    \n    \n      Bay Leaf\n      0.982916\n      0.046806\n      0.374444\n      1.333957\n      10.695062\n      0.093611\n      6.037912\n      0.070208\n      6.716593\n      6.646384\n      ...\n      0.257430\n      0.608472\n      0.117014\n      0.748888\n      0.655277\n      0.163819\n      1.099930\n      0.257430\n      7.535689\n      0.070208\n    \n    \n      Black Salt\n      0.070208\n      0.000000\n      0.210625\n      0.304236\n      0.093611\n      1.638193\n      0.093611\n      0.023403\n      0.608472\n      0.093611\n      ...\n      0.023403\n      0.000000\n      0.093611\n      0.000000\n      0.093611\n      0.023403\n      0.023403\n      0.280833\n      0.327639\n      0.000000\n    \n    \n      Cardamom\n      1.053124\n      0.070208\n      0.351041\n      1.614791\n      6.037912\n      0.093611\n      17.786099\n      0.140417\n      6.131524\n      7.980342\n      ...\n      0.070208\n      1.076527\n      0.234028\n      1.474374\n      3.135970\n      0.351041\n      1.287152\n      0.421250\n      6.599579\n      0.070208\n    \n    \n      Celery Seeds\n      0.000000\n      0.000000\n      0.023403\n      0.210625\n      0.070208\n      0.023403\n      0.140417\n      0.795694\n      0.374444\n      0.187222\n      ...\n      0.000000\n      0.093611\n      0.000000\n      0.000000\n      0.023403\n      0.000000\n      0.023403\n      0.000000\n      0.514861\n      0.000000\n    \n    \n      Chilli Powder\n      3.487011\n      0.070208\n      3.861456\n      9.688743\n      6.716593\n      0.608472\n      6.131524\n      0.374444\n      37.959279\n      7.044231\n      ...\n      0.842499\n      0.444652\n      0.468055\n      1.380763\n      0.678680\n      1.591388\n      0.819097\n      3.580623\n      28.387550\n      0.046806\n    \n    \n      Cinnamon\n      1.333957\n      0.070208\n      0.468055\n      1.872221\n      6.646384\n      0.093611\n      7.980342\n      0.187222\n      7.044231\n      13.128949\n      ...\n      0.140417\n      0.959513\n      0.187222\n      1.404166\n      0.842499\n      0.234028\n      1.380763\n      0.889305\n      8.097355\n      0.070208\n    \n    \n      Cloves\n      2.012637\n      0.070208\n      1.427568\n      5.054996\n      6.576176\n      0.163819\n      7.652703\n      0.187222\n      14.135268\n      9.290896\n      ...\n      0.351041\n      0.702083\n      0.234028\n      1.591388\n      0.795694\n      0.959513\n      1.427568\n      3.931664\n      17.294641\n      0.023403\n    \n    \n      Coriander Seeds/Powder\n      1.755207\n      0.000000\n      2.410484\n      5.125205\n      4.914580\n      0.257430\n      4.306108\n      0.468055\n      16.264919\n      4.352914\n      ...\n      0.351041\n      0.304236\n      0.280833\n      0.702083\n      0.327639\n      0.561666\n      0.585069\n      1.848818\n      16.779780\n      0.000000\n    \n    \n      Cumin Seeds/Powder\n      2.153054\n      0.000000\n      3.276387\n      13.269366\n      5.874093\n      1.193541\n      5.195413\n      0.351041\n      21.553943\n      6.669787\n      ...\n      0.889305\n      0.538264\n      0.514861\n      1.240346\n      0.538264\n      1.919026\n      0.912708\n      5.874093\n      27.451439\n      0.070208\n    \n    \n      Curry Leaves\n      0.608472\n      0.000000\n      0.444652\n      12.543880\n      1.006319\n      0.117014\n      1.170138\n      0.046806\n      8.635619\n      2.036040\n      ...\n      0.163819\n      0.070208\n      0.070208\n      0.655277\n      0.023403\n      1.731804\n      0.280833\n      7.325064\n      16.522350\n      0.046806\n    \n    \n      Fennel Seed\n      0.748888\n      0.046806\n      0.819097\n      1.684999\n      1.450971\n      0.163819\n      1.989235\n      0.070208\n      3.767845\n      2.457290\n      ...\n      0.702083\n      0.257430\n      0.093611\n      0.912708\n      0.421250\n      0.374444\n      0.748888\n      0.819097\n      4.212497\n      0.000000\n    \n    \n      Fenugreek Leaf\n      0.865902\n      0.000000\n      0.795694\n      4.540136\n      1.638193\n      0.117014\n      1.521179\n      0.117014\n      6.388954\n      1.731804\n      ...\n      0.702083\n      0.023403\n      0.163819\n      0.374444\n      0.070208\n      0.889305\n      0.257430\n      3.229581\n      8.705827\n      0.000000\n    \n    \n      Fenugreek Seed\n      0.140417\n      0.000000\n      0.468055\n      3.159373\n      0.351041\n      0.070208\n      0.374444\n      0.070208\n      2.363679\n      0.608472\n      ...\n      0.608472\n      0.000000\n      0.046806\n      0.304236\n      0.023403\n      0.585069\n      0.070208\n      2.925345\n      4.516733\n      0.000000\n    \n    \n      Garam Masala\n      1.427568\n      0.000000\n      2.293471\n      3.182776\n      4.399719\n      0.257430\n      3.978469\n      0.280833\n      14.065060\n      4.001872\n      ...\n      0.327639\n      0.140417\n      0.304236\n      0.631875\n      0.491458\n      0.421250\n      0.444652\n      0.491458\n      13.245963\n      0.000000\n    \n    \n      Ginger Powder\n      0.210625\n      0.023403\n      0.046806\n      0.444652\n      0.351041\n      0.046806\n      0.842499\n      0.023403\n      0.585069\n      0.491458\n      ...\n      0.000000\n      0.187222\n      0.023403\n      0.023403\n      0.117014\n      0.070208\n      0.000000\n      0.070208\n      0.468055\n      0.000000\n    \n    \n      Green Chillies\n      1.802013\n      0.000000\n      1.591388\n      7.605897\n      4.610344\n      0.280833\n      3.955067\n      0.210625\n      12.216242\n      4.844372\n      ...\n      0.772291\n      0.187222\n      0.327639\n      1.193541\n      0.327639\n      1.076527\n      0.655277\n      2.363679\n      17.107419\n      0.070208\n    \n    \n      Indian Gooseberry\n      0.046806\n      0.000000\n      0.000000\n      0.304236\n      0.000000\n      0.023403\n      0.000000\n      0.023403\n      0.163819\n      0.000000\n      ...\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.023403\n      0.000000\n      0.046806\n      0.210625\n      0.000000\n    \n    \n      Kalpasi\n      0.023403\n      0.000000\n      0.000000\n      0.023403\n      0.023403\n      0.000000\n      0.070208\n      0.000000\n      0.023403\n      0.070208\n      ...\n      0.000000\n      0.023403\n      0.000000\n      0.070208\n      0.000000\n      0.000000\n      0.046806\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      Mace\n      0.374444\n      0.000000\n      0.023403\n      0.093611\n      0.819097\n      0.000000\n      1.076527\n      0.046806\n      0.795694\n      1.053124\n      ...\n      0.000000\n      0.491458\n      0.023403\n      0.257430\n      0.140417\n      0.000000\n      0.304236\n      0.000000\n      0.889305\n      0.000000\n    \n    \n      Mustard Seed\n      0.748888\n      0.000000\n      0.865902\n      12.707700\n      1.146735\n      0.070208\n      0.725486\n      0.023403\n      8.027147\n      1.591388\n      ...\n      0.702083\n      0.093611\n      0.070208\n      0.795694\n      0.046806\n      1.638193\n      0.280833\n      6.739995\n      15.352212\n      0.000000\n    \n    \n      Nigella Seed\n      0.163819\n      0.000000\n      0.351041\n      0.304236\n      0.257430\n      0.023403\n      0.070208\n      0.000000\n      0.842499\n      0.140417\n      ...\n      1.661596\n      0.000000\n      0.023403\n      0.163819\n      0.023403\n      0.070208\n      0.023403\n      0.070208\n      1.263749\n      0.023403\n    \n    \n      Nutmeg\n      0.163819\n      0.000000\n      0.000000\n      0.140417\n      0.608472\n      0.000000\n      1.076527\n      0.093611\n      0.444652\n      0.959513\n      ...\n      0.000000\n      1.521179\n      0.000000\n      0.304236\n      0.234028\n      0.070208\n      0.280833\n      0.046806\n      0.561666\n      0.000000\n    \n    \n      Pomegranate Seed\n      0.093611\n      0.000000\n      0.140417\n      0.093611\n      0.117014\n      0.093611\n      0.234028\n      0.000000\n      0.468055\n      0.187222\n      ...\n      0.023403\n      0.000000\n      0.772291\n      0.046806\n      0.070208\n      0.023403\n      0.023403\n      0.070208\n      0.327639\n      0.000000\n    \n    \n      Poppy Seed\n      0.234028\n      0.000000\n      0.023403\n      0.538264\n      0.748888\n      0.000000\n      1.474374\n      0.000000\n      1.380763\n      1.404166\n      ...\n      0.163819\n      0.304236\n      0.046806\n      3.252984\n      0.187222\n      0.257430\n      0.374444\n      0.421250\n      1.802013\n      0.023403\n    \n    \n      Saffron\n      0.210625\n      0.000000\n      0.046806\n      0.280833\n      0.655277\n      0.093611\n      3.135970\n      0.023403\n      0.678680\n      0.842499\n      ...\n      0.023403\n      0.234028\n      0.070208\n      0.187222\n      4.025275\n      0.070208\n      0.140417\n      0.000000\n      0.585069\n      0.000000\n    \n    \n      Sesame Seed\n      0.397847\n      0.000000\n      0.257430\n      1.567985\n      0.163819\n      0.023403\n      0.351041\n      0.000000\n      1.591388\n      0.234028\n      ...\n      0.070208\n      0.070208\n      0.023403\n      0.257430\n      0.070208\n      4.189094\n      0.070208\n      0.819097\n      1.614791\n      0.000000\n    \n    \n      Star Anise\n      0.234028\n      0.000000\n      0.046806\n      0.257430\n      1.099930\n      0.023403\n      1.287152\n      0.023403\n      0.819097\n      1.380763\n      ...\n      0.023403\n      0.280833\n      0.023403\n      0.374444\n      0.140417\n      0.070208\n      1.731804\n      0.140417\n      0.889305\n      0.000000\n    \n    \n      Tamarind\n      0.374444\n      0.000000\n      0.327639\n      5.172010\n      0.257430\n      0.280833\n      0.421250\n      0.000000\n      3.580623\n      0.889305\n      ...\n      0.070208\n      0.046806\n      0.070208\n      0.421250\n      0.000000\n      0.819097\n      0.140417\n      11.958811\n      7.208051\n      0.000000\n    \n    \n      Turmeric\n      2.972151\n      0.000000\n      3.510414\n      15.047976\n      7.535689\n      0.327639\n      6.599579\n      0.514861\n      28.387550\n      8.097355\n      ...\n      1.263749\n      0.561666\n      0.327639\n      1.802013\n      0.585069\n      1.614791\n      0.889305\n      7.208051\n      48.467119\n      0.046806\n    \n    \n      White Pepper\n      0.000000\n      0.000000\n      0.023403\n      0.023403\n      0.070208\n      0.000000\n      0.070208\n      0.000000\n      0.046806\n      0.070208\n      ...\n      0.023403\n      0.000000\n      0.000000\n      0.023403\n      0.000000\n      0.000000\n      0.000000\n      0.000000\n      0.046806\n      0.163819\n    \n  \n\n34 rows × 34 columns\n\n\n\n\nfig, ax = plt.subplots(1,1, figsize=(10,10))\nsns.heatmap(spice_adj_freq.round(2).corr(), ax=ax)\n#plt.savefig(\"heatmap.png\", format=\"PNG\", dpi=300)\n\n<AxesSubplot:>\n\n\n\n\n\nUsing frequency adjacency matrix we can plot a heatmap showing the pair-wise occurence for a given pair of spices. The idea with such an analysis is that if we can check the variation of Spice 1 with all the other spices in the list and compare that to Spice 2’s variation with all the other spices in the list, if spice 1 and spice 2 should have similar variation.\nThis map itself is quite interesting. The color intensity of each title shows the frequency that pair of spice occurred together in a recipe. Brighter the color higher their occurence together.\nSome prominent spice pairs which show similarity are:\n\nCurry leaves and Mustard seeds\nTumeric and Chilli Powder\n\nSome pair of spices never occur together:\n\nSaffron and Fenugreek seeds\nNutmeg and Mustard Seeds\n\nThose who cook or know indian recipes would see that these pairs make sense and thereby validate the correlation seen from corpus of Indian recipes.\nWith that analysis, we can go a step further and analyze this information in form of a circular network graph. Using this method of plotting, we can see the interactions between different spices.\n#hide spice_dict = {i : spice_adj_freq.loc[i, i] for i in spice_col_name } top_10_spices = list({k: v for k, v in sorted(spice_dict.items(), reverse=True, key=lambda item: item[1])}.keys())[:10] spice_adj_10 = spice_adj_freq.loc[top_10_spices, top_10_spices]\n#hide top_10_spices\n\n\n\nimport networkx as nx \n\n\nnodes_data = [(i, {'count':spice_adj_freq.loc[i, i]}) for i in temp_name]\n\n\n# most binary interactions \nbinary_int = []\nfor i in temp_name:\n    binary_int.append((i, spice_adj_freq.loc[i].sort_values(ascending=False).index[1]))\n\n\nspice_dict = {i : spice_adj_freq.loc[i, i] for i in temp_name }\n\n\nspice_dict\n\n{'Ajwain': 5.218815820266792,\n 'Alkanet Root': 0.07020828457758016,\n 'Amchoor': 4.984788205008191,\n 'Asafoetida': 24.596302363678916,\n 'Bay Leaf': 10.695062017318044,\n 'Black Salt': 1.6381933068102035,\n 'Cardamom': 17.78609875965364,\n 'Celery Seeds': 0.7956938918792418,\n 'Chilli Powder': 37.959279194945005,\n 'Cinnamon': 13.128949216007488,\n 'Cloves': 28.34074420781652,\n 'Coriander Seeds/Powder': 20.336999765972386,\n 'Cumin Seeds/Powder': 43.59934472267727,\n 'Curry Leaves': 27.615258600514856,\n 'Fennel Seed': 7.208050549964897,\n 'Fenugreek Leaf': 12.965129885326467,\n 'Fenugreek Seed': 7.208050549964897,\n 'Garam Masala': 18.34776503627428,\n 'Ginger Powder': 1.357360168499883,\n 'Green Chillies': 29.815118183945703,\n 'Indian Gooseberry': 0.3978469459396209,\n 'Kalpasi': 0.07020828457758016,\n 'Mace': 1.2403463608705827,\n 'Mustard Seed': 24.315469225368595,\n 'Nigella Seed': 1.6615960683360638,\n 'Nutmeg': 1.5211794991809033,\n 'Pomegranate Seed': 0.7722911303533817,\n 'Poppy Seed': 3.2529838520945473,\n 'Saffron': 4.025274982447929,\n 'Sesame Seed': 4.189094313128949,\n 'Star Anise': 1.7318043529136438,\n 'Tamarind': 11.958811139714488,\n 'Turmeric': 48.46711912005617,\n 'White Pepper': 0.16381933068102036}\n\n\n\nedges_data = [] \nfor i in temp_name:\n    for j in temp_name:\n        if i != j:\n            if spice_adj_freq.loc[i,j] != 0.0:\n                edges_data.append((i, j, {'weight':spice_adj_freq.loc[i,j], 'distance':1}))\n\n\n#G = nx.from_pandas_adjacency(spice_adj_freq)\n#BUILD THE INITIAL FULL GRAPH\nG=nx.Graph()\nG.add_nodes_from(nodes_data)\nG.add_edges_from(edges_data)\n\n\nprint(nx.info(G))\n\nName: \nType: Graph\nNumber of nodes: 34\nNumber of edges: 471\nAverage degree:  27.7059\n\n\n\ndeg_l = {i:G.degree(i) for i in temp_name} \n\n\nhighest_centrality_node = max(deg_l.items(), key=lambda x: x[1])[0]\n\n\nhighest_centrality_node\n\n'Asafoetida'\n\n\n\n#Adopted from: https://stackoverflow.com/questions/43894987/networkx-node-labels-relative-position\nn = len(nodes_data)\nedges = G.edges()\n\nweights = [G[u][v]['weight'] for u,v in edges]\nw_arr = np.array(weights)\nnorm_weight =  (w_arr - w_arr.min())/(w_arr.max() - w_arr.min())\n\n\nangle = []\nangle_dict = {}\nnode_list = sorted(G.nodes())\nfor i, node in zip(np.arange(n),node_list):\n    theta = 2.0*np.pi*i/n\n    angle.append((np.cos(theta),np.sin(theta)))\n    angle_dict[node] = theta\npos = {}\nfor node_i, node in enumerate(node_list):\n    pos[node] = angle[node_i]\n    \nfig, ax = plt.subplots(figsize=(20,20))\nmargin=0.33\nfig.subplots_adjust(margin, margin, 1.-margin, 1.-margin)\nax.axis('equal')\n\nnx.draw(G,pos=pos,with_labels=False, node_size=[spice_dict[k]*20 for k in spice_dict], width=norm_weight*2.0, node_color=np.arange(n), cmap=plt.cm.viridis, ax=ax)\ndescription = nx.draw_networkx_labels(G,pos)\n\nr = fig.canvas.get_renderer()\ntrans = plt.gca().transData.inverted()\nfor node, t in description.items():\n    bb = t.get_window_extent(renderer=r)\n    bbdata = bb.transformed(trans)\n    radius = 1.1+bbdata.width/2\n    position = (radius*np.cos(angle_dict[node]),radius* np.sin(angle_dict[node]))\n    t.set_position(position)\n    t.set_rotation(angle_dict[node]*360.0/(2.0*np.pi))\n    t.set_clip_on(False)\n    \n#plt.savefig(\"Graph.png\", format=\"PNG\", dpi=300)\n\n\n\n\nFinally a networkx circular graph is made where each node is a spice entry. Each edge between a pair of spice is a connection provided those two spices are found together in a recipe. The size of the node is the frequency of that spice to occur in all of 6000 food recipes. The thickness of the edge connecting a give spice-pair is the normalized frequency that pair occured among 6000 recipes.\nRepresenting the analysis this way we find few key takeaways: * Tumeric, Mustard Seeds, Chilli Powder, Corriander Seeds, Cumin Seeds, Curry Leaves, Green Chillies, Asafoetida are the key spices in the Indian cuisine.\n\nMost recipes use Tumeric + Chilli Powder + Cumin Powder (Seeds) in them."
  },
  {
    "objectID": "posts/2021-04-08-matplotlib-equal-aspect.html",
    "href": "posts/2021-04-08-matplotlib-equal-aspect.html",
    "title": "Making equal spaces parity plots using Matplotlib",
    "section": "",
    "text": "import os\nimport matplotlib.pyplot as plt\nimport numpy as np \n\n# High DPI rendering for mac\n%config InlineBackend.figure_format = 'retina'\n%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n\nplot_params = {\n'font.size' : 22,\n'axes.titlesize' : 24,\n'axes.labelsize' : 20,\n'axes.labelweight' : 'bold',\n'xtick.labelsize' : 16,\n'ytick.labelsize' : 16,\n}\n \nplt.rcParams.update(plot_params)\n\n\n# Make dataset\nX = np.linspace(0,5,200)\nY = 1.3*X + np.random.normal(0.01, size=X.shape)\n\nQuick plotting\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(X, Y)\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nText(0, 0.5, 'Y')\n\n\n\n\n\nMake plots with equal aspect ratio and axes\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(X, Y, label='data')\n\n# Find limits for each axes \nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n       ]\n\nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='parity')\nax.set_aspect('equal')\n\nax.set_xlim(lims)\nax.set_ylim(lims)\n\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nhandles, labels = ax.get_legend_handles_labels()\nprint(labels)\nax.legend(handles=handles, labels=labels, title=\"Legend\")\n\n['parity', 'data']\n\n\n<matplotlib.legend.Legend at 0x11ad6a190>\n\n\n\n\n\nSlightly fancier output with parity and linear fit plots\n\nfig, ax = plt.subplots(1,1, figsize=(8,8))\nax.scatter(X, Y, alpha=0.6, label='data')\n\nlims = [np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n        ]\n\n# Linear fit line \nreg = np.polyfit(X, Y, deg=1)\nax.plot(lims, reg[0] * np.array(lims) + reg[1], 'r--', linewidth=1.5, label='linear fit')\n\n# Parity plot \nax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, label='parity')\n#ax.set_aspect('equal')\n        \nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nhandles, labels = ax.get_legend_handles_labels()\nprint(labels)\n\n# Put a legend to the right of the current axis\nax.legend(handles=handles, labels=labels, title=\"Legend\", loc='center left', bbox_to_anchor=(1, 0.5))\n\n['linear fit', 'parity', 'data']\n\n\n<matplotlib.legend.Legend at 0x11af6afd0>"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Personal blogposts and explorations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nCategories\n\n\nReading Time\n\n\n\n\n\n\nFingerprints on fingertips\n\n\npython,chemical-science,data-analysis\n\n\n3 min\n\n\n\n\nWeb-scraping Hindi (Bollywood) movies from IMDb\n\n\n\n\n0 min\n\n\n\n\nClassifying reactions using machine-learning\n\n\npython,chemical-science,data-analysis\n\n\n2 min\n\n\n\n\nFingerprints\n\n\n\n\n1 min\n\n\n\n\nAuto3D to make optimize tautomers and 3D conformers\n\n\n\n\n0 min\n\n\n\n\nSmall Molecules Resources\n\n\nchemical-science,machine-learning,resources\n\n\n47 min\n\n\n\n\nCheminformatics basics - Clustering molecules\n\n\n\n\n0 min\n\n\n\n\nCheminformatics basics - Why the SMIRKS?\n\n\n\n\n3 min\n\n\n\n\nCheminformatics basics - A SMARTS way to filter molecules\n\n\n\n\n7 min\n\n\n\n\nOn machine learning model interpretability\n\n\nexploratory-data-analysis,machine-learning,resources,chemical-science\n\n\n1 min\n\n\n\n\nRdkit quick tips\n\n\nchemical-science,exploratory-data-analysis,machine-learning,resources\n\n\n5 min\n\n\n\n\nModel building checklist\n\n\nexploratory-data-analysis,machine-learning,resources,chemical-science\n\n\n2 min\n\n\n\n\nResources list\n\n\nexploratory-data-analysis,machine-learning,resources\n\n\n5 min\n\n\n\n\nPandas cookbook\n\n\nexploratory-data-analysis,machine-learning,resources\n\n\n6 min\n\n\n\n\nExploratory Data Analysis on Behavioral Risk Factor Surveillance System (BRFSS) dataset\n\n\n\n\n3 min\n\n\n\n\nMaterial-informatics Literature and Resources\n\n\nchemical-science,machine-learning,resources\n\n\n16 min\n\n\n\n\nCheminformatics basics - RDkit, regression models, similarity\n\n\n\n\n4 min\n\n\n\n\nMateiral informatics sample project\n\n\nchemical-science,python,machine-learning\n\n\n1 min\n\n\n\n\nMaking equal spaces parity plots using Matplotlib\n\n\n\n\n0 min\n\n\n\n\nAnamoly detection using autoencoders\n\n\n\n\n2 min\n\n\n\n\nImplement neural network from scratch for binary classification\n\n\npython,pytorch,machine-learning\n\n\n4 min\n\n\n\n\nt-SNE and UMAP - Effect of initialization on the dimensionality reduction\n\n\npython,data-visualization\n\n\n1 min\n\n\n\n\nBayesian optimisation implementation\n\n\n\n\n3 min\n\n\n\n\nEstimating prediction confidence through dropout\n\n\n\n\n2 min\n\n\n\n\nSolving the birthday problem using simple counting\n\n\n\n\n1 min\n\n\n\n\nCentral limit theorem\n\n\n\n\n3 min\n\n\n\n\nRelational analysis of spices used in Indian cuisine\n\n\n\n\n2 min\n\n\n\n\nNetwork analysis hands-on\n\n\n\n\n3 min\n\n\n\n\nTransfer learning walkthrough using Pytorch\n\n\n\n\n2 min\n\n\n\n\nGet SMILES from PubChem using DASK\n\n\n\n\n0 min\n\n\n\n\nAnalyze Bollywood movie ratings (1950-2020)\n\n\n\n\n1 min\n\n\n\n\nClassification-based algorithms walkthrough\n\n\n\n\n9 min\n\n\n\n\nS&P 500 analysis using beautifulsoup and pandas\n\n\n\n\n0 min\n\n\n\n\nPlotting surface in matplotlib\n\n\n\n\n1 min\n\n\n\n\nActivation functions\n\n\n\n\n1 min\n\n\n\n\nConvolutional neural network example\n\n\n\n\n2 min\n\n\n\n\nImplement Support Vector Machines in scikit-learn\n\n\n\n\n5 min\n\n\n\n\nAn Example Markdown Post\n\n\nmarkdown\n\n\n1 min\n\n\n\n\nVectorisation in python using numpy\n\n\n\n\n0 min\n\n\n\n\nLambda, Filter, and Map functions in Python\n\n\n\n\n0 min\n\n\n\n\nPrincipal component analysis\n\n\n\n\n6 min\n\n\n\n\nNeural network implementation in PyTorch\n\n\n\n\n0 min\n\n\n\n\nEnd-to-end Machine Learning Project\n\n\npython,exploratory-data-analysis,machine-learning\n\n\n16 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Blog documenting the tinkerings and helpful tips I have accumulated in the area of data science and machine learning, with some flavor of chemical science sprinkled sporadically.\nThe posts are meant to be a reference for my future self or whoever wishes to start in the data science and ML space."
  }
]